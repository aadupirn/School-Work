2016-10-06 20:23:53 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-06 20:23:53 WARN  Utils:66 - Your hostname, aadu-XPS-13-9350 resolves to a loopback address: 127.0.1.1; using 10.0.0.187 instead (on interface wlp58s0)
2016-10-06 20:23:53 WARN  Utils:66 - Set SPARK_LOCAL_IP if you need to bind to another address
2016-10-06 20:23:54 WARN  SparkContext:66 - Use an existing SparkContext, some configuration may not take effect.
2016-10-06 20:51:44 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-06 20:51:44 WARN  Utils:66 - Your hostname, aadu-XPS-13-9350 resolves to a loopback address: 127.0.1.1; using 10.0.0.187 instead (on interface wlp58s0)
2016-10-06 20:51:44 WARN  Utils:66 - Set SPARK_LOCAL_IP if you need to bind to another address
2016-10-06 20:51:45 WARN  SparkContext:66 - Use an existing SparkContext, some configuration may not take effect.
2016-10-06 21:06:27 ERROR Executor:91 - Exception in task 0.0 in stage 3.0 (TID 3)
org.apache.spark.SparkException: This RDD lacks a SparkContext. It could happen in the following cases: 
(1) RDD transformations and actions are NOT invoked by the driver, but inside of other transformations; for example, rdd1.map(x => rdd2.values.count() * x) is invalid because the values transformation and count action cannot be performed inside of the rdd1.map transformation. For more information, see SPARK-5063.
(2) When a Spark Streaming job recovers from checkpoint, this exception will be hit if a reference to an RDD not defined by the streaming job is used in DStream operations. For more information, See SPARK-13758.
	at org.apache.spark.rdd.RDD.org$apache$spark$rdd$RDD$$sc(RDD.scala:89)
	at org.apache.spark.rdd.RDD.count(RDD.scala:1115)
	at $line38.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$anonfun$3.apply(<console>:34)
	at $line38.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$anonfun$3.apply(<console>:34)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463)
	at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1682)
	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1115)
	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1115)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1897)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1897)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:85)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-10-06 21:06:27 WARN  TaskSetManager:66 - Lost task 0.0 in stage 3.0 (TID 3, localhost): org.apache.spark.SparkException: This RDD lacks a SparkContext. It could happen in the following cases: 
(1) RDD transformations and actions are NOT invoked by the driver, but inside of other transformations; for example, rdd1.map(x => rdd2.values.count() * x) is invalid because the values transformation and count action cannot be performed inside of the rdd1.map transformation. For more information, see SPARK-5063.
(2) When a Spark Streaming job recovers from checkpoint, this exception will be hit if a reference to an RDD not defined by the streaming job is used in DStream operations. For more information, See SPARK-13758.
	at org.apache.spark.rdd.RDD.org$apache$spark$rdd$RDD$$sc(RDD.scala:89)
	at org.apache.spark.rdd.RDD.count(RDD.scala:1115)
	at $line38.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$anonfun$3.apply(<console>:34)
	at $line38.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$anonfun$3.apply(<console>:34)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463)
	at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1682)
	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1115)
	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1115)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1897)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1897)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:85)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2016-10-06 21:06:27 ERROR TaskSetManager:70 - Task 0 in stage 3.0 failed 1 times; aborting job
2016-10-06 21:06:51 ERROR Executor:91 - Exception in task 0.0 in stage 5.0 (TID 4)
org.apache.spark.SparkException: This RDD lacks a SparkContext. It could happen in the following cases: 
(1) RDD transformations and actions are NOT invoked by the driver, but inside of other transformations; for example, rdd1.map(x => rdd2.values.count() * x) is invalid because the values transformation and count action cannot be performed inside of the rdd1.map transformation. For more information, see SPARK-5063.
(2) When a Spark Streaming job recovers from checkpoint, this exception will be hit if a reference to an RDD not defined by the streaming job is used in DStream operations. For more information, See SPARK-13758.
	at org.apache.spark.rdd.RDD.org$apache$spark$rdd$RDD$$sc(RDD.scala:89)
	at org.apache.spark.rdd.RDD.count(RDD.scala:1115)
	at $line38.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$anonfun$3.apply(<console>:34)
	at $line38.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$anonfun$3.apply(<console>:34)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463)
	at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1682)
	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1115)
	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1115)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1897)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1897)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:85)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-10-06 21:06:51 WARN  TaskSetManager:66 - Lost task 0.0 in stage 5.0 (TID 4, localhost): org.apache.spark.SparkException: This RDD lacks a SparkContext. It could happen in the following cases: 
(1) RDD transformations and actions are NOT invoked by the driver, but inside of other transformations; for example, rdd1.map(x => rdd2.values.count() * x) is invalid because the values transformation and count action cannot be performed inside of the rdd1.map transformation. For more information, see SPARK-5063.
(2) When a Spark Streaming job recovers from checkpoint, this exception will be hit if a reference to an RDD not defined by the streaming job is used in DStream operations. For more information, See SPARK-13758.
	at org.apache.spark.rdd.RDD.org$apache$spark$rdd$RDD$$sc(RDD.scala:89)
	at org.apache.spark.rdd.RDD.count(RDD.scala:1115)
	at $line38.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$anonfun$3.apply(<console>:34)
	at $line38.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$anonfun$3.apply(<console>:34)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463)
	at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1682)
	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1115)
	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1115)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1897)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1897)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:85)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2016-10-06 21:06:51 ERROR TaskSetManager:70 - Task 0 in stage 5.0 failed 1 times; aborting job
2016-10-06 21:09:12 ERROR Executor:91 - Exception in task 0.0 in stage 7.0 (TID 6)
org.apache.spark.SparkException: This RDD lacks a SparkContext. It could happen in the following cases: 
(1) RDD transformations and actions are NOT invoked by the driver, but inside of other transformations; for example, rdd1.map(x => rdd2.values.count() * x) is invalid because the values transformation and count action cannot be performed inside of the rdd1.map transformation. For more information, see SPARK-5063.
(2) When a Spark Streaming job recovers from checkpoint, this exception will be hit if a reference to an RDD not defined by the streaming job is used in DStream operations. For more information, See SPARK-13758.
	at org.apache.spark.rdd.RDD.org$apache$spark$rdd$RDD$$sc(RDD.scala:89)
	at org.apache.spark.rdd.RDD.count(RDD.scala:1115)
	at $line46.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$anonfun$3.apply(<console>:34)
	at $line46.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$anonfun$3.apply(<console>:34)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463)
	at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1682)
	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1115)
	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1115)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1897)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1897)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:85)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-10-06 21:09:12 WARN  TaskSetManager:66 - Lost task 0.0 in stage 7.0 (TID 6, localhost): org.apache.spark.SparkException: This RDD lacks a SparkContext. It could happen in the following cases: 
(1) RDD transformations and actions are NOT invoked by the driver, but inside of other transformations; for example, rdd1.map(x => rdd2.values.count() * x) is invalid because the values transformation and count action cannot be performed inside of the rdd1.map transformation. For more information, see SPARK-5063.
(2) When a Spark Streaming job recovers from checkpoint, this exception will be hit if a reference to an RDD not defined by the streaming job is used in DStream operations. For more information, See SPARK-13758.
	at org.apache.spark.rdd.RDD.org$apache$spark$rdd$RDD$$sc(RDD.scala:89)
	at org.apache.spark.rdd.RDD.count(RDD.scala:1115)
	at $line46.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$anonfun$3.apply(<console>:34)
	at $line46.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$anonfun$3.apply(<console>:34)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463)
	at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1682)
	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1115)
	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1115)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1897)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1897)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:85)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2016-10-06 21:09:12 ERROR TaskSetManager:70 - Task 0 in stage 7.0 failed 1 times; aborting job
2016-10-06 22:08:43 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-06 22:08:43 WARN  Utils:66 - Your hostname, aadu-XPS-13-9350 resolves to a loopback address: 127.0.1.1; using 10.0.0.187 instead (on interface wlp58s0)
2016-10-06 22:08:43 WARN  Utils:66 - Set SPARK_LOCAL_IP if you need to bind to another address
2016-10-06 22:08:44 WARN  SparkContext:66 - Use an existing SparkContext, some configuration may not take effect.
2016-10-06 22:26:30 WARN  TaskMemoryManager:381 - leak 203.8 MB memory from org.apache.spark.util.collection.ExternalAppendOnlyMap@5f7cf4c3
2016-10-06 22:26:30 WARN  Executor:66 - Managed memory leak detected; size = 213732850 bytes, TID = 7
2016-10-07 15:05:56 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-07 15:05:56 WARN  Utils:66 - Your hostname, aadu-XPS-13-9350 resolves to a loopback address: 127.0.1.1; using 150.212.233.212 instead (on interface wlp58s0)
2016-10-07 15:05:56 WARN  Utils:66 - Set SPARK_LOCAL_IP if you need to bind to another address
2016-10-07 15:05:56 WARN  SparkContext:66 - Use an existing SparkContext, some configuration may not take effect.
2016-10-07 16:09:08 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-07 16:09:08 WARN  Utils:66 - Your hostname, aadu-XPS-13-9350 resolves to a loopback address: 127.0.1.1; using 10.0.0.187 instead (on interface wlp58s0)
2016-10-07 16:09:08 WARN  Utils:66 - Set SPARK_LOCAL_IP if you need to bind to another address
2016-10-07 16:09:09 WARN  SparkContext:66 - Use an existing SparkContext, some configuration may not take effect.
2016-10-07 16:11:12 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-07 16:11:12 WARN  Utils:66 - Your hostname, aadu-XPS-13-9350 resolves to a loopback address: 127.0.1.1; using 10.0.0.187 instead (on interface wlp58s0)
2016-10-07 16:11:12 WARN  Utils:66 - Set SPARK_LOCAL_IP if you need to bind to another address
2016-10-07 16:11:13 WARN  SparkContext:66 - Use an existing SparkContext, some configuration may not take effect.
2016-10-07 16:16:54 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-07 16:16:54 WARN  Utils:66 - Your hostname, aadu-XPS-13-9350 resolves to a loopback address: 127.0.1.1; using 10.0.0.187 instead (on interface wlp58s0)
2016-10-07 16:16:54 WARN  Utils:66 - Set SPARK_LOCAL_IP if you need to bind to another address
2016-10-07 16:16:55 WARN  SparkContext:66 - Use an existing SparkContext, some configuration may not take effect.
2016-10-07 16:30:33 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-07 16:30:33 WARN  Utils:66 - Your hostname, aadu-XPS-13-9350 resolves to a loopback address: 127.0.1.1; using 10.0.0.187 instead (on interface wlp58s0)
2016-10-07 16:30:33 WARN  Utils:66 - Set SPARK_LOCAL_IP if you need to bind to another address
2016-10-07 16:30:34 WARN  SparkContext:66 - Use an existing SparkContext, some configuration may not take effect.
2016-10-07 16:32:19 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-07 16:32:19 WARN  Utils:66 - Your hostname, aadu-XPS-13-9350 resolves to a loopback address: 127.0.1.1; using 10.0.0.187 instead (on interface wlp58s0)
2016-10-07 16:32:19 WARN  Utils:66 - Set SPARK_LOCAL_IP if you need to bind to another address
2016-10-07 16:32:20 WARN  SparkContext:66 - Use an existing SparkContext, some configuration may not take effect.
2016-10-07 16:35:28 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-07 16:35:28 WARN  Utils:66 - Your hostname, aadu-XPS-13-9350 resolves to a loopback address: 127.0.1.1; using 10.0.0.187 instead (on interface wlp58s0)
2016-10-07 16:35:28 WARN  Utils:66 - Set SPARK_LOCAL_IP if you need to bind to another address
2016-10-07 16:35:29 WARN  SparkContext:66 - Use an existing SparkContext, some configuration may not take effect.
2016-10-07 16:36:05 WARN  TaskMemoryManager:381 - leak 316.4 MB memory from org.apache.spark.util.collection.ExternalAppendOnlyMap@3f75958c
2016-10-07 16:36:05 WARN  Executor:66 - Managed memory leak detected; size = 331739154 bytes, TID = 3
2016-10-12 16:57:09 INFO  SparkContext:54 - Running Spark version 2.0.0
2016-10-12 16:57:09 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-12 16:57:09 WARN  Utils:66 - Your hostname, aadu-XPS-13-9350 resolves to a loopback address: 127.0.1.1; using 150.212.30.95 instead (on interface wlp58s0)
2016-10-12 16:57:09 WARN  Utils:66 - Set SPARK_LOCAL_IP if you need to bind to another address
2016-10-12 16:57:09 INFO  SecurityManager:54 - Changing view acls to: aadu
2016-10-12 16:57:09 INFO  SecurityManager:54 - Changing modify acls to: aadu
2016-10-12 16:57:09 INFO  SecurityManager:54 - Changing view acls groups to: 
2016-10-12 16:57:09 INFO  SecurityManager:54 - Changing modify acls groups to: 
2016-10-12 16:57:09 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(aadu); groups with view permissions: Set(); users  with modify permissions: Set(aadu); groups with modify permissions: Set()
2016-10-12 16:57:10 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 35713.
2016-10-12 16:57:10 INFO  SparkEnv:54 - Registering MapOutputTracker
2016-10-12 16:57:10 INFO  SparkEnv:54 - Registering BlockManagerMaster
2016-10-12 16:57:10 INFO  DiskBlockManager:54 - Created local directory at /tmp/blockmgr-bb089cdc-8bca-4c1c-92cb-a881017978e0
2016-10-12 16:57:10 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2016-10-12 16:57:10 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2016-10-12 16:57:10 INFO  log:186 - Logging initialized @1649ms
2016-10-12 16:57:10 INFO  Server:327 - jetty-9.2.z-SNAPSHOT
2016-10-12 16:57:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,AVAILABLE}
2016-10-12 16:57:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,AVAILABLE}
2016-10-12 16:57:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,AVAILABLE}
2016-10-12 16:57:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,AVAILABLE}
2016-10-12 16:57:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,AVAILABLE}
2016-10-12 16:57:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,AVAILABLE}
2016-10-12 16:57:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,AVAILABLE}
2016-10-12 16:57:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,AVAILABLE}
2016-10-12 16:57:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,AVAILABLE}
2016-10-12 16:57:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,AVAILABLE}
2016-10-12 16:57:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1643d68f{/storage,null,AVAILABLE}
2016-10-12 16:57:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,AVAILABLE}
2016-10-12 16:57:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,AVAILABLE}
2016-10-12 16:57:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,AVAILABLE}
2016-10-12 16:57:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4052274f{/environment,null,AVAILABLE}
2016-10-12 16:57:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,AVAILABLE}
2016-10-12 16:57:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@297ea53a{/executors,null,AVAILABLE}
2016-10-12 16:57:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,AVAILABLE}
2016-10-12 16:57:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,AVAILABLE}
2016-10-12 16:57:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,AVAILABLE}
2016-10-12 16:57:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a7471ce{/static,null,AVAILABLE}
2016-10-12 16:57:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@28276e50{/,null,AVAILABLE}
2016-10-12 16:57:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@62e70ea3{/api,null,AVAILABLE}
2016-10-12 16:57:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,AVAILABLE}
2016-10-12 16:57:10 INFO  ServerConnector:266 - Started ServerConnector@64337702{HTTP/1.1}{0.0.0.0:4040}
2016-10-12 16:57:10 INFO  Server:379 - Started @1767ms
2016-10-12 16:57:10 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2016-10-12 16:57:10 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://150.212.30.95:4040
2016-10-12 16:57:10 INFO  SparkContext:54 - Added JAR file:/home/aadu/Repos/adam/adam-assembly/target/adam_2.11-0.19.1-SNAPSHOT.jar at spark://150.212.30.95:35713/jars/adam_2.11-0.19.1-SNAPSHOT.jar with timestamp 1476305830630
2016-10-12 16:57:10 INFO  SparkContext:54 - Added JAR file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/a1.jar at spark://150.212.30.95:35713/jars/a1.jar with timestamp 1476305830632
2016-10-12 16:57:10 INFO  Executor:54 - Starting executor ID driver on host localhost
2016-10-12 16:57:10 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45945.
2016-10-12 16:57:10 INFO  NettyBlockTransferService:54 - Server created on 150.212.30.95:45945
2016-10-12 16:57:10 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 150.212.30.95, 45945)
2016-10-12 16:57:10 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 150.212.30.95:45945 with 366.3 MB RAM, BlockManagerId(driver, 150.212.30.95, 45945)
2016-10-12 16:57:10 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 150.212.30.95, 45945)
2016-10-12 16:57:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@199e4c2b{/metrics/json,null,AVAILABLE}
2016-10-12 16:57:11 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2016-10-12 16:57:11 INFO  ServerConnector:306 - Stopped ServerConnector@64337702{HTTP/1.1}{0.0.0.0:4040}
2016-10-12 16:57:11 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,UNAVAILABLE}
2016-10-12 16:57:11 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@62e70ea3{/api,null,UNAVAILABLE}
2016-10-12 16:57:11 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@28276e50{/,null,UNAVAILABLE}
2016-10-12 16:57:11 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a7471ce{/static,null,UNAVAILABLE}
2016-10-12 16:57:11 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,UNAVAILABLE}
2016-10-12 16:57:11 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,UNAVAILABLE}
2016-10-12 16:57:11 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,UNAVAILABLE}
2016-10-12 16:57:11 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@297ea53a{/executors,null,UNAVAILABLE}
2016-10-12 16:57:11 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,UNAVAILABLE}
2016-10-12 16:57:11 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4052274f{/environment,null,UNAVAILABLE}
2016-10-12 16:57:11 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,UNAVAILABLE}
2016-10-12 16:57:11 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,UNAVAILABLE}
2016-10-12 16:57:11 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,UNAVAILABLE}
2016-10-12 16:57:11 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1643d68f{/storage,null,UNAVAILABLE}
2016-10-12 16:57:11 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,UNAVAILABLE}
2016-10-12 16:57:11 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,UNAVAILABLE}
2016-10-12 16:57:11 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,UNAVAILABLE}
2016-10-12 16:57:11 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,UNAVAILABLE}
2016-10-12 16:57:11 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,UNAVAILABLE}
2016-10-12 16:57:11 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,UNAVAILABLE}
2016-10-12 16:57:11 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,UNAVAILABLE}
2016-10-12 16:57:11 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,UNAVAILABLE}
2016-10-12 16:57:11 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,UNAVAILABLE}
2016-10-12 16:57:11 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,UNAVAILABLE}
2016-10-12 16:57:11 INFO  SparkUI:54 - Stopped Spark web UI at http://150.212.30.95:4040
2016-10-12 16:57:11 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2016-10-12 16:57:11 INFO  MemoryStore:54 - MemoryStore cleared
2016-10-12 16:57:11 INFO  BlockManager:54 - BlockManager stopped
2016-10-12 16:57:11 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2016-10-12 16:57:11 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2016-10-12 16:57:11 INFO  SparkContext:54 - Successfully stopped SparkContext
2016-10-12 16:57:11 INFO  ShutdownHookManager:54 - Shutdown hook called
2016-10-12 16:57:11 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-75e0001e-7cc1-453a-ba1e-797fb452c138
2016-10-12 16:57:58 INFO  SparkContext:54 - Running Spark version 2.0.0
2016-10-12 16:57:58 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-12 16:57:58 WARN  Utils:66 - Your hostname, aadu-XPS-13-9350 resolves to a loopback address: 127.0.1.1; using 150.212.30.95 instead (on interface wlp58s0)
2016-10-12 16:57:58 WARN  Utils:66 - Set SPARK_LOCAL_IP if you need to bind to another address
2016-10-12 16:57:58 INFO  SecurityManager:54 - Changing view acls to: aadu
2016-10-12 16:57:58 INFO  SecurityManager:54 - Changing modify acls to: aadu
2016-10-12 16:57:58 INFO  SecurityManager:54 - Changing view acls groups to: 
2016-10-12 16:57:58 INFO  SecurityManager:54 - Changing modify acls groups to: 
2016-10-12 16:57:58 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(aadu); groups with view permissions: Set(); users  with modify permissions: Set(aadu); groups with modify permissions: Set()
2016-10-12 16:57:59 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 41107.
2016-10-12 16:57:59 INFO  SparkEnv:54 - Registering MapOutputTracker
2016-10-12 16:57:59 INFO  SparkEnv:54 - Registering BlockManagerMaster
2016-10-12 16:57:59 INFO  DiskBlockManager:54 - Created local directory at /tmp/blockmgr-bc18cf5d-b5da-4551-8bac-4b9efa373b31
2016-10-12 16:57:59 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2016-10-12 16:57:59 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2016-10-12 16:57:59 INFO  log:186 - Logging initialized @1442ms
2016-10-12 16:57:59 INFO  Server:327 - jetty-9.2.z-SNAPSHOT
2016-10-12 16:57:59 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,AVAILABLE}
2016-10-12 16:57:59 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,AVAILABLE}
2016-10-12 16:57:59 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,AVAILABLE}
2016-10-12 16:57:59 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,AVAILABLE}
2016-10-12 16:57:59 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,AVAILABLE}
2016-10-12 16:57:59 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,AVAILABLE}
2016-10-12 16:57:59 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,AVAILABLE}
2016-10-12 16:57:59 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,AVAILABLE}
2016-10-12 16:57:59 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,AVAILABLE}
2016-10-12 16:57:59 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,AVAILABLE}
2016-10-12 16:57:59 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1643d68f{/storage,null,AVAILABLE}
2016-10-12 16:57:59 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,AVAILABLE}
2016-10-12 16:57:59 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,AVAILABLE}
2016-10-12 16:57:59 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,AVAILABLE}
2016-10-12 16:57:59 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4052274f{/environment,null,AVAILABLE}
2016-10-12 16:57:59 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,AVAILABLE}
2016-10-12 16:57:59 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@297ea53a{/executors,null,AVAILABLE}
2016-10-12 16:57:59 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,AVAILABLE}
2016-10-12 16:57:59 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,AVAILABLE}
2016-10-12 16:57:59 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,AVAILABLE}
2016-10-12 16:57:59 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a7471ce{/static,null,AVAILABLE}
2016-10-12 16:57:59 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@28276e50{/,null,AVAILABLE}
2016-10-12 16:57:59 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@62e70ea3{/api,null,AVAILABLE}
2016-10-12 16:57:59 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,AVAILABLE}
2016-10-12 16:57:59 INFO  ServerConnector:266 - Started ServerConnector@64337702{HTTP/1.1}{0.0.0.0:4040}
2016-10-12 16:57:59 INFO  Server:379 - Started @1553ms
2016-10-12 16:57:59 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2016-10-12 16:57:59 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://150.212.30.95:4040
2016-10-12 16:57:59 INFO  SparkContext:54 - Added JAR file:/home/aadu/Repos/adam/adam-assembly/target/adam_2.11-0.19.1-SNAPSHOT.jar at spark://150.212.30.95:41107/jars/adam_2.11-0.19.1-SNAPSHOT.jar with timestamp 1476305879590
2016-10-12 16:57:59 INFO  SparkContext:54 - Added JAR file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/a1.jar at spark://150.212.30.95:41107/jars/a1.jar with timestamp 1476305879593
2016-10-12 16:57:59 INFO  Executor:54 - Starting executor ID driver on host localhost
2016-10-12 16:57:59 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35676.
2016-10-12 16:57:59 INFO  NettyBlockTransferService:54 - Server created on 150.212.30.95:35676
2016-10-12 16:57:59 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 150.212.30.95, 35676)
2016-10-12 16:57:59 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 150.212.30.95:35676 with 366.3 MB RAM, BlockManagerId(driver, 150.212.30.95, 35676)
2016-10-12 16:57:59 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 150.212.30.95, 35676)
2016-10-12 16:57:59 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@199e4c2b{/metrics/json,null,AVAILABLE}
2016-10-12 16:58:00 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2016-10-12 16:58:00 INFO  ServerConnector:306 - Stopped ServerConnector@64337702{HTTP/1.1}{0.0.0.0:4040}
2016-10-12 16:58:00 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,UNAVAILABLE}
2016-10-12 16:58:00 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@62e70ea3{/api,null,UNAVAILABLE}
2016-10-12 16:58:00 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@28276e50{/,null,UNAVAILABLE}
2016-10-12 16:58:00 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a7471ce{/static,null,UNAVAILABLE}
2016-10-12 16:58:00 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,UNAVAILABLE}
2016-10-12 16:58:00 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,UNAVAILABLE}
2016-10-12 16:58:00 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,UNAVAILABLE}
2016-10-12 16:58:00 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@297ea53a{/executors,null,UNAVAILABLE}
2016-10-12 16:58:00 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,UNAVAILABLE}
2016-10-12 16:58:00 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4052274f{/environment,null,UNAVAILABLE}
2016-10-12 16:58:00 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,UNAVAILABLE}
2016-10-12 16:58:00 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,UNAVAILABLE}
2016-10-12 16:58:00 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,UNAVAILABLE}
2016-10-12 16:58:00 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1643d68f{/storage,null,UNAVAILABLE}
2016-10-12 16:58:00 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,UNAVAILABLE}
2016-10-12 16:58:00 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,UNAVAILABLE}
2016-10-12 16:58:00 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,UNAVAILABLE}
2016-10-12 16:58:00 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,UNAVAILABLE}
2016-10-12 16:58:00 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,UNAVAILABLE}
2016-10-12 16:58:00 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,UNAVAILABLE}
2016-10-12 16:58:00 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,UNAVAILABLE}
2016-10-12 16:58:00 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,UNAVAILABLE}
2016-10-12 16:58:00 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,UNAVAILABLE}
2016-10-12 16:58:00 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,UNAVAILABLE}
2016-10-12 16:58:00 INFO  SparkUI:54 - Stopped Spark web UI at http://150.212.30.95:4040
2016-10-12 16:58:00 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2016-10-12 16:58:00 INFO  MemoryStore:54 - MemoryStore cleared
2016-10-12 16:58:00 INFO  BlockManager:54 - BlockManager stopped
2016-10-12 16:58:00 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2016-10-12 16:58:00 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2016-10-12 16:58:00 INFO  SparkContext:54 - Successfully stopped SparkContext
2016-10-12 16:58:00 INFO  ShutdownHookManager:54 - Shutdown hook called
2016-10-12 16:58:00 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-4416bbf9-36a9-4735-bc59-451136707775
2016-10-12 16:59:54 INFO  SparkContext:54 - Running Spark version 2.0.0
2016-10-12 16:59:54 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-12 16:59:54 WARN  Utils:66 - Your hostname, aadu-XPS-13-9350 resolves to a loopback address: 127.0.1.1; using 150.212.30.95 instead (on interface wlp58s0)
2016-10-12 16:59:54 WARN  Utils:66 - Set SPARK_LOCAL_IP if you need to bind to another address
2016-10-12 16:59:54 INFO  SecurityManager:54 - Changing view acls to: aadu
2016-10-12 16:59:54 INFO  SecurityManager:54 - Changing modify acls to: aadu
2016-10-12 16:59:54 INFO  SecurityManager:54 - Changing view acls groups to: 
2016-10-12 16:59:54 INFO  SecurityManager:54 - Changing modify acls groups to: 
2016-10-12 16:59:54 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(aadu); groups with view permissions: Set(); users  with modify permissions: Set(aadu); groups with modify permissions: Set()
2016-10-12 16:59:55 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 45763.
2016-10-12 16:59:55 INFO  SparkEnv:54 - Registering MapOutputTracker
2016-10-12 16:59:55 INFO  SparkEnv:54 - Registering BlockManagerMaster
2016-10-12 16:59:55 INFO  DiskBlockManager:54 - Created local directory at /tmp/blockmgr-19396c4e-88b0-494a-b35f-a11669975fcb
2016-10-12 16:59:55 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2016-10-12 16:59:55 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2016-10-12 16:59:55 INFO  log:186 - Logging initialized @1457ms
2016-10-12 16:59:55 INFO  Server:327 - jetty-9.2.z-SNAPSHOT
2016-10-12 16:59:55 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,AVAILABLE}
2016-10-12 16:59:55 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,AVAILABLE}
2016-10-12 16:59:55 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,AVAILABLE}
2016-10-12 16:59:55 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,AVAILABLE}
2016-10-12 16:59:55 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,AVAILABLE}
2016-10-12 16:59:55 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,AVAILABLE}
2016-10-12 16:59:55 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,AVAILABLE}
2016-10-12 16:59:55 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,AVAILABLE}
2016-10-12 16:59:55 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,AVAILABLE}
2016-10-12 16:59:55 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,AVAILABLE}
2016-10-12 16:59:55 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1643d68f{/storage,null,AVAILABLE}
2016-10-12 16:59:55 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,AVAILABLE}
2016-10-12 16:59:55 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,AVAILABLE}
2016-10-12 16:59:55 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,AVAILABLE}
2016-10-12 16:59:55 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4052274f{/environment,null,AVAILABLE}
2016-10-12 16:59:55 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,AVAILABLE}
2016-10-12 16:59:55 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@297ea53a{/executors,null,AVAILABLE}
2016-10-12 16:59:55 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,AVAILABLE}
2016-10-12 16:59:55 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,AVAILABLE}
2016-10-12 16:59:55 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,AVAILABLE}
2016-10-12 16:59:55 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a7471ce{/static,null,AVAILABLE}
2016-10-12 16:59:55 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@28276e50{/,null,AVAILABLE}
2016-10-12 16:59:55 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@62e70ea3{/api,null,AVAILABLE}
2016-10-12 16:59:55 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,AVAILABLE}
2016-10-12 16:59:55 INFO  ServerConnector:266 - Started ServerConnector@64337702{HTTP/1.1}{0.0.0.0:4040}
2016-10-12 16:59:55 INFO  Server:379 - Started @1563ms
2016-10-12 16:59:55 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2016-10-12 16:59:55 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://150.212.30.95:4040
2016-10-12 16:59:55 INFO  SparkContext:54 - Added JAR file:/home/aadu/Repos/adam/adam-assembly/target/adam_2.11-0.19.1-SNAPSHOT.jar at spark://150.212.30.95:45763/jars/adam_2.11-0.19.1-SNAPSHOT.jar with timestamp 1476305995472
2016-10-12 16:59:55 INFO  SparkContext:54 - Added JAR file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/a1.jar at spark://150.212.30.95:45763/jars/a1.jar with timestamp 1476305995474
2016-10-12 16:59:55 INFO  Executor:54 - Starting executor ID driver on host localhost
2016-10-12 16:59:55 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35852.
2016-10-12 16:59:55 INFO  NettyBlockTransferService:54 - Server created on 150.212.30.95:35852
2016-10-12 16:59:55 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 150.212.30.95, 35852)
2016-10-12 16:59:55 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 150.212.30.95:35852 with 366.3 MB RAM, BlockManagerId(driver, 150.212.30.95, 35852)
2016-10-12 16:59:55 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 150.212.30.95, 35852)
2016-10-12 16:59:55 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@199e4c2b{/metrics/json,null,AVAILABLE}
2016-10-12 16:59:55 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2016-10-12 16:59:55 INFO  ServerConnector:306 - Stopped ServerConnector@64337702{HTTP/1.1}{0.0.0.0:4040}
2016-10-12 16:59:55 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,UNAVAILABLE}
2016-10-12 16:59:55 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@62e70ea3{/api,null,UNAVAILABLE}
2016-10-12 16:59:55 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@28276e50{/,null,UNAVAILABLE}
2016-10-12 16:59:55 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a7471ce{/static,null,UNAVAILABLE}
2016-10-12 16:59:55 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,UNAVAILABLE}
2016-10-12 16:59:55 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,UNAVAILABLE}
2016-10-12 16:59:55 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,UNAVAILABLE}
2016-10-12 16:59:55 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@297ea53a{/executors,null,UNAVAILABLE}
2016-10-12 16:59:55 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,UNAVAILABLE}
2016-10-12 16:59:55 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4052274f{/environment,null,UNAVAILABLE}
2016-10-12 16:59:55 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,UNAVAILABLE}
2016-10-12 16:59:55 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,UNAVAILABLE}
2016-10-12 16:59:55 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,UNAVAILABLE}
2016-10-12 16:59:55 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1643d68f{/storage,null,UNAVAILABLE}
2016-10-12 16:59:55 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,UNAVAILABLE}
2016-10-12 16:59:55 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,UNAVAILABLE}
2016-10-12 16:59:55 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,UNAVAILABLE}
2016-10-12 16:59:55 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,UNAVAILABLE}
2016-10-12 16:59:55 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,UNAVAILABLE}
2016-10-12 16:59:55 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,UNAVAILABLE}
2016-10-12 16:59:55 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,UNAVAILABLE}
2016-10-12 16:59:55 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,UNAVAILABLE}
2016-10-12 16:59:55 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,UNAVAILABLE}
2016-10-12 16:59:55 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,UNAVAILABLE}
2016-10-12 16:59:55 INFO  SparkUI:54 - Stopped Spark web UI at http://150.212.30.95:4040
2016-10-12 16:59:55 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2016-10-12 16:59:55 INFO  MemoryStore:54 - MemoryStore cleared
2016-10-12 16:59:55 INFO  BlockManager:54 - BlockManager stopped
2016-10-12 16:59:55 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2016-10-12 16:59:55 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2016-10-12 16:59:55 INFO  SparkContext:54 - Successfully stopped SparkContext
2016-10-12 16:59:55 INFO  ShutdownHookManager:54 - Shutdown hook called
2016-10-12 16:59:55 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-e1db2d3f-f5a3-476a-bd32-1b321ad9f8d7
2016-10-12 17:02:12 INFO  SparkContext:54 - Running Spark version 2.0.0
2016-10-12 17:02:13 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-12 17:02:13 WARN  Utils:66 - Your hostname, aadu-XPS-13-9350 resolves to a loopback address: 127.0.1.1; using 150.212.30.95 instead (on interface wlp58s0)
2016-10-12 17:02:13 WARN  Utils:66 - Set SPARK_LOCAL_IP if you need to bind to another address
2016-10-12 17:02:13 INFO  SecurityManager:54 - Changing view acls to: aadu
2016-10-12 17:02:13 INFO  SecurityManager:54 - Changing modify acls to: aadu
2016-10-12 17:02:13 INFO  SecurityManager:54 - Changing view acls groups to: 
2016-10-12 17:02:13 INFO  SecurityManager:54 - Changing modify acls groups to: 
2016-10-12 17:02:13 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(aadu); groups with view permissions: Set(); users  with modify permissions: Set(aadu); groups with modify permissions: Set()
2016-10-12 17:02:13 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 45606.
2016-10-12 17:02:13 INFO  SparkEnv:54 - Registering MapOutputTracker
2016-10-12 17:02:13 INFO  SparkEnv:54 - Registering BlockManagerMaster
2016-10-12 17:02:13 INFO  DiskBlockManager:54 - Created local directory at /tmp/blockmgr-88fbc881-70b9-413e-825e-09fd56001d4c
2016-10-12 17:02:13 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2016-10-12 17:02:13 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2016-10-12 17:02:13 INFO  log:186 - Logging initialized @1443ms
2016-10-12 17:02:13 INFO  Server:327 - jetty-9.2.z-SNAPSHOT
2016-10-12 17:02:13 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@18f20260{/jobs,null,AVAILABLE}
2016-10-12 17:02:13 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4ae33a11{/jobs/json,null,AVAILABLE}
2016-10-12 17:02:13 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a48e6e2{/jobs/job,null,AVAILABLE}
2016-10-12 17:02:13 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@b40bb6e{/jobs/job/json,null,AVAILABLE}
2016-10-12 17:02:13 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3a94964{/stages,null,AVAILABLE}
2016-10-12 17:02:13 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5049d8b2{/stages/json,null,AVAILABLE}
2016-10-12 17:02:13 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6d0b5baf{/stages/stage,null,AVAILABLE}
2016-10-12 17:02:13 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@631e06ab{/stages/stage/json,null,AVAILABLE}
2016-10-12 17:02:13 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2a3591c5{/stages/pool,null,AVAILABLE}
2016-10-12 17:02:13 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@34a75079{/stages/pool/json,null,AVAILABLE}
2016-10-12 17:02:13 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@346a361{/storage,null,AVAILABLE}
2016-10-12 17:02:13 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@107ed6fc{/storage/json,null,AVAILABLE}
2016-10-12 17:02:13 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1643d68f{/storage/rdd,null,AVAILABLE}
2016-10-12 17:02:13 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@186978a6{/storage/rdd/json,null,AVAILABLE}
2016-10-12 17:02:13 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2e029d61{/environment,null,AVAILABLE}
2016-10-12 17:02:13 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@482d776b{/environment/json,null,AVAILABLE}
2016-10-12 17:02:13 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4052274f{/executors,null,AVAILABLE}
2016-10-12 17:02:13 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@132ddbab{/executors/json,null,AVAILABLE}
2016-10-12 17:02:13 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@297ea53a{/executors/threadDump,null,AVAILABLE}
2016-10-12 17:02:13 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@acb0951{/executors/threadDump/json,null,AVAILABLE}
2016-10-12 17:02:13 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5bf22f18{/static,null,AVAILABLE}
2016-10-12 17:02:13 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@267f474e{/,null,AVAILABLE}
2016-10-12 17:02:13 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a7471ce{/api,null,AVAILABLE}
2016-10-12 17:02:13 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@28276e50{/stages/stage/kill,null,AVAILABLE}
2016-10-12 17:02:13 INFO  ServerConnector:266 - Started ServerConnector@404ad26f{HTTP/1.1}{0.0.0.0:4040}
2016-10-12 17:02:13 INFO  Server:379 - Started @1547ms
2016-10-12 17:02:13 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2016-10-12 17:02:13 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://150.212.30.95:4040
2016-10-12 17:02:13 INFO  SparkContext:54 - Added JAR file:/home/aadu/Repos/adam/adam-assembly/target/adam_2.11-0.19.1-SNAPSHOT.jar at spark://150.212.30.95:45606/jars/adam_2.11-0.19.1-SNAPSHOT.jar with timestamp 1476306133843
2016-10-12 17:02:13 INFO  SparkContext:54 - Added JAR file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/a1.jar at spark://150.212.30.95:45606/jars/a1.jar with timestamp 1476306133843
2016-10-12 17:02:13 INFO  Executor:54 - Starting executor ID driver on host localhost
2016-10-12 17:02:13 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38206.
2016-10-12 17:02:13 INFO  NettyBlockTransferService:54 - Server created on 150.212.30.95:38206
2016-10-12 17:02:13 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 150.212.30.95, 38206)
2016-10-12 17:02:13 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 150.212.30.95:38206 with 366.3 MB RAM, BlockManagerId(driver, 150.212.30.95, 38206)
2016-10-12 17:02:13 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 150.212.30.95, 38206)
2016-10-12 17:02:14 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2237bada{/metrics/json,null,AVAILABLE}
2016-10-12 17:02:14 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2016-10-12 17:02:14 INFO  ServerConnector:306 - Stopped ServerConnector@404ad26f{HTTP/1.1}{0.0.0.0:4040}
2016-10-12 17:02:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@28276e50{/stages/stage/kill,null,UNAVAILABLE}
2016-10-12 17:02:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a7471ce{/api,null,UNAVAILABLE}
2016-10-12 17:02:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@267f474e{/,null,UNAVAILABLE}
2016-10-12 17:02:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5bf22f18{/static,null,UNAVAILABLE}
2016-10-12 17:02:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@acb0951{/executors/threadDump/json,null,UNAVAILABLE}
2016-10-12 17:02:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@297ea53a{/executors/threadDump,null,UNAVAILABLE}
2016-10-12 17:02:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@132ddbab{/executors/json,null,UNAVAILABLE}
2016-10-12 17:02:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4052274f{/executors,null,UNAVAILABLE}
2016-10-12 17:02:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@482d776b{/environment/json,null,UNAVAILABLE}
2016-10-12 17:02:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2e029d61{/environment,null,UNAVAILABLE}
2016-10-12 17:02:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@186978a6{/storage/rdd/json,null,UNAVAILABLE}
2016-10-12 17:02:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1643d68f{/storage/rdd,null,UNAVAILABLE}
2016-10-12 17:02:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@107ed6fc{/storage/json,null,UNAVAILABLE}
2016-10-12 17:02:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@346a361{/storage,null,UNAVAILABLE}
2016-10-12 17:02:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@34a75079{/stages/pool/json,null,UNAVAILABLE}
2016-10-12 17:02:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2a3591c5{/stages/pool,null,UNAVAILABLE}
2016-10-12 17:02:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@631e06ab{/stages/stage/json,null,UNAVAILABLE}
2016-10-12 17:02:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6d0b5baf{/stages/stage,null,UNAVAILABLE}
2016-10-12 17:02:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5049d8b2{/stages/json,null,UNAVAILABLE}
2016-10-12 17:02:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3a94964{/stages,null,UNAVAILABLE}
2016-10-12 17:02:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@b40bb6e{/jobs/job/json,null,UNAVAILABLE}
2016-10-12 17:02:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a48e6e2{/jobs/job,null,UNAVAILABLE}
2016-10-12 17:02:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4ae33a11{/jobs/json,null,UNAVAILABLE}
2016-10-12 17:02:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@18f20260{/jobs,null,UNAVAILABLE}
2016-10-12 17:02:14 INFO  SparkUI:54 - Stopped Spark web UI at http://150.212.30.95:4040
2016-10-12 17:02:14 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2016-10-12 17:02:14 INFO  MemoryStore:54 - MemoryStore cleared
2016-10-12 17:02:14 INFO  BlockManager:54 - BlockManager stopped
2016-10-12 17:02:14 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2016-10-12 17:02:14 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2016-10-12 17:02:14 INFO  SparkContext:54 - Successfully stopped SparkContext
2016-10-12 17:02:14 INFO  ShutdownHookManager:54 - Shutdown hook called
2016-10-12 17:02:14 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-4ecb3592-c36e-4515-bc81-cc65a45ed563
2016-10-12 17:10:49 INFO  SparkContext:54 - Running Spark version 2.0.0
2016-10-12 17:10:50 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-12 17:10:50 WARN  Utils:66 - Your hostname, aadu-XPS-13-9350 resolves to a loopback address: 127.0.1.1; using 150.212.30.95 instead (on interface wlp58s0)
2016-10-12 17:10:50 WARN  Utils:66 - Set SPARK_LOCAL_IP if you need to bind to another address
2016-10-12 17:10:50 INFO  SecurityManager:54 - Changing view acls to: aadu
2016-10-12 17:10:50 INFO  SecurityManager:54 - Changing modify acls to: aadu
2016-10-12 17:10:50 INFO  SecurityManager:54 - Changing view acls groups to: 
2016-10-12 17:10:50 INFO  SecurityManager:54 - Changing modify acls groups to: 
2016-10-12 17:10:50 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(aadu); groups with view permissions: Set(); users  with modify permissions: Set(aadu); groups with modify permissions: Set()
2016-10-12 17:10:50 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 43783.
2016-10-12 17:10:50 INFO  SparkEnv:54 - Registering MapOutputTracker
2016-10-12 17:10:50 INFO  SparkEnv:54 - Registering BlockManagerMaster
2016-10-12 17:10:50 INFO  DiskBlockManager:54 - Created local directory at /tmp/blockmgr-ba66a3f5-4f60-46ef-8cda-4c5ffce4163c
2016-10-12 17:10:50 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2016-10-12 17:10:50 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2016-10-12 17:10:50 INFO  log:186 - Logging initialized @1512ms
2016-10-12 17:10:50 INFO  Server:327 - jetty-9.2.z-SNAPSHOT
2016-10-12 17:10:50 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,AVAILABLE}
2016-10-12 17:10:50 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,AVAILABLE}
2016-10-12 17:10:50 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,AVAILABLE}
2016-10-12 17:10:50 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,AVAILABLE}
2016-10-12 17:10:50 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,AVAILABLE}
2016-10-12 17:10:50 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,AVAILABLE}
2016-10-12 17:10:50 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,AVAILABLE}
2016-10-12 17:10:50 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,AVAILABLE}
2016-10-12 17:10:50 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,AVAILABLE}
2016-10-12 17:10:50 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,AVAILABLE}
2016-10-12 17:10:50 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1643d68f{/storage,null,AVAILABLE}
2016-10-12 17:10:50 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,AVAILABLE}
2016-10-12 17:10:50 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,AVAILABLE}
2016-10-12 17:10:50 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,AVAILABLE}
2016-10-12 17:10:50 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4052274f{/environment,null,AVAILABLE}
2016-10-12 17:10:50 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,AVAILABLE}
2016-10-12 17:10:50 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@297ea53a{/executors,null,AVAILABLE}
2016-10-12 17:10:50 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,AVAILABLE}
2016-10-12 17:10:50 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,AVAILABLE}
2016-10-12 17:10:50 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,AVAILABLE}
2016-10-12 17:10:50 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a7471ce{/static,null,AVAILABLE}
2016-10-12 17:10:50 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@28276e50{/,null,AVAILABLE}
2016-10-12 17:10:50 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@62e70ea3{/api,null,AVAILABLE}
2016-10-12 17:10:50 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,AVAILABLE}
2016-10-12 17:10:50 INFO  ServerConnector:266 - Started ServerConnector@64337702{HTTP/1.1}{0.0.0.0:4040}
2016-10-12 17:10:50 INFO  Server:379 - Started @1624ms
2016-10-12 17:10:50 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2016-10-12 17:10:50 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://150.212.30.95:4040
2016-10-12 17:10:50 INFO  SparkContext:54 - Added JAR file:/home/aadu/Repos/adam/adam-assembly/target/adam_2.11-0.19.1-SNAPSHOT.jar at spark://150.212.30.95:43783/jars/adam_2.11-0.19.1-SNAPSHOT.jar with timestamp 1476306650871
2016-10-12 17:10:50 INFO  SparkContext:54 - Added JAR file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/a1.jar at spark://150.212.30.95:43783/jars/a1.jar with timestamp 1476306650873
2016-10-12 17:10:50 INFO  Executor:54 - Starting executor ID driver on host localhost
2016-10-12 17:10:50 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40977.
2016-10-12 17:10:50 INFO  NettyBlockTransferService:54 - Server created on 150.212.30.95:40977
2016-10-12 17:10:50 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 150.212.30.95, 40977)
2016-10-12 17:10:50 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 150.212.30.95:40977 with 366.3 MB RAM, BlockManagerId(driver, 150.212.30.95, 40977)
2016-10-12 17:10:50 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 150.212.30.95, 40977)
2016-10-12 17:10:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@199e4c2b{/metrics/json,null,AVAILABLE}
2016-10-12 17:10:51 INFO  ADAMContext:1336 - Loading /home/aadu/Repos/School-Work/2065/assignment1/small.adam as Parquet containing Genotypes. Sequence dictionary for translation is ignored.
2016-10-12 17:10:51 INFO  ADAMContext:257 - Reading the ADAM file at /home/aadu/Repos/School-Work/2065/assignment1/small.adam to create RDD
2016-10-12 17:10:51 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 268.7 KB, free 366.0 MB)
2016-10-12 17:10:52 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 22.8 KB, free 366.0 MB)
2016-10-12 17:10:52 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 150.212.30.95:40977 (size: 22.8 KB, free: 366.3 MB)
2016-10-12 17:10:52 INFO  SparkContext:54 - Created broadcast 0 from newAPIHadoopFile at ADAMContext.scala:271
2016-10-12 17:10:52 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2016-10-12 17:10:52 INFO  ServerConnector:306 - Stopped ServerConnector@64337702{HTTP/1.1}{0.0.0.0:4040}
2016-10-12 17:10:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,UNAVAILABLE}
2016-10-12 17:10:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@62e70ea3{/api,null,UNAVAILABLE}
2016-10-12 17:10:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@28276e50{/,null,UNAVAILABLE}
2016-10-12 17:10:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a7471ce{/static,null,UNAVAILABLE}
2016-10-12 17:10:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,UNAVAILABLE}
2016-10-12 17:10:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,UNAVAILABLE}
2016-10-12 17:10:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,UNAVAILABLE}
2016-10-12 17:10:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@297ea53a{/executors,null,UNAVAILABLE}
2016-10-12 17:10:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,UNAVAILABLE}
2016-10-12 17:10:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4052274f{/environment,null,UNAVAILABLE}
2016-10-12 17:10:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,UNAVAILABLE}
2016-10-12 17:10:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,UNAVAILABLE}
2016-10-12 17:10:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,UNAVAILABLE}
2016-10-12 17:10:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1643d68f{/storage,null,UNAVAILABLE}
2016-10-12 17:10:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,UNAVAILABLE}
2016-10-12 17:10:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,UNAVAILABLE}
2016-10-12 17:10:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,UNAVAILABLE}
2016-10-12 17:10:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,UNAVAILABLE}
2016-10-12 17:10:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,UNAVAILABLE}
2016-10-12 17:10:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,UNAVAILABLE}
2016-10-12 17:10:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,UNAVAILABLE}
2016-10-12 17:10:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,UNAVAILABLE}
2016-10-12 17:10:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,UNAVAILABLE}
2016-10-12 17:10:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,UNAVAILABLE}
2016-10-12 17:10:52 INFO  SparkUI:54 - Stopped Spark web UI at http://150.212.30.95:4040
2016-10-12 17:10:52 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2016-10-12 17:10:52 INFO  MemoryStore:54 - MemoryStore cleared
2016-10-12 17:10:52 INFO  BlockManager:54 - BlockManager stopped
2016-10-12 17:10:52 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2016-10-12 17:10:52 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2016-10-12 17:10:52 INFO  SparkContext:54 - Successfully stopped SparkContext
2016-10-12 17:10:52 INFO  ShutdownHookManager:54 - Shutdown hook called
2016-10-12 17:10:52 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-6fa98450-8109-491a-b641-36e8a08701f6
2016-10-12 17:12:38 INFO  SparkContext:54 - Running Spark version 2.0.0
2016-10-12 17:12:38 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-12 17:12:38 WARN  Utils:66 - Your hostname, aadu-XPS-13-9350 resolves to a loopback address: 127.0.1.1; using 150.212.30.95 instead (on interface wlp58s0)
2016-10-12 17:12:38 WARN  Utils:66 - Set SPARK_LOCAL_IP if you need to bind to another address
2016-10-12 17:12:38 INFO  SecurityManager:54 - Changing view acls to: aadu
2016-10-12 17:12:38 INFO  SecurityManager:54 - Changing modify acls to: aadu
2016-10-12 17:12:38 INFO  SecurityManager:54 - Changing view acls groups to: 
2016-10-12 17:12:38 INFO  SecurityManager:54 - Changing modify acls groups to: 
2016-10-12 17:12:38 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(aadu); groups with view permissions: Set(); users  with modify permissions: Set(aadu); groups with modify permissions: Set()
2016-10-12 17:12:38 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 36619.
2016-10-12 17:12:39 INFO  SparkEnv:54 - Registering MapOutputTracker
2016-10-12 17:12:39 INFO  SparkEnv:54 - Registering BlockManagerMaster
2016-10-12 17:12:39 INFO  DiskBlockManager:54 - Created local directory at /tmp/blockmgr-b4306444-ac43-440c-87c3-3a1142d66227
2016-10-12 17:12:39 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2016-10-12 17:12:39 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2016-10-12 17:12:39 INFO  log:186 - Logging initialized @1501ms
2016-10-12 17:12:39 INFO  Server:327 - jetty-9.2.z-SNAPSHOT
2016-10-12 17:12:39 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,AVAILABLE}
2016-10-12 17:12:39 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,AVAILABLE}
2016-10-12 17:12:39 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,AVAILABLE}
2016-10-12 17:12:39 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,AVAILABLE}
2016-10-12 17:12:39 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,AVAILABLE}
2016-10-12 17:12:39 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,AVAILABLE}
2016-10-12 17:12:39 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,AVAILABLE}
2016-10-12 17:12:39 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,AVAILABLE}
2016-10-12 17:12:39 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,AVAILABLE}
2016-10-12 17:12:39 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,AVAILABLE}
2016-10-12 17:12:39 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1643d68f{/storage,null,AVAILABLE}
2016-10-12 17:12:39 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,AVAILABLE}
2016-10-12 17:12:39 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,AVAILABLE}
2016-10-12 17:12:39 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,AVAILABLE}
2016-10-12 17:12:39 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4052274f{/environment,null,AVAILABLE}
2016-10-12 17:12:39 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,AVAILABLE}
2016-10-12 17:12:39 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@297ea53a{/executors,null,AVAILABLE}
2016-10-12 17:12:39 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,AVAILABLE}
2016-10-12 17:12:39 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,AVAILABLE}
2016-10-12 17:12:39 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,AVAILABLE}
2016-10-12 17:12:39 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a7471ce{/static,null,AVAILABLE}
2016-10-12 17:12:39 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@28276e50{/,null,AVAILABLE}
2016-10-12 17:12:39 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@62e70ea3{/api,null,AVAILABLE}
2016-10-12 17:12:39 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,AVAILABLE}
2016-10-12 17:12:39 INFO  ServerConnector:266 - Started ServerConnector@64337702{HTTP/1.1}{0.0.0.0:4040}
2016-10-12 17:12:39 INFO  Server:379 - Started @1623ms
2016-10-12 17:12:39 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2016-10-12 17:12:39 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://150.212.30.95:4040
2016-10-12 17:12:39 INFO  SparkContext:54 - Added JAR file:/home/aadu/Repos/adam/adam-assembly/target/adam_2.11-0.19.1-SNAPSHOT.jar at spark://150.212.30.95:36619/jars/adam_2.11-0.19.1-SNAPSHOT.jar with timestamp 1476306759325
2016-10-12 17:12:39 INFO  SparkContext:54 - Added JAR file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/a1.jar at spark://150.212.30.95:36619/jars/a1.jar with timestamp 1476306759327
2016-10-12 17:12:39 INFO  Executor:54 - Starting executor ID driver on host localhost
2016-10-12 17:12:39 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36285.
2016-10-12 17:12:39 INFO  NettyBlockTransferService:54 - Server created on 150.212.30.95:36285
2016-10-12 17:12:39 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 150.212.30.95, 36285)
2016-10-12 17:12:39 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 150.212.30.95:36285 with 366.3 MB RAM, BlockManagerId(driver, 150.212.30.95, 36285)
2016-10-12 17:12:39 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 150.212.30.95, 36285)
2016-10-12 17:12:39 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@27f0ad19{/metrics/json,null,AVAILABLE}
2016-10-12 17:12:39 INFO  ADAMContext:1336 - Loading small.adam as Parquet containing Genotypes. Sequence dictionary for translation is ignored.
2016-10-12 17:12:39 INFO  ADAMContext:257 - Reading the ADAM file at small.adam to create RDD
2016-10-12 17:12:40 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 268.7 KB, free 366.0 MB)
2016-10-12 17:12:40 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 22.8 KB, free 366.0 MB)
2016-10-12 17:12:40 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 150.212.30.95:36285 (size: 22.8 KB, free: 366.3 MB)
2016-10-12 17:12:40 INFO  SparkContext:54 - Created broadcast 0 from newAPIHadoopFile at ADAMContext.scala:271
2016-10-12 17:12:40 INFO  FileInputFormat:283 - Total input paths to process : 1
2016-10-12 17:12:40 INFO  SparkContext:54 - Starting job: count at a1.scala:30
2016-10-12 17:12:40 INFO  DAGScheduler:54 - Registering RDD 3 (distinct at a1.scala:30)
2016-10-12 17:12:40 INFO  DAGScheduler:54 - Got job 0 (count at a1.scala:30) with 1 output partitions
2016-10-12 17:12:40 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (count at a1.scala:30)
2016-10-12 17:12:40 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 0)
2016-10-12 17:12:40 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 0)
2016-10-12 17:12:40 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at distinct at a1.scala:30), which has no missing parents
2016-10-12 17:12:41 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 4.2 KB, free 366.0 MB)
2016-10-12 17:12:41 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.5 KB, free 366.0 MB)
2016-10-12 17:12:41 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 150.212.30.95:36285 (size: 2.5 KB, free: 366.3 MB)
2016-10-12 17:12:41 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1012
2016-10-12 17:12:41 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at distinct at a1.scala:30)
2016-10-12 17:12:41 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2016-10-12 17:12:41 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5507 bytes)
2016-10-12 17:12:41 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2016-10-12 17:12:41 INFO  Executor:54 - Fetching spark://150.212.30.95:36619/jars/adam_2.11-0.19.1-SNAPSHOT.jar with timestamp 1476306759325
2016-10-12 17:12:41 INFO  TransportClientFactory:250 - Successfully created connection to /150.212.30.95:36619 after 34 ms (0 ms spent in bootstraps)
2016-10-12 17:12:41 INFO  Utils:54 - Fetching spark://150.212.30.95:36619/jars/adam_2.11-0.19.1-SNAPSHOT.jar to /tmp/spark-eb9fcfcc-256d-4cb4-b05a-23abe974c279/userFiles-71b74677-2d12-4b72-a228-846625cfe2ce/fetchFileTemp1407447994301219995.tmp
2016-10-12 17:12:41 INFO  Executor:54 - Adding file:/tmp/spark-eb9fcfcc-256d-4cb4-b05a-23abe974c279/userFiles-71b74677-2d12-4b72-a228-846625cfe2ce/adam_2.11-0.19.1-SNAPSHOT.jar to class loader
2016-10-12 17:12:41 INFO  Executor:54 - Fetching spark://150.212.30.95:36619/jars/a1.jar with timestamp 1476306759327
2016-10-12 17:12:41 INFO  Utils:54 - Fetching spark://150.212.30.95:36619/jars/a1.jar to /tmp/spark-eb9fcfcc-256d-4cb4-b05a-23abe974c279/userFiles-71b74677-2d12-4b72-a228-846625cfe2ce/fetchFileTemp4438104297438817887.tmp
2016-10-12 17:12:41 INFO  Executor:54 - Adding file:/tmp/spark-eb9fcfcc-256d-4cb4-b05a-23abe974c279/userFiles-71b74677-2d12-4b72-a228-846625cfe2ce/a1.jar to class loader
2016-10-12 17:12:41 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 17:12:41 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 17:12:45 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1490 bytes result sent to driver
2016-10-12 17:12:45 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 4433 ms on localhost (1/1)
2016-10-12 17:12:45 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2016-10-12 17:12:45 INFO  DAGScheduler:54 - ShuffleMapStage 0 (distinct at a1.scala:30) finished in 4.449 s
2016-10-12 17:12:45 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 17:12:45 INFO  DAGScheduler:54 - running: Set()
2016-10-12 17:12:45 INFO  DAGScheduler:54 - waiting: Set(ResultStage 1)
2016-10-12 17:12:45 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 17:12:45 INFO  DAGScheduler:54 - Submitting ResultStage 1 (MapPartitionsRDD[5] at distinct at a1.scala:30), which has no missing parents
2016-10-12 17:12:45 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 3.7 KB, free 366.0 MB)
2016-10-12 17:12:45 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.2 KB, free 366.0 MB)
2016-10-12 17:12:45 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on 150.212.30.95:36285 (size: 2.2 KB, free: 366.3 MB)
2016-10-12 17:12:45 INFO  SparkContext:54 - Created broadcast 2 from broadcast at DAGScheduler.scala:1012
2016-10-12 17:12:45 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at distinct at a1.scala:30)
2016-10-12 17:12:45 INFO  TaskSchedulerImpl:54 - Adding task set 1.0 with 1 tasks
2016-10-12 17:12:45 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, ANY, 5177 bytes)
2016-10-12 17:12:45 INFO  Executor:54 - Running task 0.0 in stage 1.0 (TID 1)
2016-10-12 17:12:45 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 17:12:45 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 4 ms
2016-10-12 17:12:45 INFO  Executor:54 - Finished task 0.0 in stage 1.0 (TID 1). 1512 bytes result sent to driver
2016-10-12 17:12:45 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 1) in 101 ms on localhost (1/1)
2016-10-12 17:12:45 INFO  DAGScheduler:54 - ResultStage 1 (count at a1.scala:30) finished in 0.102 s
2016-10-12 17:12:45 INFO  TaskSchedulerImpl:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2016-10-12 17:12:45 INFO  DAGScheduler:54 - Job 0 finished: count at a1.scala:30, took 4.741847 s
2016-10-12 17:12:45 INFO  SparkContext:54 - Starting job: count at a1.scala:31
2016-10-12 17:12:45 INFO  DAGScheduler:54 - Registering RDD 7 (distinct at a1.scala:31)
2016-10-12 17:12:45 INFO  DAGScheduler:54 - Got job 1 (count at a1.scala:31) with 1 output partitions
2016-10-12 17:12:45 INFO  DAGScheduler:54 - Final stage: ResultStage 3 (count at a1.scala:31)
2016-10-12 17:12:45 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 2)
2016-10-12 17:12:45 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 2)
2016-10-12 17:12:45 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 2 (MapPartitionsRDD[7] at distinct at a1.scala:31), which has no missing parents
2016-10-12 17:12:45 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 4.2 KB, free 366.0 MB)
2016-10-12 17:12:45 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.5 KB, free 366.0 MB)
2016-10-12 17:12:45 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on 150.212.30.95:36285 (size: 2.5 KB, free: 366.3 MB)
2016-10-12 17:12:45 INFO  SparkContext:54 - Created broadcast 3 from broadcast at DAGScheduler.scala:1012
2016-10-12 17:12:45 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[7] at distinct at a1.scala:31)
2016-10-12 17:12:45 INFO  TaskSchedulerImpl:54 - Adding task set 2.0 with 1 tasks
2016-10-12 17:12:45 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5507 bytes)
2016-10-12 17:12:45 INFO  Executor:54 - Running task 0.0 in stage 2.0 (TID 2)
2016-10-12 17:12:45 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 17:12:45 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 17:12:46 INFO  ContextCleaner:54 - Cleaned shuffle 0
2016-10-12 17:12:46 INFO  BlockManagerInfo:54 - Removed broadcast_1_piece0 on 150.212.30.95:36285 in memory (size: 2.5 KB, free: 366.3 MB)
2016-10-12 17:12:46 INFO  BlockManagerInfo:54 - Removed broadcast_2_piece0 on 150.212.30.95:36285 in memory (size: 2.2 KB, free: 366.3 MB)
2016-10-12 17:12:49 INFO  Executor:54 - Finished task 0.0 in stage 2.0 (TID 2). 1490 bytes result sent to driver
2016-10-12 17:12:49 INFO  TaskSetManager:54 - Finished task 0.0 in stage 2.0 (TID 2) in 3354 ms on localhost (1/1)
2016-10-12 17:12:49 INFO  DAGScheduler:54 - ShuffleMapStage 2 (distinct at a1.scala:31) finished in 3.355 s
2016-10-12 17:12:49 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 17:12:49 INFO  DAGScheduler:54 - running: Set()
2016-10-12 17:12:49 INFO  DAGScheduler:54 - waiting: Set(ResultStage 3)
2016-10-12 17:12:49 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 17:12:49 INFO  DAGScheduler:54 - Submitting ResultStage 3 (MapPartitionsRDD[9] at distinct at a1.scala:31), which has no missing parents
2016-10-12 17:12:49 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 3.8 KB, free 366.0 MB)
2016-10-12 17:12:49 INFO  TaskSchedulerImpl:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2016-10-12 17:12:49 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.2 KB, free 366.0 MB)
2016-10-12 17:12:49 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on 150.212.30.95:36285 (size: 2.2 KB, free: 366.3 MB)
2016-10-12 17:12:49 INFO  SparkContext:54 - Created broadcast 4 from broadcast at DAGScheduler.scala:1012
2016-10-12 17:12:49 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[9] at distinct at a1.scala:31)
2016-10-12 17:12:49 INFO  TaskSchedulerImpl:54 - Adding task set 3.0 with 1 tasks
2016-10-12 17:12:49 INFO  TaskSetManager:54 - Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, ANY, 5177 bytes)
2016-10-12 17:12:49 INFO  Executor:54 - Running task 0.0 in stage 3.0 (TID 3)
2016-10-12 17:12:49 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 17:12:49 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 2 ms
2016-10-12 17:12:49 INFO  Executor:54 - Finished task 0.0 in stage 3.0 (TID 3). 1512 bytes result sent to driver
2016-10-12 17:12:49 INFO  DAGScheduler:54 - ResultStage 3 (count at a1.scala:31) finished in 0.067 s
2016-10-12 17:12:49 INFO  DAGScheduler:54 - Job 1 finished: count at a1.scala:31, took 3.476805 s
2016-10-12 17:12:49 INFO  TaskSetManager:54 - Finished task 0.0 in stage 3.0 (TID 3) in 66 ms on localhost (1/1)
2016-10-12 17:12:49 INFO  TaskSchedulerImpl:54 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2016-10-12 17:12:49 INFO  SparkContext:54 - Starting job: count at a1.scala:32
2016-10-12 17:12:49 INFO  DAGScheduler:54 - Registering RDD 10 (map at a1.scala:32)
2016-10-12 17:12:49 INFO  DAGScheduler:54 - Got job 2 (count at a1.scala:32) with 1 output partitions
2016-10-12 17:12:49 INFO  DAGScheduler:54 - Final stage: ResultStage 5 (count at a1.scala:32)
2016-10-12 17:12:49 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 4)
2016-10-12 17:12:49 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 4)
2016-10-12 17:12:49 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 4 (MapPartitionsRDD[10] at map at a1.scala:32), which has no missing parents
2016-10-12 17:12:49 INFO  MemoryStore:54 - Block broadcast_5 stored as values in memory (estimated size 4.0 KB, free 366.0 MB)
2016-10-12 17:12:49 INFO  MemoryStore:54 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.4 KB, free 366.0 MB)
2016-10-12 17:12:49 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on 150.212.30.95:36285 (size: 2.4 KB, free: 366.3 MB)
2016-10-12 17:12:49 INFO  SparkContext:54 - Created broadcast 5 from broadcast at DAGScheduler.scala:1012
2016-10-12 17:12:49 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[10] at map at a1.scala:32)
2016-10-12 17:12:49 INFO  TaskSchedulerImpl:54 - Adding task set 4.0 with 1 tasks
2016-10-12 17:12:49 INFO  TaskSetManager:54 - Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5507 bytes)
2016-10-12 17:12:49 INFO  Executor:54 - Running task 0.0 in stage 4.0 (TID 4)
2016-10-12 17:12:49 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 17:12:49 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 17:12:49 INFO  ContextCleaner:54 - Cleaned shuffle 1
2016-10-12 17:12:49 INFO  BlockManagerInfo:54 - Removed broadcast_3_piece0 on 150.212.30.95:36285 in memory (size: 2.5 KB, free: 366.3 MB)
2016-10-12 17:12:49 INFO  BlockManagerInfo:54 - Removed broadcast_4_piece0 on 150.212.30.95:36285 in memory (size: 2.2 KB, free: 366.3 MB)
2016-10-12 17:12:52 INFO  Executor:54 - Finished task 0.0 in stage 4.0 (TID 4). 1490 bytes result sent to driver
2016-10-12 17:12:52 INFO  TaskSetManager:54 - Finished task 0.0 in stage 4.0 (TID 4) in 3251 ms on localhost (1/1)
2016-10-12 17:12:52 INFO  DAGScheduler:54 - ShuffleMapStage 4 (map at a1.scala:32) finished in 3.250 s
2016-10-12 17:12:52 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 17:12:52 INFO  TaskSchedulerImpl:54 - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2016-10-12 17:12:52 INFO  DAGScheduler:54 - running: Set()
2016-10-12 17:12:52 INFO  DAGScheduler:54 - waiting: Set(ResultStage 5)
2016-10-12 17:12:52 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 17:12:52 INFO  DAGScheduler:54 - Submitting ResultStage 5 (MapPartitionsRDD[12] at filter at a1.scala:32), which has no missing parents
2016-10-12 17:12:52 INFO  MemoryStore:54 - Block broadcast_6 stored as values in memory (estimated size 3.5 KB, free 366.0 MB)
2016-10-12 17:12:52 INFO  MemoryStore:54 - Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.0 MB)
2016-10-12 17:12:52 INFO  BlockManagerInfo:54 - Added broadcast_6_piece0 in memory on 150.212.30.95:36285 (size: 2.1 KB, free: 366.3 MB)
2016-10-12 17:12:52 INFO  SparkContext:54 - Created broadcast 6 from broadcast at DAGScheduler.scala:1012
2016-10-12 17:12:52 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[12] at filter at a1.scala:32)
2016-10-12 17:12:52 INFO  TaskSchedulerImpl:54 - Adding task set 5.0 with 1 tasks
2016-10-12 17:12:52 INFO  TaskSetManager:54 - Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, ANY, 5177 bytes)
2016-10-12 17:12:52 INFO  Executor:54 - Running task 0.0 in stage 5.0 (TID 5)
2016-10-12 17:12:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 17:12:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2016-10-12 17:12:52 INFO  Executor:54 - Finished task 0.0 in stage 5.0 (TID 5). 1512 bytes result sent to driver
2016-10-12 17:12:52 INFO  TaskSetManager:54 - Finished task 0.0 in stage 5.0 (TID 5) in 47 ms on localhost (1/1)
2016-10-12 17:12:52 INFO  TaskSchedulerImpl:54 - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2016-10-12 17:12:52 INFO  DAGScheduler:54 - ResultStage 5 (count at a1.scala:32) finished in 0.046 s
2016-10-12 17:12:52 INFO  DAGScheduler:54 - Job 2 finished: count at a1.scala:32, took 3.365954 s
2016-10-12 17:12:52 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2016-10-12 17:12:52 INFO  ServerConnector:306 - Stopped ServerConnector@64337702{HTTP/1.1}{0.0.0.0:4040}
2016-10-12 17:12:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,UNAVAILABLE}
2016-10-12 17:12:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@62e70ea3{/api,null,UNAVAILABLE}
2016-10-12 17:12:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@28276e50{/,null,UNAVAILABLE}
2016-10-12 17:12:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a7471ce{/static,null,UNAVAILABLE}
2016-10-12 17:12:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,UNAVAILABLE}
2016-10-12 17:12:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,UNAVAILABLE}
2016-10-12 17:12:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,UNAVAILABLE}
2016-10-12 17:12:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@297ea53a{/executors,null,UNAVAILABLE}
2016-10-12 17:12:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,UNAVAILABLE}
2016-10-12 17:12:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4052274f{/environment,null,UNAVAILABLE}
2016-10-12 17:12:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,UNAVAILABLE}
2016-10-12 17:12:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,UNAVAILABLE}
2016-10-12 17:12:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,UNAVAILABLE}
2016-10-12 17:12:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1643d68f{/storage,null,UNAVAILABLE}
2016-10-12 17:12:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,UNAVAILABLE}
2016-10-12 17:12:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,UNAVAILABLE}
2016-10-12 17:12:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,UNAVAILABLE}
2016-10-12 17:12:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,UNAVAILABLE}
2016-10-12 17:12:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,UNAVAILABLE}
2016-10-12 17:12:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,UNAVAILABLE}
2016-10-12 17:12:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,UNAVAILABLE}
2016-10-12 17:12:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,UNAVAILABLE}
2016-10-12 17:12:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,UNAVAILABLE}
2016-10-12 17:12:52 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,UNAVAILABLE}
2016-10-12 17:12:52 INFO  SparkUI:54 - Stopped Spark web UI at http://150.212.30.95:4040
2016-10-12 17:12:52 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2016-10-12 17:12:52 INFO  MemoryStore:54 - MemoryStore cleared
2016-10-12 17:12:52 INFO  BlockManager:54 - BlockManager stopped
2016-10-12 17:12:52 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2016-10-12 17:12:52 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2016-10-12 17:12:52 INFO  SparkContext:54 - Successfully stopped SparkContext
2016-10-12 17:12:52 INFO  ShutdownHookManager:54 - Shutdown hook called
2016-10-12 17:12:52 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-eb9fcfcc-256d-4cb4-b05a-23abe974c279
2016-10-12 17:13:35 INFO  SparkContext:54 - Running Spark version 2.0.0
2016-10-12 17:13:35 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-12 17:13:35 WARN  Utils:66 - Your hostname, aadu-XPS-13-9350 resolves to a loopback address: 127.0.1.1; using 150.212.30.95 instead (on interface wlp58s0)
2016-10-12 17:13:35 WARN  Utils:66 - Set SPARK_LOCAL_IP if you need to bind to another address
2016-10-12 17:13:35 INFO  SecurityManager:54 - Changing view acls to: aadu
2016-10-12 17:13:35 INFO  SecurityManager:54 - Changing modify acls to: aadu
2016-10-12 17:13:35 INFO  SecurityManager:54 - Changing view acls groups to: 
2016-10-12 17:13:35 INFO  SecurityManager:54 - Changing modify acls groups to: 
2016-10-12 17:13:35 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(aadu); groups with view permissions: Set(); users  with modify permissions: Set(aadu); groups with modify permissions: Set()
2016-10-12 17:13:35 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 45534.
2016-10-12 17:13:35 INFO  SparkEnv:54 - Registering MapOutputTracker
2016-10-12 17:13:35 INFO  SparkEnv:54 - Registering BlockManagerMaster
2016-10-12 17:13:35 INFO  DiskBlockManager:54 - Created local directory at /tmp/blockmgr-c113b64b-6f2c-4b39-ac48-dc42d0c03b2a
2016-10-12 17:13:35 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2016-10-12 17:13:36 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2016-10-12 17:13:36 INFO  log:186 - Logging initialized @1765ms
2016-10-12 17:13:36 INFO  Server:327 - jetty-9.2.z-SNAPSHOT
2016-10-12 17:13:36 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,AVAILABLE}
2016-10-12 17:13:36 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,AVAILABLE}
2016-10-12 17:13:36 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,AVAILABLE}
2016-10-12 17:13:36 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,AVAILABLE}
2016-10-12 17:13:36 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,AVAILABLE}
2016-10-12 17:13:36 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,AVAILABLE}
2016-10-12 17:13:36 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,AVAILABLE}
2016-10-12 17:13:36 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,AVAILABLE}
2016-10-12 17:13:36 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,AVAILABLE}
2016-10-12 17:13:36 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,AVAILABLE}
2016-10-12 17:13:36 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1643d68f{/storage,null,AVAILABLE}
2016-10-12 17:13:36 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,AVAILABLE}
2016-10-12 17:13:36 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,AVAILABLE}
2016-10-12 17:13:36 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,AVAILABLE}
2016-10-12 17:13:36 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4052274f{/environment,null,AVAILABLE}
2016-10-12 17:13:36 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,AVAILABLE}
2016-10-12 17:13:36 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@297ea53a{/executors,null,AVAILABLE}
2016-10-12 17:13:36 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,AVAILABLE}
2016-10-12 17:13:36 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,AVAILABLE}
2016-10-12 17:13:36 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,AVAILABLE}
2016-10-12 17:13:36 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a7471ce{/static,null,AVAILABLE}
2016-10-12 17:13:36 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@28276e50{/,null,AVAILABLE}
2016-10-12 17:13:36 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@62e70ea3{/api,null,AVAILABLE}
2016-10-12 17:13:36 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,AVAILABLE}
2016-10-12 17:13:36 INFO  ServerConnector:266 - Started ServerConnector@64337702{HTTP/1.1}{0.0.0.0:4040}
2016-10-12 17:13:36 INFO  Server:379 - Started @1865ms
2016-10-12 17:13:36 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2016-10-12 17:13:36 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://150.212.30.95:4040
2016-10-12 17:13:36 INFO  SparkContext:54 - Added JAR file:/home/aadu/Repos/adam/adam-assembly/target/adam_2.11-0.19.1-SNAPSHOT.jar at spark://150.212.30.95:45534/jars/adam_2.11-0.19.1-SNAPSHOT.jar with timestamp 1476306816239
2016-10-12 17:13:36 INFO  SparkContext:54 - Added JAR file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/a1.jar at spark://150.212.30.95:45534/jars/a1.jar with timestamp 1476306816241
2016-10-12 17:13:36 INFO  Executor:54 - Starting executor ID driver on host localhost
2016-10-12 17:13:36 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36728.
2016-10-12 17:13:36 INFO  NettyBlockTransferService:54 - Server created on 150.212.30.95:36728
2016-10-12 17:13:36 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 150.212.30.95, 36728)
2016-10-12 17:13:36 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 150.212.30.95:36728 with 366.3 MB RAM, BlockManagerId(driver, 150.212.30.95, 36728)
2016-10-12 17:13:36 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 150.212.30.95, 36728)
2016-10-12 17:13:36 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@199e4c2b{/metrics/json,null,AVAILABLE}
2016-10-12 17:13:36 INFO  ADAMContext:1336 - Loading small.adam as Parquet containing Genotypes. Sequence dictionary for translation is ignored.
2016-10-12 17:13:36 INFO  ADAMContext:257 - Reading the ADAM file at small.adam to create RDD
2016-10-12 17:13:37 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 268.7 KB, free 366.0 MB)
2016-10-12 17:13:38 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 22.8 KB, free 366.0 MB)
2016-10-12 17:13:38 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 150.212.30.95:36728 (size: 22.8 KB, free: 366.3 MB)
2016-10-12 17:13:38 INFO  SparkContext:54 - Created broadcast 0 from newAPIHadoopFile at ADAMContext.scala:271
2016-10-12 17:13:38 INFO  FileInputFormat:283 - Total input paths to process : 1
2016-10-12 17:13:38 INFO  SparkContext:54 - Starting job: count at a1.scala:30
2016-10-12 17:13:38 INFO  DAGScheduler:54 - Registering RDD 3 (distinct at a1.scala:30)
2016-10-12 17:13:38 INFO  DAGScheduler:54 - Got job 0 (count at a1.scala:30) with 1 output partitions
2016-10-12 17:13:38 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (count at a1.scala:30)
2016-10-12 17:13:38 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 0)
2016-10-12 17:13:38 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 0)
2016-10-12 17:13:38 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at distinct at a1.scala:30), which has no missing parents
2016-10-12 17:13:38 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 4.2 KB, free 366.0 MB)
2016-10-12 17:13:38 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.5 KB, free 366.0 MB)
2016-10-12 17:13:38 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 150.212.30.95:36728 (size: 2.5 KB, free: 366.3 MB)
2016-10-12 17:13:38 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1012
2016-10-12 17:13:38 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at distinct at a1.scala:30)
2016-10-12 17:13:38 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2016-10-12 17:13:38 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5507 bytes)
2016-10-12 17:13:38 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2016-10-12 17:13:38 INFO  Executor:54 - Fetching spark://150.212.30.95:45534/jars/a1.jar with timestamp 1476306816241
2016-10-12 17:13:38 INFO  TransportClientFactory:250 - Successfully created connection to /150.212.30.95:45534 after 51 ms (0 ms spent in bootstraps)
2016-10-12 17:13:38 INFO  Utils:54 - Fetching spark://150.212.30.95:45534/jars/a1.jar to /tmp/spark-05fcf695-3b06-44be-b73a-583329b06156/userFiles-8f5d4dbb-ce1a-4993-9eaa-4b32a079770a/fetchFileTemp7898516234388733588.tmp
2016-10-12 17:13:39 INFO  Executor:54 - Adding file:/tmp/spark-05fcf695-3b06-44be-b73a-583329b06156/userFiles-8f5d4dbb-ce1a-4993-9eaa-4b32a079770a/a1.jar to class loader
2016-10-12 17:13:39 INFO  Executor:54 - Fetching spark://150.212.30.95:45534/jars/adam_2.11-0.19.1-SNAPSHOT.jar with timestamp 1476306816239
2016-10-12 17:13:39 INFO  Utils:54 - Fetching spark://150.212.30.95:45534/jars/adam_2.11-0.19.1-SNAPSHOT.jar to /tmp/spark-05fcf695-3b06-44be-b73a-583329b06156/userFiles-8f5d4dbb-ce1a-4993-9eaa-4b32a079770a/fetchFileTemp2625850315946394103.tmp
2016-10-12 17:13:39 INFO  Executor:54 - Adding file:/tmp/spark-05fcf695-3b06-44be-b73a-583329b06156/userFiles-8f5d4dbb-ce1a-4993-9eaa-4b32a079770a/adam_2.11-0.19.1-SNAPSHOT.jar to class loader
2016-10-12 17:13:39 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 17:13:39 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 17:13:43 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1490 bytes result sent to driver
2016-10-12 17:13:43 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 4864 ms on localhost (1/1)
2016-10-12 17:13:43 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2016-10-12 17:13:43 INFO  DAGScheduler:54 - ShuffleMapStage 0 (distinct at a1.scala:30) finished in 4.883 s
2016-10-12 17:13:43 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 17:13:43 INFO  DAGScheduler:54 - running: Set()
2016-10-12 17:13:43 INFO  DAGScheduler:54 - waiting: Set(ResultStage 1)
2016-10-12 17:13:43 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 17:13:43 INFO  DAGScheduler:54 - Submitting ResultStage 1 (MapPartitionsRDD[5] at distinct at a1.scala:30), which has no missing parents
2016-10-12 17:13:43 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 3.7 KB, free 366.0 MB)
2016-10-12 17:13:43 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.2 KB, free 366.0 MB)
2016-10-12 17:13:43 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on 150.212.30.95:36728 (size: 2.2 KB, free: 366.3 MB)
2016-10-12 17:13:43 INFO  SparkContext:54 - Created broadcast 2 from broadcast at DAGScheduler.scala:1012
2016-10-12 17:13:43 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at distinct at a1.scala:30)
2016-10-12 17:13:43 INFO  TaskSchedulerImpl:54 - Adding task set 1.0 with 1 tasks
2016-10-12 17:13:43 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, ANY, 5177 bytes)
2016-10-12 17:13:43 INFO  Executor:54 - Running task 0.0 in stage 1.0 (TID 1)
2016-10-12 17:13:43 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 17:13:43 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 4 ms
2016-10-12 17:13:43 INFO  Executor:54 - Finished task 0.0 in stage 1.0 (TID 1). 1512 bytes result sent to driver
2016-10-12 17:13:43 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 1) in 89 ms on localhost (1/1)
2016-10-12 17:13:43 INFO  DAGScheduler:54 - ResultStage 1 (count at a1.scala:30) finished in 0.087 s
2016-10-12 17:13:43 INFO  TaskSchedulerImpl:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2016-10-12 17:13:43 INFO  DAGScheduler:54 - Job 0 finished: count at a1.scala:30, took 5.242341 s
2016-10-12 17:13:43 INFO  SparkContext:54 - Starting job: count at a1.scala:31
2016-10-12 17:13:43 INFO  DAGScheduler:54 - Registering RDD 7 (distinct at a1.scala:31)
2016-10-12 17:13:43 INFO  DAGScheduler:54 - Got job 1 (count at a1.scala:31) with 1 output partitions
2016-10-12 17:13:43 INFO  DAGScheduler:54 - Final stage: ResultStage 3 (count at a1.scala:31)
2016-10-12 17:13:43 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 2)
2016-10-12 17:13:43 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 2)
2016-10-12 17:13:43 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 2 (MapPartitionsRDD[7] at distinct at a1.scala:31), which has no missing parents
2016-10-12 17:13:43 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 4.2 KB, free 366.0 MB)
2016-10-12 17:13:43 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.5 KB, free 366.0 MB)
2016-10-12 17:13:43 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on 150.212.30.95:36728 (size: 2.5 KB, free: 366.3 MB)
2016-10-12 17:13:43 INFO  SparkContext:54 - Created broadcast 3 from broadcast at DAGScheduler.scala:1012
2016-10-12 17:13:43 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[7] at distinct at a1.scala:31)
2016-10-12 17:13:43 INFO  TaskSchedulerImpl:54 - Adding task set 2.0 with 1 tasks
2016-10-12 17:13:43 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5507 bytes)
2016-10-12 17:13:43 INFO  Executor:54 - Running task 0.0 in stage 2.0 (TID 2)
2016-10-12 17:13:43 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 17:13:43 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 17:13:44 INFO  BlockManagerInfo:54 - Removed broadcast_2_piece0 on 150.212.30.95:36728 in memory (size: 2.2 KB, free: 366.3 MB)
2016-10-12 17:13:47 INFO  Executor:54 - Finished task 0.0 in stage 2.0 (TID 2). 1490 bytes result sent to driver
2016-10-12 17:13:47 INFO  DAGScheduler:54 - ShuffleMapStage 2 (distinct at a1.scala:31) finished in 3.511 s
2016-10-12 17:13:47 INFO  TaskSetManager:54 - Finished task 0.0 in stage 2.0 (TID 2) in 3510 ms on localhost (1/1)
2016-10-12 17:13:47 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 17:13:47 INFO  DAGScheduler:54 - running: Set()
2016-10-12 17:13:47 INFO  DAGScheduler:54 - waiting: Set(ResultStage 3)
2016-10-12 17:13:47 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 17:13:47 INFO  DAGScheduler:54 - Submitting ResultStage 3 (MapPartitionsRDD[9] at distinct at a1.scala:31), which has no missing parents
2016-10-12 17:13:47 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 3.8 KB, free 366.0 MB)
2016-10-12 17:13:47 INFO  TaskSchedulerImpl:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2016-10-12 17:13:47 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.2 KB, free 366.0 MB)
2016-10-12 17:13:47 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on 150.212.30.95:36728 (size: 2.2 KB, free: 366.3 MB)
2016-10-12 17:13:47 INFO  SparkContext:54 - Created broadcast 4 from broadcast at DAGScheduler.scala:1012
2016-10-12 17:13:47 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[9] at distinct at a1.scala:31)
2016-10-12 17:13:47 INFO  TaskSchedulerImpl:54 - Adding task set 3.0 with 1 tasks
2016-10-12 17:13:47 INFO  TaskSetManager:54 - Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, ANY, 5177 bytes)
2016-10-12 17:13:47 INFO  Executor:54 - Running task 0.0 in stage 3.0 (TID 3)
2016-10-12 17:13:47 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 17:13:47 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2016-10-12 17:13:47 INFO  Executor:54 - Finished task 0.0 in stage 3.0 (TID 3). 1512 bytes result sent to driver
2016-10-12 17:13:47 INFO  DAGScheduler:54 - ResultStage 3 (count at a1.scala:31) finished in 0.050 s
2016-10-12 17:13:47 INFO  DAGScheduler:54 - Job 1 finished: count at a1.scala:31, took 3.641061 s
2016-10-12 17:13:47 INFO  TaskSetManager:54 - Finished task 0.0 in stage 3.0 (TID 3) in 51 ms on localhost (1/1)
2016-10-12 17:13:47 INFO  TaskSchedulerImpl:54 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2016-10-12 17:13:47 INFO  SparkContext:54 - Starting job: count at a1.scala:32
2016-10-12 17:13:47 INFO  DAGScheduler:54 - Registering RDD 10 (map at a1.scala:32)
2016-10-12 17:13:47 INFO  DAGScheduler:54 - Got job 2 (count at a1.scala:32) with 1 output partitions
2016-10-12 17:13:47 INFO  DAGScheduler:54 - Final stage: ResultStage 5 (count at a1.scala:32)
2016-10-12 17:13:47 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 4)
2016-10-12 17:13:47 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 4)
2016-10-12 17:13:47 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 4 (MapPartitionsRDD[10] at map at a1.scala:32), which has no missing parents
2016-10-12 17:13:47 INFO  MemoryStore:54 - Block broadcast_5 stored as values in memory (estimated size 4.0 KB, free 366.0 MB)
2016-10-12 17:13:47 INFO  MemoryStore:54 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.4 KB, free 366.0 MB)
2016-10-12 17:13:47 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on 150.212.30.95:36728 (size: 2.4 KB, free: 366.3 MB)
2016-10-12 17:13:47 INFO  SparkContext:54 - Created broadcast 5 from broadcast at DAGScheduler.scala:1012
2016-10-12 17:13:47 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[10] at map at a1.scala:32)
2016-10-12 17:13:47 INFO  TaskSchedulerImpl:54 - Adding task set 4.0 with 1 tasks
2016-10-12 17:13:47 INFO  TaskSetManager:54 - Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5507 bytes)
2016-10-12 17:13:47 INFO  Executor:54 - Running task 0.0 in stage 4.0 (TID 4)
2016-10-12 17:13:47 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 17:13:47 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 17:13:47 INFO  BlockManagerInfo:54 - Removed broadcast_4_piece0 on 150.212.30.95:36728 in memory (size: 2.2 KB, free: 366.3 MB)
2016-10-12 17:13:47 INFO  ContextCleaner:54 - Cleaned shuffle 1
2016-10-12 17:13:47 INFO  BlockManagerInfo:54 - Removed broadcast_3_piece0 on 150.212.30.95:36728 in memory (size: 2.5 KB, free: 366.3 MB)
2016-10-12 17:13:50 INFO  Executor:54 - Finished task 0.0 in stage 4.0 (TID 4). 1490 bytes result sent to driver
2016-10-12 17:13:50 INFO  TaskSetManager:54 - Finished task 0.0 in stage 4.0 (TID 4) in 3154 ms on localhost (1/1)
2016-10-12 17:13:50 INFO  TaskSchedulerImpl:54 - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2016-10-12 17:13:50 INFO  DAGScheduler:54 - ShuffleMapStage 4 (map at a1.scala:32) finished in 3.153 s
2016-10-12 17:13:50 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 17:13:50 INFO  DAGScheduler:54 - running: Set()
2016-10-12 17:13:50 INFO  DAGScheduler:54 - waiting: Set(ResultStage 5)
2016-10-12 17:13:50 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 17:13:50 INFO  DAGScheduler:54 - Submitting ResultStage 5 (MapPartitionsRDD[12] at filter at a1.scala:32), which has no missing parents
2016-10-12 17:13:50 INFO  MemoryStore:54 - Block broadcast_6 stored as values in memory (estimated size 3.5 KB, free 366.0 MB)
2016-10-12 17:13:50 INFO  MemoryStore:54 - Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.0 MB)
2016-10-12 17:13:50 INFO  BlockManagerInfo:54 - Added broadcast_6_piece0 in memory on 150.212.30.95:36728 (size: 2.1 KB, free: 366.3 MB)
2016-10-12 17:13:50 INFO  SparkContext:54 - Created broadcast 6 from broadcast at DAGScheduler.scala:1012
2016-10-12 17:13:50 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[12] at filter at a1.scala:32)
2016-10-12 17:13:50 INFO  TaskSchedulerImpl:54 - Adding task set 5.0 with 1 tasks
2016-10-12 17:13:50 INFO  TaskSetManager:54 - Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, ANY, 5177 bytes)
2016-10-12 17:13:50 INFO  Executor:54 - Running task 0.0 in stage 5.0 (TID 5)
2016-10-12 17:13:50 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 17:13:50 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2016-10-12 17:13:50 INFO  Executor:54 - Finished task 0.0 in stage 5.0 (TID 5). 1512 bytes result sent to driver
2016-10-12 17:13:50 INFO  DAGScheduler:54 - ResultStage 5 (count at a1.scala:32) finished in 0.049 s
2016-10-12 17:13:50 INFO  DAGScheduler:54 - Job 2 finished: count at a1.scala:32, took 3.269726 s
2016-10-12 17:13:50 INFO  TaskSetManager:54 - Finished task 0.0 in stage 5.0 (TID 5) in 51 ms on localhost (1/1)
2016-10-12 17:13:50 INFO  TaskSchedulerImpl:54 - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2016-10-12 17:13:50 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2016-10-12 17:13:50 INFO  ServerConnector:306 - Stopped ServerConnector@64337702{HTTP/1.1}{0.0.0.0:4040}
2016-10-12 17:13:50 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,UNAVAILABLE}
2016-10-12 17:13:50 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@62e70ea3{/api,null,UNAVAILABLE}
2016-10-12 17:13:50 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@28276e50{/,null,UNAVAILABLE}
2016-10-12 17:13:50 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a7471ce{/static,null,UNAVAILABLE}
2016-10-12 17:13:50 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,UNAVAILABLE}
2016-10-12 17:13:50 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,UNAVAILABLE}
2016-10-12 17:13:50 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,UNAVAILABLE}
2016-10-12 17:13:50 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@297ea53a{/executors,null,UNAVAILABLE}
2016-10-12 17:13:50 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,UNAVAILABLE}
2016-10-12 17:13:50 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4052274f{/environment,null,UNAVAILABLE}
2016-10-12 17:13:50 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,UNAVAILABLE}
2016-10-12 17:13:50 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,UNAVAILABLE}
2016-10-12 17:13:50 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,UNAVAILABLE}
2016-10-12 17:13:50 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1643d68f{/storage,null,UNAVAILABLE}
2016-10-12 17:13:50 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,UNAVAILABLE}
2016-10-12 17:13:50 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,UNAVAILABLE}
2016-10-12 17:13:50 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,UNAVAILABLE}
2016-10-12 17:13:50 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,UNAVAILABLE}
2016-10-12 17:13:50 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,UNAVAILABLE}
2016-10-12 17:13:50 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,UNAVAILABLE}
2016-10-12 17:13:50 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,UNAVAILABLE}
2016-10-12 17:13:50 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,UNAVAILABLE}
2016-10-12 17:13:50 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,UNAVAILABLE}
2016-10-12 17:13:50 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,UNAVAILABLE}
2016-10-12 17:13:50 INFO  SparkUI:54 - Stopped Spark web UI at http://150.212.30.95:4040
2016-10-12 17:13:50 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2016-10-12 17:13:50 INFO  MemoryStore:54 - MemoryStore cleared
2016-10-12 17:13:50 INFO  BlockManager:54 - BlockManager stopped
2016-10-12 17:13:50 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2016-10-12 17:13:50 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2016-10-12 17:13:50 INFO  SparkContext:54 - Successfully stopped SparkContext
2016-10-12 17:13:50 INFO  ShutdownHookManager:54 - Shutdown hook called
2016-10-12 17:13:50 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-05fcf695-3b06-44be-b73a-583329b06156
2016-10-12 17:21:42 INFO  SparkContext:54 - Running Spark version 2.0.0
2016-10-12 17:21:42 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-12 17:21:42 WARN  Utils:66 - Your hostname, aadu-XPS-13-9350 resolves to a loopback address: 127.0.1.1; using 150.212.30.95 instead (on interface wlp58s0)
2016-10-12 17:21:42 WARN  Utils:66 - Set SPARK_LOCAL_IP if you need to bind to another address
2016-10-12 17:21:42 INFO  SecurityManager:54 - Changing view acls to: aadu
2016-10-12 17:21:42 INFO  SecurityManager:54 - Changing modify acls to: aadu
2016-10-12 17:21:42 INFO  SecurityManager:54 - Changing view acls groups to: 
2016-10-12 17:21:42 INFO  SecurityManager:54 - Changing modify acls groups to: 
2016-10-12 17:21:42 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(aadu); groups with view permissions: Set(); users  with modify permissions: Set(aadu); groups with modify permissions: Set()
2016-10-12 17:21:43 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 42867.
2016-10-12 17:21:43 INFO  SparkEnv:54 - Registering MapOutputTracker
2016-10-12 17:21:43 INFO  SparkEnv:54 - Registering BlockManagerMaster
2016-10-12 17:21:43 INFO  DiskBlockManager:54 - Created local directory at /tmp/blockmgr-851f58fa-6bda-4ef9-9928-66d7b70b0328
2016-10-12 17:21:43 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2016-10-12 17:21:43 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2016-10-12 17:21:43 INFO  log:186 - Logging initialized @1474ms
2016-10-12 17:21:43 INFO  Server:327 - jetty-9.2.z-SNAPSHOT
2016-10-12 17:21:43 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,AVAILABLE}
2016-10-12 17:21:43 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,AVAILABLE}
2016-10-12 17:21:43 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,AVAILABLE}
2016-10-12 17:21:43 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,AVAILABLE}
2016-10-12 17:21:43 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,AVAILABLE}
2016-10-12 17:21:43 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,AVAILABLE}
2016-10-12 17:21:43 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,AVAILABLE}
2016-10-12 17:21:43 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,AVAILABLE}
2016-10-12 17:21:43 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,AVAILABLE}
2016-10-12 17:21:43 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,AVAILABLE}
2016-10-12 17:21:43 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1643d68f{/storage,null,AVAILABLE}
2016-10-12 17:21:43 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,AVAILABLE}
2016-10-12 17:21:43 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,AVAILABLE}
2016-10-12 17:21:43 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,AVAILABLE}
2016-10-12 17:21:43 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4052274f{/environment,null,AVAILABLE}
2016-10-12 17:21:43 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,AVAILABLE}
2016-10-12 17:21:43 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@297ea53a{/executors,null,AVAILABLE}
2016-10-12 17:21:43 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,AVAILABLE}
2016-10-12 17:21:43 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,AVAILABLE}
2016-10-12 17:21:43 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,AVAILABLE}
2016-10-12 17:21:43 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a7471ce{/static,null,AVAILABLE}
2016-10-12 17:21:43 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@28276e50{/,null,AVAILABLE}
2016-10-12 17:21:43 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@62e70ea3{/api,null,AVAILABLE}
2016-10-12 17:21:43 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,AVAILABLE}
2016-10-12 17:21:43 INFO  ServerConnector:266 - Started ServerConnector@64337702{HTTP/1.1}{0.0.0.0:4040}
2016-10-12 17:21:43 INFO  Server:379 - Started @1583ms
2016-10-12 17:21:43 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2016-10-12 17:21:43 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://150.212.30.95:4040
2016-10-12 17:21:43 INFO  SparkContext:54 - Added JAR file:/home/aadu/Repos/adam/adam-assembly/target/adam_2.11-0.19.1-SNAPSHOT.jar at spark://150.212.30.95:42867/jars/adam_2.11-0.19.1-SNAPSHOT.jar with timestamp 1476307303384
2016-10-12 17:21:43 INFO  SparkContext:54 - Added JAR file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/a1.jar at spark://150.212.30.95:42867/jars/a1.jar with timestamp 1476307303386
2016-10-12 17:21:43 INFO  Executor:54 - Starting executor ID driver on host localhost
2016-10-12 17:21:43 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44036.
2016-10-12 17:21:43 INFO  NettyBlockTransferService:54 - Server created on 150.212.30.95:44036
2016-10-12 17:21:43 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 150.212.30.95, 44036)
2016-10-12 17:21:43 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 150.212.30.95:44036 with 366.3 MB RAM, BlockManagerId(driver, 150.212.30.95, 44036)
2016-10-12 17:21:43 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 150.212.30.95, 44036)
2016-10-12 17:21:43 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@199e4c2b{/metrics/json,null,AVAILABLE}
2016-10-12 17:21:43 INFO  ADAMContext:1336 - Loading small.adam as Parquet containing Genotypes. Sequence dictionary for translation is ignored.
2016-10-12 17:21:43 INFO  ADAMContext:257 - Reading the ADAM file at small.adam to create RDD
2016-10-12 17:21:44 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 268.7 KB, free 366.0 MB)
2016-10-12 17:21:44 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 22.8 KB, free 366.0 MB)
2016-10-12 17:21:44 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 150.212.30.95:44036 (size: 22.8 KB, free: 366.3 MB)
2016-10-12 17:21:44 INFO  SparkContext:54 - Created broadcast 0 from newAPIHadoopFile at ADAMContext.scala:271
2016-10-12 17:21:44 INFO  FileInputFormat:283 - Total input paths to process : 1
2016-10-12 17:21:44 INFO  SparkContext:54 - Starting job: count at a1.scala:30
2016-10-12 17:21:45 INFO  DAGScheduler:54 - Registering RDD 3 (distinct at a1.scala:30)
2016-10-12 17:21:45 INFO  DAGScheduler:54 - Got job 0 (count at a1.scala:30) with 1 output partitions
2016-10-12 17:21:45 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (count at a1.scala:30)
2016-10-12 17:21:45 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 0)
2016-10-12 17:21:45 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 0)
2016-10-12 17:21:45 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at distinct at a1.scala:30), which has no missing parents
2016-10-12 17:21:45 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 4.2 KB, free 366.0 MB)
2016-10-12 17:21:45 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.5 KB, free 366.0 MB)
2016-10-12 17:21:45 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 150.212.30.95:44036 (size: 2.5 KB, free: 366.3 MB)
2016-10-12 17:21:45 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1012
2016-10-12 17:21:45 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at distinct at a1.scala:30)
2016-10-12 17:21:45 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2016-10-12 17:21:45 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5507 bytes)
2016-10-12 17:21:45 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2016-10-12 17:21:45 INFO  Executor:54 - Fetching spark://150.212.30.95:42867/jars/adam_2.11-0.19.1-SNAPSHOT.jar with timestamp 1476307303384
2016-10-12 17:21:45 INFO  TransportClientFactory:250 - Successfully created connection to /150.212.30.95:42867 after 24 ms (0 ms spent in bootstraps)
2016-10-12 17:21:45 INFO  Utils:54 - Fetching spark://150.212.30.95:42867/jars/adam_2.11-0.19.1-SNAPSHOT.jar to /tmp/spark-1300f5e7-1325-4443-ad06-aaa492dbf31f/userFiles-6f8ba1d5-3a69-4ae4-b8a1-0797f2b0ac5c/fetchFileTemp8656718623920170616.tmp
2016-10-12 17:21:45 INFO  Executor:54 - Adding file:/tmp/spark-1300f5e7-1325-4443-ad06-aaa492dbf31f/userFiles-6f8ba1d5-3a69-4ae4-b8a1-0797f2b0ac5c/adam_2.11-0.19.1-SNAPSHOT.jar to class loader
2016-10-12 17:21:45 INFO  Executor:54 - Fetching spark://150.212.30.95:42867/jars/a1.jar with timestamp 1476307303386
2016-10-12 17:21:45 INFO  Utils:54 - Fetching spark://150.212.30.95:42867/jars/a1.jar to /tmp/spark-1300f5e7-1325-4443-ad06-aaa492dbf31f/userFiles-6f8ba1d5-3a69-4ae4-b8a1-0797f2b0ac5c/fetchFileTemp3668459700172271001.tmp
2016-10-12 17:21:45 INFO  Executor:54 - Adding file:/tmp/spark-1300f5e7-1325-4443-ad06-aaa492dbf31f/userFiles-6f8ba1d5-3a69-4ae4-b8a1-0797f2b0ac5c/a1.jar to class loader
2016-10-12 17:21:45 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 17:21:45 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 17:21:49 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1490 bytes result sent to driver
2016-10-12 17:21:49 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 4311 ms on localhost (1/1)
2016-10-12 17:21:49 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2016-10-12 17:21:49 INFO  DAGScheduler:54 - ShuffleMapStage 0 (distinct at a1.scala:30) finished in 4.330 s
2016-10-12 17:21:49 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 17:21:49 INFO  DAGScheduler:54 - running: Set()
2016-10-12 17:21:49 INFO  DAGScheduler:54 - waiting: Set(ResultStage 1)
2016-10-12 17:21:49 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 17:21:49 INFO  DAGScheduler:54 - Submitting ResultStage 1 (MapPartitionsRDD[5] at distinct at a1.scala:30), which has no missing parents
2016-10-12 17:21:49 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 3.7 KB, free 366.0 MB)
2016-10-12 17:21:49 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.2 KB, free 366.0 MB)
2016-10-12 17:21:49 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on 150.212.30.95:44036 (size: 2.2 KB, free: 366.3 MB)
2016-10-12 17:21:49 INFO  SparkContext:54 - Created broadcast 2 from broadcast at DAGScheduler.scala:1012
2016-10-12 17:21:49 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at distinct at a1.scala:30)
2016-10-12 17:21:49 INFO  TaskSchedulerImpl:54 - Adding task set 1.0 with 1 tasks
2016-10-12 17:21:49 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, ANY, 5177 bytes)
2016-10-12 17:21:49 INFO  Executor:54 - Running task 0.0 in stage 1.0 (TID 1)
2016-10-12 17:21:49 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 17:21:49 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 5 ms
2016-10-12 17:21:49 INFO  Executor:54 - Finished task 0.0 in stage 1.0 (TID 1). 1512 bytes result sent to driver
2016-10-12 17:21:49 INFO  DAGScheduler:54 - ResultStage 1 (count at a1.scala:30) finished in 0.106 s
2016-10-12 17:21:49 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 1) in 106 ms on localhost (1/1)
2016-10-12 17:21:49 INFO  TaskSchedulerImpl:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2016-10-12 17:21:49 INFO  DAGScheduler:54 - Job 0 finished: count at a1.scala:30, took 4.622060 s
2016-10-12 17:21:49 INFO  SparkContext:54 - Starting job: count at a1.scala:31
2016-10-12 17:21:49 INFO  DAGScheduler:54 - Registering RDD 7 (distinct at a1.scala:31)
2016-10-12 17:21:49 INFO  DAGScheduler:54 - Got job 1 (count at a1.scala:31) with 1 output partitions
2016-10-12 17:21:49 INFO  DAGScheduler:54 - Final stage: ResultStage 3 (count at a1.scala:31)
2016-10-12 17:21:49 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 2)
2016-10-12 17:21:49 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 2)
2016-10-12 17:21:49 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 2 (MapPartitionsRDD[7] at distinct at a1.scala:31), which has no missing parents
2016-10-12 17:21:49 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 4.2 KB, free 366.0 MB)
2016-10-12 17:21:49 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.5 KB, free 366.0 MB)
2016-10-12 17:21:49 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on 150.212.30.95:44036 (size: 2.5 KB, free: 366.3 MB)
2016-10-12 17:21:49 INFO  SparkContext:54 - Created broadcast 3 from broadcast at DAGScheduler.scala:1012
2016-10-12 17:21:49 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[7] at distinct at a1.scala:31)
2016-10-12 17:21:49 INFO  TaskSchedulerImpl:54 - Adding task set 2.0 with 1 tasks
2016-10-12 17:21:49 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5507 bytes)
2016-10-12 17:21:49 INFO  Executor:54 - Running task 0.0 in stage 2.0 (TID 2)
2016-10-12 17:21:49 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 17:21:49 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 17:21:50 INFO  ContextCleaner:54 - Cleaned shuffle 0
2016-10-12 17:21:50 INFO  BlockManagerInfo:54 - Removed broadcast_1_piece0 on 150.212.30.95:44036 in memory (size: 2.5 KB, free: 366.3 MB)
2016-10-12 17:21:50 INFO  BlockManagerInfo:54 - Removed broadcast_2_piece0 on 150.212.30.95:44036 in memory (size: 2.2 KB, free: 366.3 MB)
2016-10-12 17:21:53 INFO  Executor:54 - Finished task 0.0 in stage 2.0 (TID 2). 1577 bytes result sent to driver
2016-10-12 17:21:53 INFO  DAGScheduler:54 - ShuffleMapStage 2 (distinct at a1.scala:31) finished in 3.405 s
2016-10-12 17:21:53 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 17:21:53 INFO  DAGScheduler:54 - running: Set()
2016-10-12 17:21:53 INFO  DAGScheduler:54 - waiting: Set(ResultStage 3)
2016-10-12 17:21:53 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 17:21:53 INFO  DAGScheduler:54 - Submitting ResultStage 3 (MapPartitionsRDD[9] at distinct at a1.scala:31), which has no missing parents
2016-10-12 17:21:53 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 3.8 KB, free 366.0 MB)
2016-10-12 17:21:53 INFO  TaskSetManager:54 - Finished task 0.0 in stage 2.0 (TID 2) in 3407 ms on localhost (1/1)
2016-10-12 17:21:53 INFO  TaskSchedulerImpl:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2016-10-12 17:21:53 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.2 KB, free 366.0 MB)
2016-10-12 17:21:53 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on 150.212.30.95:44036 (size: 2.2 KB, free: 366.3 MB)
2016-10-12 17:21:53 INFO  SparkContext:54 - Created broadcast 4 from broadcast at DAGScheduler.scala:1012
2016-10-12 17:21:53 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[9] at distinct at a1.scala:31)
2016-10-12 17:21:53 INFO  TaskSchedulerImpl:54 - Adding task set 3.0 with 1 tasks
2016-10-12 17:21:53 INFO  TaskSetManager:54 - Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, ANY, 5177 bytes)
2016-10-12 17:21:53 INFO  Executor:54 - Running task 0.0 in stage 3.0 (TID 3)
2016-10-12 17:21:53 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 17:21:53 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2016-10-12 17:21:53 INFO  Executor:54 - Finished task 0.0 in stage 3.0 (TID 3). 1512 bytes result sent to driver
2016-10-12 17:21:53 INFO  TaskSetManager:54 - Finished task 0.0 in stage 3.0 (TID 3) in 67 ms on localhost (1/1)
2016-10-12 17:21:53 INFO  TaskSchedulerImpl:54 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2016-10-12 17:21:53 INFO  DAGScheduler:54 - ResultStage 3 (count at a1.scala:31) finished in 0.060 s
2016-10-12 17:21:53 INFO  DAGScheduler:54 - Job 1 finished: count at a1.scala:31, took 3.538613 s
2016-10-12 17:21:53 INFO  SparkContext:54 - Starting job: count at a1.scala:37
2016-10-12 17:21:53 INFO  DAGScheduler:54 - Registering RDD 10 (map at a1.scala:32)
2016-10-12 17:21:53 INFO  DAGScheduler:54 - Got job 2 (count at a1.scala:37) with 1 output partitions
2016-10-12 17:21:53 INFO  DAGScheduler:54 - Final stage: ResultStage 5 (count at a1.scala:37)
2016-10-12 17:21:53 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 4)
2016-10-12 17:21:53 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 4)
2016-10-12 17:21:53 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 4 (MapPartitionsRDD[10] at map at a1.scala:32), which has no missing parents
2016-10-12 17:21:53 INFO  MemoryStore:54 - Block broadcast_5 stored as values in memory (estimated size 4.0 KB, free 366.0 MB)
2016-10-12 17:21:53 INFO  MemoryStore:54 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.4 KB, free 366.0 MB)
2016-10-12 17:21:53 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on 150.212.30.95:44036 (size: 2.4 KB, free: 366.3 MB)
2016-10-12 17:21:53 INFO  SparkContext:54 - Created broadcast 5 from broadcast at DAGScheduler.scala:1012
2016-10-12 17:21:53 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[10] at map at a1.scala:32)
2016-10-12 17:21:53 INFO  TaskSchedulerImpl:54 - Adding task set 4.0 with 1 tasks
2016-10-12 17:21:53 INFO  TaskSetManager:54 - Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5507 bytes)
2016-10-12 17:21:53 INFO  Executor:54 - Running task 0.0 in stage 4.0 (TID 4)
2016-10-12 17:21:53 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 17:21:53 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 17:21:53 INFO  ContextCleaner:54 - Cleaned shuffle 1
2016-10-12 17:21:53 INFO  BlockManagerInfo:54 - Removed broadcast_3_piece0 on 150.212.30.95:44036 in memory (size: 2.5 KB, free: 366.3 MB)
2016-10-12 17:21:53 INFO  BlockManagerInfo:54 - Removed broadcast_4_piece0 on 150.212.30.95:44036 in memory (size: 2.2 KB, free: 366.3 MB)
2016-10-12 17:21:56 INFO  Executor:54 - Finished task 0.0 in stage 4.0 (TID 4). 1490 bytes result sent to driver
2016-10-12 17:21:56 INFO  TaskSetManager:54 - Finished task 0.0 in stage 4.0 (TID 4) in 3189 ms on localhost (1/1)
2016-10-12 17:21:56 INFO  TaskSchedulerImpl:54 - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2016-10-12 17:21:56 INFO  DAGScheduler:54 - ShuffleMapStage 4 (map at a1.scala:32) finished in 3.184 s
2016-10-12 17:21:56 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 17:21:56 INFO  DAGScheduler:54 - running: Set()
2016-10-12 17:21:56 INFO  DAGScheduler:54 - waiting: Set(ResultStage 5)
2016-10-12 17:21:56 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 17:21:56 INFO  DAGScheduler:54 - Submitting ResultStage 5 (MapPartitionsRDD[12] at filter at a1.scala:32), which has no missing parents
2016-10-12 17:21:56 INFO  MemoryStore:54 - Block broadcast_6 stored as values in memory (estimated size 3.5 KB, free 366.0 MB)
2016-10-12 17:21:56 INFO  MemoryStore:54 - Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.0 MB)
2016-10-12 17:21:56 INFO  BlockManagerInfo:54 - Added broadcast_6_piece0 in memory on 150.212.30.95:44036 (size: 2.1 KB, free: 366.3 MB)
2016-10-12 17:21:56 INFO  SparkContext:54 - Created broadcast 6 from broadcast at DAGScheduler.scala:1012
2016-10-12 17:21:56 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[12] at filter at a1.scala:32)
2016-10-12 17:21:56 INFO  TaskSchedulerImpl:54 - Adding task set 5.0 with 1 tasks
2016-10-12 17:21:56 INFO  TaskSetManager:54 - Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, ANY, 5177 bytes)
2016-10-12 17:21:56 INFO  Executor:54 - Running task 0.0 in stage 5.0 (TID 5)
2016-10-12 17:21:56 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 17:21:56 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 2 ms
2016-10-12 17:21:56 INFO  Executor:54 - Finished task 0.0 in stage 5.0 (TID 5). 1512 bytes result sent to driver
2016-10-12 17:21:56 INFO  DAGScheduler:54 - ResultStage 5 (count at a1.scala:37) finished in 0.045 s
2016-10-12 17:21:56 INFO  DAGScheduler:54 - Job 2 finished: count at a1.scala:37, took 3.290244 s
2016-10-12 17:21:56 INFO  TaskSetManager:54 - Finished task 0.0 in stage 5.0 (TID 5) in 50 ms on localhost (1/1)
2016-10-12 17:21:56 INFO  TaskSchedulerImpl:54 - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2016-10-12 17:21:56 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2016-10-12 17:21:56 INFO  ServerConnector:306 - Stopped ServerConnector@64337702{HTTP/1.1}{0.0.0.0:4040}
2016-10-12 17:21:56 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,UNAVAILABLE}
2016-10-12 17:21:56 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@62e70ea3{/api,null,UNAVAILABLE}
2016-10-12 17:21:56 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@28276e50{/,null,UNAVAILABLE}
2016-10-12 17:21:56 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a7471ce{/static,null,UNAVAILABLE}
2016-10-12 17:21:56 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,UNAVAILABLE}
2016-10-12 17:21:56 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,UNAVAILABLE}
2016-10-12 17:21:56 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,UNAVAILABLE}
2016-10-12 17:21:56 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@297ea53a{/executors,null,UNAVAILABLE}
2016-10-12 17:21:56 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,UNAVAILABLE}
2016-10-12 17:21:56 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4052274f{/environment,null,UNAVAILABLE}
2016-10-12 17:21:56 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,UNAVAILABLE}
2016-10-12 17:21:56 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,UNAVAILABLE}
2016-10-12 17:21:56 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,UNAVAILABLE}
2016-10-12 17:21:56 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1643d68f{/storage,null,UNAVAILABLE}
2016-10-12 17:21:56 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,UNAVAILABLE}
2016-10-12 17:21:56 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,UNAVAILABLE}
2016-10-12 17:21:56 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,UNAVAILABLE}
2016-10-12 17:21:56 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,UNAVAILABLE}
2016-10-12 17:21:56 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,UNAVAILABLE}
2016-10-12 17:21:56 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,UNAVAILABLE}
2016-10-12 17:21:56 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,UNAVAILABLE}
2016-10-12 17:21:56 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,UNAVAILABLE}
2016-10-12 17:21:56 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,UNAVAILABLE}
2016-10-12 17:21:56 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,UNAVAILABLE}
2016-10-12 17:21:56 INFO  SparkUI:54 - Stopped Spark web UI at http://150.212.30.95:4040
2016-10-12 17:21:56 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2016-10-12 17:21:56 INFO  MemoryStore:54 - MemoryStore cleared
2016-10-12 17:21:56 INFO  BlockManager:54 - BlockManager stopped
2016-10-12 17:21:56 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2016-10-12 17:21:56 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2016-10-12 17:21:56 INFO  SparkContext:54 - Successfully stopped SparkContext
2016-10-12 17:21:56 INFO  ShutdownHookManager:54 - Shutdown hook called
2016-10-12 17:21:56 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-1300f5e7-1325-4443-ad06-aaa492dbf31f
2016-10-12 17:23:52 INFO  SparkContext:54 - Running Spark version 2.0.0
2016-10-12 17:23:53 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-12 17:23:53 WARN  Utils:66 - Your hostname, aadu-XPS-13-9350 resolves to a loopback address: 127.0.1.1; using 150.212.30.95 instead (on interface wlp58s0)
2016-10-12 17:23:53 WARN  Utils:66 - Set SPARK_LOCAL_IP if you need to bind to another address
2016-10-12 17:23:53 INFO  SecurityManager:54 - Changing view acls to: aadu
2016-10-12 17:23:53 INFO  SecurityManager:54 - Changing modify acls to: aadu
2016-10-12 17:23:53 INFO  SecurityManager:54 - Changing view acls groups to: 
2016-10-12 17:23:53 INFO  SecurityManager:54 - Changing modify acls groups to: 
2016-10-12 17:23:53 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(aadu); groups with view permissions: Set(); users  with modify permissions: Set(aadu); groups with modify permissions: Set()
2016-10-12 17:23:53 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 43240.
2016-10-12 17:23:53 INFO  SparkEnv:54 - Registering MapOutputTracker
2016-10-12 17:23:53 INFO  SparkEnv:54 - Registering BlockManagerMaster
2016-10-12 17:23:53 INFO  DiskBlockManager:54 - Created local directory at /tmp/blockmgr-915cdf68-7927-40a0-aefd-46d68564dbf6
2016-10-12 17:23:53 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2016-10-12 17:23:53 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2016-10-12 17:23:53 INFO  log:186 - Logging initialized @1496ms
2016-10-12 17:23:53 INFO  Server:327 - jetty-9.2.z-SNAPSHOT
2016-10-12 17:23:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,AVAILABLE}
2016-10-12 17:23:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,AVAILABLE}
2016-10-12 17:23:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,AVAILABLE}
2016-10-12 17:23:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,AVAILABLE}
2016-10-12 17:23:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,AVAILABLE}
2016-10-12 17:23:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,AVAILABLE}
2016-10-12 17:23:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,AVAILABLE}
2016-10-12 17:23:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,AVAILABLE}
2016-10-12 17:23:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,AVAILABLE}
2016-10-12 17:23:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,AVAILABLE}
2016-10-12 17:23:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1643d68f{/storage,null,AVAILABLE}
2016-10-12 17:23:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,AVAILABLE}
2016-10-12 17:23:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,AVAILABLE}
2016-10-12 17:23:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,AVAILABLE}
2016-10-12 17:23:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4052274f{/environment,null,AVAILABLE}
2016-10-12 17:23:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,AVAILABLE}
2016-10-12 17:23:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@297ea53a{/executors,null,AVAILABLE}
2016-10-12 17:23:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,AVAILABLE}
2016-10-12 17:23:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,AVAILABLE}
2016-10-12 17:23:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,AVAILABLE}
2016-10-12 17:23:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a7471ce{/static,null,AVAILABLE}
2016-10-12 17:23:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@28276e50{/,null,AVAILABLE}
2016-10-12 17:23:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@62e70ea3{/api,null,AVAILABLE}
2016-10-12 17:23:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,AVAILABLE}
2016-10-12 17:23:53 INFO  ServerConnector:266 - Started ServerConnector@64337702{HTTP/1.1}{0.0.0.0:4040}
2016-10-12 17:23:53 INFO  Server:379 - Started @1605ms
2016-10-12 17:23:53 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2016-10-12 17:23:53 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://150.212.30.95:4040
2016-10-12 17:23:53 INFO  SparkContext:54 - Added JAR file:/home/aadu/Repos/adam/adam-assembly/target/adam_2.11-0.19.1-SNAPSHOT.jar at spark://150.212.30.95:43240/jars/adam_2.11-0.19.1-SNAPSHOT.jar with timestamp 1476307433969
2016-10-12 17:23:53 INFO  SparkContext:54 - Added JAR file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/a1.jar at spark://150.212.30.95:43240/jars/a1.jar with timestamp 1476307433971
2016-10-12 17:23:54 INFO  Executor:54 - Starting executor ID driver on host localhost
2016-10-12 17:23:54 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33419.
2016-10-12 17:23:54 INFO  NettyBlockTransferService:54 - Server created on 150.212.30.95:33419
2016-10-12 17:23:54 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 150.212.30.95, 33419)
2016-10-12 17:23:54 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 150.212.30.95:33419 with 366.3 MB RAM, BlockManagerId(driver, 150.212.30.95, 33419)
2016-10-12 17:23:54 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 150.212.30.95, 33419)
2016-10-12 17:23:54 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@199e4c2b{/metrics/json,null,AVAILABLE}
2016-10-12 17:23:54 INFO  ADAMContext:1336 - Loading small.adam as Parquet containing Genotypes. Sequence dictionary for translation is ignored.
2016-10-12 17:23:54 INFO  ADAMContext:257 - Reading the ADAM file at small.adam to create RDD
2016-10-12 17:23:54 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 268.7 KB, free 366.0 MB)
2016-10-12 17:23:55 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 22.8 KB, free 366.0 MB)
2016-10-12 17:23:55 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 150.212.30.95:33419 (size: 22.8 KB, free: 366.3 MB)
2016-10-12 17:23:55 INFO  SparkContext:54 - Created broadcast 0 from newAPIHadoopFile at ADAMContext.scala:271
2016-10-12 17:23:55 INFO  FileInputFormat:283 - Total input paths to process : 1
2016-10-12 17:23:55 INFO  SparkContext:54 - Starting job: count at a1.scala:30
2016-10-12 17:23:55 INFO  DAGScheduler:54 - Registering RDD 3 (distinct at a1.scala:30)
2016-10-12 17:23:55 INFO  DAGScheduler:54 - Got job 0 (count at a1.scala:30) with 1 output partitions
2016-10-12 17:23:55 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (count at a1.scala:30)
2016-10-12 17:23:55 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 0)
2016-10-12 17:23:55 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 0)
2016-10-12 17:23:55 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at distinct at a1.scala:30), which has no missing parents
2016-10-12 17:23:55 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 4.2 KB, free 366.0 MB)
2016-10-12 17:23:55 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.5 KB, free 366.0 MB)
2016-10-12 17:23:55 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 150.212.30.95:33419 (size: 2.5 KB, free: 366.3 MB)
2016-10-12 17:23:55 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1012
2016-10-12 17:23:55 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at distinct at a1.scala:30)
2016-10-12 17:23:55 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2016-10-12 17:23:55 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5507 bytes)
2016-10-12 17:23:55 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2016-10-12 17:23:55 INFO  Executor:54 - Fetching spark://150.212.30.95:43240/jars/adam_2.11-0.19.1-SNAPSHOT.jar with timestamp 1476307433969
2016-10-12 17:23:55 INFO  TransportClientFactory:250 - Successfully created connection to /150.212.30.95:43240 after 29 ms (0 ms spent in bootstraps)
2016-10-12 17:23:55 INFO  Utils:54 - Fetching spark://150.212.30.95:43240/jars/adam_2.11-0.19.1-SNAPSHOT.jar to /tmp/spark-cccff3a5-d8bf-4c68-ac5f-e5097e5d4b15/userFiles-5b001e1f-583e-49b1-8f12-5c9d9dcdda5c/fetchFileTemp7333665865563207973.tmp
2016-10-12 17:23:56 INFO  Executor:54 - Adding file:/tmp/spark-cccff3a5-d8bf-4c68-ac5f-e5097e5d4b15/userFiles-5b001e1f-583e-49b1-8f12-5c9d9dcdda5c/adam_2.11-0.19.1-SNAPSHOT.jar to class loader
2016-10-12 17:23:56 INFO  Executor:54 - Fetching spark://150.212.30.95:43240/jars/a1.jar with timestamp 1476307433971
2016-10-12 17:23:56 INFO  Utils:54 - Fetching spark://150.212.30.95:43240/jars/a1.jar to /tmp/spark-cccff3a5-d8bf-4c68-ac5f-e5097e5d4b15/userFiles-5b001e1f-583e-49b1-8f12-5c9d9dcdda5c/fetchFileTemp1537067018730728092.tmp
2016-10-12 17:23:56 INFO  Executor:54 - Adding file:/tmp/spark-cccff3a5-d8bf-4c68-ac5f-e5097e5d4b15/userFiles-5b001e1f-583e-49b1-8f12-5c9d9dcdda5c/a1.jar to class loader
2016-10-12 17:23:56 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 17:23:56 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 17:24:00 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1577 bytes result sent to driver
2016-10-12 17:24:00 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 4326 ms on localhost (1/1)
2016-10-12 17:24:00 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2016-10-12 17:24:00 INFO  DAGScheduler:54 - ShuffleMapStage 0 (distinct at a1.scala:30) finished in 4.342 s
2016-10-12 17:24:00 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 17:24:00 INFO  DAGScheduler:54 - running: Set()
2016-10-12 17:24:00 INFO  DAGScheduler:54 - waiting: Set(ResultStage 1)
2016-10-12 17:24:00 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 17:24:00 INFO  DAGScheduler:54 - Submitting ResultStage 1 (MapPartitionsRDD[5] at distinct at a1.scala:30), which has no missing parents
2016-10-12 17:24:00 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 3.7 KB, free 366.0 MB)
2016-10-12 17:24:00 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.2 KB, free 366.0 MB)
2016-10-12 17:24:00 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on 150.212.30.95:33419 (size: 2.2 KB, free: 366.3 MB)
2016-10-12 17:24:00 INFO  SparkContext:54 - Created broadcast 2 from broadcast at DAGScheduler.scala:1012
2016-10-12 17:24:00 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at distinct at a1.scala:30)
2016-10-12 17:24:00 INFO  TaskSchedulerImpl:54 - Adding task set 1.0 with 1 tasks
2016-10-12 17:24:00 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, ANY, 5177 bytes)
2016-10-12 17:24:00 INFO  Executor:54 - Running task 0.0 in stage 1.0 (TID 1)
2016-10-12 17:24:00 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 17:24:00 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 4 ms
2016-10-12 17:24:00 INFO  Executor:54 - Finished task 0.0 in stage 1.0 (TID 1). 1512 bytes result sent to driver
2016-10-12 17:24:00 INFO  DAGScheduler:54 - ResultStage 1 (count at a1.scala:30) finished in 0.088 s
2016-10-12 17:24:00 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 1) in 87 ms on localhost (1/1)
2016-10-12 17:24:00 INFO  TaskSchedulerImpl:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2016-10-12 17:24:00 INFO  DAGScheduler:54 - Job 0 finished: count at a1.scala:30, took 4.594854 s
2016-10-12 17:24:00 INFO  SparkContext:54 - Starting job: count at a1.scala:31
2016-10-12 17:24:00 INFO  DAGScheduler:54 - Registering RDD 7 (distinct at a1.scala:31)
2016-10-12 17:24:00 INFO  DAGScheduler:54 - Got job 1 (count at a1.scala:31) with 1 output partitions
2016-10-12 17:24:00 INFO  DAGScheduler:54 - Final stage: ResultStage 3 (count at a1.scala:31)
2016-10-12 17:24:00 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 2)
2016-10-12 17:24:00 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 2)
2016-10-12 17:24:00 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 2 (MapPartitionsRDD[7] at distinct at a1.scala:31), which has no missing parents
2016-10-12 17:24:00 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 4.2 KB, free 366.0 MB)
2016-10-12 17:24:00 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.5 KB, free 366.0 MB)
2016-10-12 17:24:00 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on 150.212.30.95:33419 (size: 2.5 KB, free: 366.3 MB)
2016-10-12 17:24:00 INFO  SparkContext:54 - Created broadcast 3 from broadcast at DAGScheduler.scala:1012
2016-10-12 17:24:00 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[7] at distinct at a1.scala:31)
2016-10-12 17:24:00 INFO  TaskSchedulerImpl:54 - Adding task set 2.0 with 1 tasks
2016-10-12 17:24:00 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5507 bytes)
2016-10-12 17:24:00 INFO  Executor:54 - Running task 0.0 in stage 2.0 (TID 2)
2016-10-12 17:24:00 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 17:24:00 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 17:24:00 INFO  ContextCleaner:54 - Cleaned shuffle 0
2016-10-12 17:24:00 INFO  BlockManagerInfo:54 - Removed broadcast_1_piece0 on 150.212.30.95:33419 in memory (size: 2.5 KB, free: 366.3 MB)
2016-10-12 17:24:00 INFO  BlockManagerInfo:54 - Removed broadcast_2_piece0 on 150.212.30.95:33419 in memory (size: 2.2 KB, free: 366.3 MB)
2016-10-12 17:24:03 INFO  Executor:54 - Finished task 0.0 in stage 2.0 (TID 2). 1490 bytes result sent to driver
2016-10-12 17:24:03 INFO  TaskSetManager:54 - Finished task 0.0 in stage 2.0 (TID 2) in 3306 ms on localhost (1/1)
2016-10-12 17:24:03 INFO  DAGScheduler:54 - ShuffleMapStage 2 (distinct at a1.scala:31) finished in 3.303 s
2016-10-12 17:24:03 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 17:24:03 INFO  DAGScheduler:54 - running: Set()
2016-10-12 17:24:03 INFO  DAGScheduler:54 - waiting: Set(ResultStage 3)
2016-10-12 17:24:03 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 17:24:03 INFO  DAGScheduler:54 - Submitting ResultStage 3 (MapPartitionsRDD[9] at distinct at a1.scala:31), which has no missing parents
2016-10-12 17:24:03 INFO  TaskSchedulerImpl:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2016-10-12 17:24:03 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 3.8 KB, free 366.0 MB)
2016-10-12 17:24:03 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.2 KB, free 366.0 MB)
2016-10-12 17:24:03 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on 150.212.30.95:33419 (size: 2.2 KB, free: 366.3 MB)
2016-10-12 17:24:03 INFO  SparkContext:54 - Created broadcast 4 from broadcast at DAGScheduler.scala:1012
2016-10-12 17:24:03 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[9] at distinct at a1.scala:31)
2016-10-12 17:24:03 INFO  TaskSchedulerImpl:54 - Adding task set 3.0 with 1 tasks
2016-10-12 17:24:03 INFO  TaskSetManager:54 - Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, ANY, 5177 bytes)
2016-10-12 17:24:03 INFO  Executor:54 - Running task 0.0 in stage 3.0 (TID 3)
2016-10-12 17:24:03 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 17:24:03 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2016-10-12 17:24:03 INFO  Executor:54 - Finished task 0.0 in stage 3.0 (TID 3). 1512 bytes result sent to driver
2016-10-12 17:24:03 INFO  DAGScheduler:54 - ResultStage 3 (count at a1.scala:31) finished in 0.049 s
2016-10-12 17:24:03 INFO  DAGScheduler:54 - Job 1 finished: count at a1.scala:31, took 3.410121 s
2016-10-12 17:24:03 INFO  TaskSetManager:54 - Finished task 0.0 in stage 3.0 (TID 3) in 52 ms on localhost (1/1)
2016-10-12 17:24:03 INFO  TaskSchedulerImpl:54 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2016-10-12 17:24:03 INFO  SparkContext:54 - Starting job: count at a1.scala:37
2016-10-12 17:24:03 INFO  DAGScheduler:54 - Registering RDD 10 (map at a1.scala:32)
2016-10-12 17:24:03 INFO  DAGScheduler:54 - Got job 2 (count at a1.scala:37) with 1 output partitions
2016-10-12 17:24:03 INFO  DAGScheduler:54 - Final stage: ResultStage 5 (count at a1.scala:37)
2016-10-12 17:24:03 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 4)
2016-10-12 17:24:03 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 4)
2016-10-12 17:24:03 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 4 (MapPartitionsRDD[10] at map at a1.scala:32), which has no missing parents
2016-10-12 17:24:03 INFO  MemoryStore:54 - Block broadcast_5 stored as values in memory (estimated size 4.0 KB, free 366.0 MB)
2016-10-12 17:24:03 INFO  MemoryStore:54 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.4 KB, free 366.0 MB)
2016-10-12 17:24:03 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on 150.212.30.95:33419 (size: 2.4 KB, free: 366.3 MB)
2016-10-12 17:24:03 INFO  SparkContext:54 - Created broadcast 5 from broadcast at DAGScheduler.scala:1012
2016-10-12 17:24:03 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[10] at map at a1.scala:32)
2016-10-12 17:24:03 INFO  TaskSchedulerImpl:54 - Adding task set 4.0 with 1 tasks
2016-10-12 17:24:03 INFO  TaskSetManager:54 - Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5507 bytes)
2016-10-12 17:24:03 INFO  Executor:54 - Running task 0.0 in stage 4.0 (TID 4)
2016-10-12 17:24:03 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 17:24:03 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 17:24:04 INFO  ContextCleaner:54 - Cleaned shuffle 1
2016-10-12 17:24:04 INFO  BlockManagerInfo:54 - Removed broadcast_3_piece0 on 150.212.30.95:33419 in memory (size: 2.5 KB, free: 366.3 MB)
2016-10-12 17:24:04 INFO  BlockManagerInfo:54 - Removed broadcast_4_piece0 on 150.212.30.95:33419 in memory (size: 2.2 KB, free: 366.3 MB)
2016-10-12 17:24:06 INFO  Executor:54 - Finished task 0.0 in stage 4.0 (TID 4). 1490 bytes result sent to driver
2016-10-12 17:24:06 INFO  DAGScheduler:54 - ShuffleMapStage 4 (map at a1.scala:32) finished in 3.265 s
2016-10-12 17:24:06 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 17:24:06 INFO  DAGScheduler:54 - running: Set()
2016-10-12 17:24:06 INFO  DAGScheduler:54 - waiting: Set(ResultStage 5)
2016-10-12 17:24:06 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 17:24:06 INFO  DAGScheduler:54 - Submitting ResultStage 5 (MapPartitionsRDD[12] at filter at a1.scala:32), which has no missing parents
2016-10-12 17:24:06 INFO  TaskSetManager:54 - Finished task 0.0 in stage 4.0 (TID 4) in 3268 ms on localhost (1/1)
2016-10-12 17:24:06 INFO  TaskSchedulerImpl:54 - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2016-10-12 17:24:06 INFO  MemoryStore:54 - Block broadcast_6 stored as values in memory (estimated size 3.5 KB, free 366.0 MB)
2016-10-12 17:24:07 INFO  MemoryStore:54 - Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.0 MB)
2016-10-12 17:24:07 INFO  BlockManagerInfo:54 - Added broadcast_6_piece0 in memory on 150.212.30.95:33419 (size: 2.1 KB, free: 366.3 MB)
2016-10-12 17:24:07 INFO  SparkContext:54 - Created broadcast 6 from broadcast at DAGScheduler.scala:1012
2016-10-12 17:24:07 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[12] at filter at a1.scala:32)
2016-10-12 17:24:07 INFO  TaskSchedulerImpl:54 - Adding task set 5.0 with 1 tasks
2016-10-12 17:24:07 INFO  TaskSetManager:54 - Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, ANY, 5177 bytes)
2016-10-12 17:24:07 INFO  Executor:54 - Running task 0.0 in stage 5.0 (TID 5)
2016-10-12 17:24:07 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 17:24:07 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2016-10-12 17:24:07 INFO  Executor:54 - Finished task 0.0 in stage 5.0 (TID 5). 1512 bytes result sent to driver
2016-10-12 17:24:07 INFO  TaskSetManager:54 - Finished task 0.0 in stage 5.0 (TID 5) in 52 ms on localhost (1/1)
2016-10-12 17:24:07 INFO  DAGScheduler:54 - ResultStage 5 (count at a1.scala:37) finished in 0.049 s
2016-10-12 17:24:07 INFO  DAGScheduler:54 - Job 2 finished: count at a1.scala:37, took 3.378695 s
2016-10-12 17:24:07 INFO  TaskSchedulerImpl:54 - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2016-10-12 17:24:07 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2016-10-12 17:24:07 INFO  ServerConnector:306 - Stopped ServerConnector@64337702{HTTP/1.1}{0.0.0.0:4040}
2016-10-12 17:24:07 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,UNAVAILABLE}
2016-10-12 17:24:07 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@62e70ea3{/api,null,UNAVAILABLE}
2016-10-12 17:24:07 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@28276e50{/,null,UNAVAILABLE}
2016-10-12 17:24:07 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a7471ce{/static,null,UNAVAILABLE}
2016-10-12 17:24:07 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,UNAVAILABLE}
2016-10-12 17:24:07 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,UNAVAILABLE}
2016-10-12 17:24:07 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,UNAVAILABLE}
2016-10-12 17:24:07 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@297ea53a{/executors,null,UNAVAILABLE}
2016-10-12 17:24:07 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,UNAVAILABLE}
2016-10-12 17:24:07 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4052274f{/environment,null,UNAVAILABLE}
2016-10-12 17:24:07 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,UNAVAILABLE}
2016-10-12 17:24:07 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,UNAVAILABLE}
2016-10-12 17:24:07 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,UNAVAILABLE}
2016-10-12 17:24:07 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1643d68f{/storage,null,UNAVAILABLE}
2016-10-12 17:24:07 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,UNAVAILABLE}
2016-10-12 17:24:07 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,UNAVAILABLE}
2016-10-12 17:24:07 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,UNAVAILABLE}
2016-10-12 17:24:07 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,UNAVAILABLE}
2016-10-12 17:24:07 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,UNAVAILABLE}
2016-10-12 17:24:07 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,UNAVAILABLE}
2016-10-12 17:24:07 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,UNAVAILABLE}
2016-10-12 17:24:07 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,UNAVAILABLE}
2016-10-12 17:24:07 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,UNAVAILABLE}
2016-10-12 17:24:07 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,UNAVAILABLE}
2016-10-12 17:24:07 INFO  SparkUI:54 - Stopped Spark web UI at http://150.212.30.95:4040
2016-10-12 17:24:07 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2016-10-12 17:24:07 INFO  MemoryStore:54 - MemoryStore cleared
2016-10-12 17:24:07 INFO  BlockManager:54 - BlockManager stopped
2016-10-12 17:24:07 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2016-10-12 17:24:07 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2016-10-12 17:24:07 INFO  SparkContext:54 - Successfully stopped SparkContext
2016-10-12 17:24:07 INFO  ShutdownHookManager:54 - Shutdown hook called
2016-10-12 17:24:07 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-cccff3a5-d8bf-4c68-ac5f-e5097e5d4b15
2016-10-12 17:54:53 INFO  SparkContext:54 - Running Spark version 2.0.0
2016-10-12 17:54:53 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-12 17:54:53 WARN  Utils:66 - Your hostname, aadu-XPS-13-9350 resolves to a loopback address: 127.0.1.1; using 150.212.30.95 instead (on interface wlp58s0)
2016-10-12 17:54:53 WARN  Utils:66 - Set SPARK_LOCAL_IP if you need to bind to another address
2016-10-12 17:54:53 INFO  SecurityManager:54 - Changing view acls to: aadu
2016-10-12 17:54:53 INFO  SecurityManager:54 - Changing modify acls to: aadu
2016-10-12 17:54:53 INFO  SecurityManager:54 - Changing view acls groups to: 
2016-10-12 17:54:53 INFO  SecurityManager:54 - Changing modify acls groups to: 
2016-10-12 17:54:53 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(aadu); groups with view permissions: Set(); users  with modify permissions: Set(aadu); groups with modify permissions: Set()
2016-10-12 17:54:54 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 40828.
2016-10-12 17:54:54 INFO  SparkEnv:54 - Registering MapOutputTracker
2016-10-12 17:54:54 INFO  SparkEnv:54 - Registering BlockManagerMaster
2016-10-12 17:54:54 INFO  DiskBlockManager:54 - Created local directory at /tmp/blockmgr-43f153e7-9810-4d89-9144-c7e4cbfd4d1f
2016-10-12 17:54:54 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2016-10-12 17:54:54 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2016-10-12 17:54:54 INFO  log:186 - Logging initialized @1474ms
2016-10-12 17:54:54 INFO  Server:327 - jetty-9.2.z-SNAPSHOT
2016-10-12 17:54:54 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,AVAILABLE}
2016-10-12 17:54:54 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,AVAILABLE}
2016-10-12 17:54:54 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,AVAILABLE}
2016-10-12 17:54:54 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,AVAILABLE}
2016-10-12 17:54:54 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,AVAILABLE}
2016-10-12 17:54:54 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,AVAILABLE}
2016-10-12 17:54:54 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,AVAILABLE}
2016-10-12 17:54:54 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,AVAILABLE}
2016-10-12 17:54:54 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,AVAILABLE}
2016-10-12 17:54:54 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,AVAILABLE}
2016-10-12 17:54:54 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1643d68f{/storage,null,AVAILABLE}
2016-10-12 17:54:54 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,AVAILABLE}
2016-10-12 17:54:54 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,AVAILABLE}
2016-10-12 17:54:54 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,AVAILABLE}
2016-10-12 17:54:54 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4052274f{/environment,null,AVAILABLE}
2016-10-12 17:54:54 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,AVAILABLE}
2016-10-12 17:54:54 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@297ea53a{/executors,null,AVAILABLE}
2016-10-12 17:54:54 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,AVAILABLE}
2016-10-12 17:54:54 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,AVAILABLE}
2016-10-12 17:54:54 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,AVAILABLE}
2016-10-12 17:54:54 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a7471ce{/static,null,AVAILABLE}
2016-10-12 17:54:54 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@28276e50{/,null,AVAILABLE}
2016-10-12 17:54:54 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@62e70ea3{/api,null,AVAILABLE}
2016-10-12 17:54:54 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,AVAILABLE}
2016-10-12 17:54:54 INFO  ServerConnector:266 - Started ServerConnector@64337702{HTTP/1.1}{0.0.0.0:4040}
2016-10-12 17:54:54 INFO  Server:379 - Started @1592ms
2016-10-12 17:54:54 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2016-10-12 17:54:54 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://150.212.30.95:4040
2016-10-12 17:54:54 INFO  SparkContext:54 - Added JAR file:/home/aadu/Repos/adam/adam-assembly/target/adam_2.11-0.19.1-SNAPSHOT.jar at spark://150.212.30.95:40828/jars/adam_2.11-0.19.1-SNAPSHOT.jar with timestamp 1476309294607
2016-10-12 17:54:54 INFO  SparkContext:54 - Added JAR file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/a1.jar at spark://150.212.30.95:40828/jars/a1.jar with timestamp 1476309294609
2016-10-12 17:54:54 INFO  Executor:54 - Starting executor ID driver on host localhost
2016-10-12 17:54:54 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38999.
2016-10-12 17:54:54 INFO  NettyBlockTransferService:54 - Server created on 150.212.30.95:38999
2016-10-12 17:54:54 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 150.212.30.95, 38999)
2016-10-12 17:54:54 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 150.212.30.95:38999 with 366.3 MB RAM, BlockManagerId(driver, 150.212.30.95, 38999)
2016-10-12 17:54:54 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 150.212.30.95, 38999)
2016-10-12 17:54:54 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@199e4c2b{/metrics/json,null,AVAILABLE}
2016-10-12 17:54:54 INFO  ADAMContext:1336 - Loading small.adam as Parquet containing Genotypes. Sequence dictionary for translation is ignored.
2016-10-12 17:54:54 INFO  ADAMContext:257 - Reading the ADAM file at small.adam to create RDD
2016-10-12 17:54:55 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 268.7 KB, free 366.0 MB)
2016-10-12 17:54:56 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 22.8 KB, free 366.0 MB)
2016-10-12 17:54:56 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 150.212.30.95:38999 (size: 22.8 KB, free: 366.3 MB)
2016-10-12 17:54:56 INFO  SparkContext:54 - Created broadcast 0 from newAPIHadoopFile at ADAMContext.scala:271
2016-10-12 17:54:56 INFO  FileInputFormat:283 - Total input paths to process : 1
2016-10-12 17:54:56 INFO  SparkContext:54 - Starting job: count at a1.scala:30
2016-10-12 17:54:56 INFO  DAGScheduler:54 - Registering RDD 3 (distinct at a1.scala:30)
2016-10-12 17:54:56 INFO  DAGScheduler:54 - Got job 0 (count at a1.scala:30) with 1 output partitions
2016-10-12 17:54:56 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (count at a1.scala:30)
2016-10-12 17:54:56 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 0)
2016-10-12 17:54:56 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 0)
2016-10-12 17:54:56 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at distinct at a1.scala:30), which has no missing parents
2016-10-12 17:54:56 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 4.2 KB, free 366.0 MB)
2016-10-12 17:54:56 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.5 KB, free 366.0 MB)
2016-10-12 17:54:56 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 150.212.30.95:38999 (size: 2.5 KB, free: 366.3 MB)
2016-10-12 17:54:56 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1012
2016-10-12 17:54:56 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at distinct at a1.scala:30)
2016-10-12 17:54:56 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2016-10-12 17:54:56 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5507 bytes)
2016-10-12 17:54:56 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2016-10-12 17:54:56 INFO  Executor:54 - Fetching spark://150.212.30.95:40828/jars/a1.jar with timestamp 1476309294609
2016-10-12 17:54:56 INFO  TransportClientFactory:250 - Successfully created connection to /150.212.30.95:40828 after 32 ms (0 ms spent in bootstraps)
2016-10-12 17:54:56 INFO  Utils:54 - Fetching spark://150.212.30.95:40828/jars/a1.jar to /tmp/spark-8bc97c7a-25dc-4fdc-8c35-763b1a1ceee8/userFiles-2fdbbb0d-f01f-40db-a137-9f8b97a30502/fetchFileTemp1673213707208283506.tmp
2016-10-12 17:54:56 INFO  Executor:54 - Adding file:/tmp/spark-8bc97c7a-25dc-4fdc-8c35-763b1a1ceee8/userFiles-2fdbbb0d-f01f-40db-a137-9f8b97a30502/a1.jar to class loader
2016-10-12 17:54:56 INFO  Executor:54 - Fetching spark://150.212.30.95:40828/jars/adam_2.11-0.19.1-SNAPSHOT.jar with timestamp 1476309294607
2016-10-12 17:54:56 INFO  Utils:54 - Fetching spark://150.212.30.95:40828/jars/adam_2.11-0.19.1-SNAPSHOT.jar to /tmp/spark-8bc97c7a-25dc-4fdc-8c35-763b1a1ceee8/userFiles-2fdbbb0d-f01f-40db-a137-9f8b97a30502/fetchFileTemp204184199320840677.tmp
2016-10-12 17:54:56 INFO  Executor:54 - Adding file:/tmp/spark-8bc97c7a-25dc-4fdc-8c35-763b1a1ceee8/userFiles-2fdbbb0d-f01f-40db-a137-9f8b97a30502/adam_2.11-0.19.1-SNAPSHOT.jar to class loader
2016-10-12 17:54:56 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 17:54:56 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 17:55:01 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1577 bytes result sent to driver
2016-10-12 17:55:01 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 5508 ms on localhost (1/1)
2016-10-12 17:55:01 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2016-10-12 17:55:01 INFO  DAGScheduler:54 - ShuffleMapStage 0 (distinct at a1.scala:30) finished in 5.522 s
2016-10-12 17:55:01 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 17:55:01 INFO  DAGScheduler:54 - running: Set()
2016-10-12 17:55:01 INFO  DAGScheduler:54 - waiting: Set(ResultStage 1)
2016-10-12 17:55:01 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 17:55:01 INFO  DAGScheduler:54 - Submitting ResultStage 1 (MapPartitionsRDD[5] at distinct at a1.scala:30), which has no missing parents
2016-10-12 17:55:01 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 3.7 KB, free 366.0 MB)
2016-10-12 17:55:01 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.2 KB, free 366.0 MB)
2016-10-12 17:55:01 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on 150.212.30.95:38999 (size: 2.2 KB, free: 366.3 MB)
2016-10-12 17:55:01 INFO  SparkContext:54 - Created broadcast 2 from broadcast at DAGScheduler.scala:1012
2016-10-12 17:55:01 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at distinct at a1.scala:30)
2016-10-12 17:55:01 INFO  TaskSchedulerImpl:54 - Adding task set 1.0 with 1 tasks
2016-10-12 17:55:01 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, ANY, 5177 bytes)
2016-10-12 17:55:01 INFO  Executor:54 - Running task 0.0 in stage 1.0 (TID 1)
2016-10-12 17:55:01 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 17:55:01 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 4 ms
2016-10-12 17:55:02 INFO  Executor:54 - Finished task 0.0 in stage 1.0 (TID 1). 1512 bytes result sent to driver
2016-10-12 17:55:02 INFO  DAGScheduler:54 - ResultStage 1 (count at a1.scala:30) finished in 0.160 s
2016-10-12 17:55:02 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 1) in 174 ms on localhost (1/1)
2016-10-12 17:55:02 INFO  TaskSchedulerImpl:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2016-10-12 17:55:02 INFO  DAGScheduler:54 - Job 0 finished: count at a1.scala:30, took 5.880184 s
2016-10-12 17:55:02 INFO  SparkContext:54 - Starting job: count at a1.scala:31
2016-10-12 17:55:02 INFO  DAGScheduler:54 - Registering RDD 7 (distinct at a1.scala:31)
2016-10-12 17:55:02 INFO  DAGScheduler:54 - Got job 1 (count at a1.scala:31) with 1 output partitions
2016-10-12 17:55:02 INFO  DAGScheduler:54 - Final stage: ResultStage 3 (count at a1.scala:31)
2016-10-12 17:55:02 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 2)
2016-10-12 17:55:02 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 2)
2016-10-12 17:55:02 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 2 (MapPartitionsRDD[7] at distinct at a1.scala:31), which has no missing parents
2016-10-12 17:55:02 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 4.2 KB, free 366.0 MB)
2016-10-12 17:55:02 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.5 KB, free 366.0 MB)
2016-10-12 17:55:02 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on 150.212.30.95:38999 (size: 2.5 KB, free: 366.3 MB)
2016-10-12 17:55:02 INFO  SparkContext:54 - Created broadcast 3 from broadcast at DAGScheduler.scala:1012
2016-10-12 17:55:02 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[7] at distinct at a1.scala:31)
2016-10-12 17:55:02 INFO  TaskSchedulerImpl:54 - Adding task set 2.0 with 1 tasks
2016-10-12 17:55:02 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5507 bytes)
2016-10-12 17:55:02 INFO  Executor:54 - Running task 0.0 in stage 2.0 (TID 2)
2016-10-12 17:55:02 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 17:55:02 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 17:55:02 INFO  ContextCleaner:54 - Cleaned shuffle 0
2016-10-12 17:55:02 INFO  BlockManagerInfo:54 - Removed broadcast_1_piece0 on 150.212.30.95:38999 in memory (size: 2.5 KB, free: 366.3 MB)
2016-10-12 17:55:02 INFO  BlockManagerInfo:54 - Removed broadcast_2_piece0 on 150.212.30.95:38999 in memory (size: 2.2 KB, free: 366.3 MB)
2016-10-12 17:55:05 INFO  Executor:54 - Finished task 0.0 in stage 2.0 (TID 2). 1490 bytes result sent to driver
2016-10-12 17:55:05 INFO  TaskSetManager:54 - Finished task 0.0 in stage 2.0 (TID 2) in 3454 ms on localhost (1/1)
2016-10-12 17:55:05 INFO  DAGScheduler:54 - ShuffleMapStage 2 (distinct at a1.scala:31) finished in 3.455 s
2016-10-12 17:55:05 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 17:55:05 INFO  DAGScheduler:54 - running: Set()
2016-10-12 17:55:05 INFO  DAGScheduler:54 - waiting: Set(ResultStage 3)
2016-10-12 17:55:05 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 17:55:05 INFO  DAGScheduler:54 - Submitting ResultStage 3 (MapPartitionsRDD[9] at distinct at a1.scala:31), which has no missing parents
2016-10-12 17:55:05 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 3.8 KB, free 366.0 MB)
2016-10-12 17:55:05 INFO  TaskSchedulerImpl:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2016-10-12 17:55:05 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.2 KB, free 366.0 MB)
2016-10-12 17:55:05 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on 150.212.30.95:38999 (size: 2.2 KB, free: 366.3 MB)
2016-10-12 17:55:05 INFO  SparkContext:54 - Created broadcast 4 from broadcast at DAGScheduler.scala:1012
2016-10-12 17:55:05 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[9] at distinct at a1.scala:31)
2016-10-12 17:55:05 INFO  TaskSchedulerImpl:54 - Adding task set 3.0 with 1 tasks
2016-10-12 17:55:05 INFO  TaskSetManager:54 - Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, ANY, 5177 bytes)
2016-10-12 17:55:05 INFO  Executor:54 - Running task 0.0 in stage 3.0 (TID 3)
2016-10-12 17:55:05 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 17:55:05 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2016-10-12 17:55:05 INFO  Executor:54 - Finished task 0.0 in stage 3.0 (TID 3). 1512 bytes result sent to driver
2016-10-12 17:55:05 INFO  TaskSetManager:54 - Finished task 0.0 in stage 3.0 (TID 3) in 62 ms on localhost (1/1)
2016-10-12 17:55:05 INFO  DAGScheduler:54 - ResultStage 3 (count at a1.scala:31) finished in 0.054 s
2016-10-12 17:55:05 INFO  TaskSchedulerImpl:54 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2016-10-12 17:55:05 INFO  DAGScheduler:54 - Job 1 finished: count at a1.scala:31, took 3.593958 s
2016-10-12 17:55:05 INFO  SparkContext:54 - Starting job: collect at a1.scala:32
2016-10-12 17:55:05 INFO  DAGScheduler:54 - Registering RDD 10 (map at a1.scala:32)
2016-10-12 17:55:05 INFO  DAGScheduler:54 - Got job 2 (collect at a1.scala:32) with 1 output partitions
2016-10-12 17:55:05 INFO  DAGScheduler:54 - Final stage: ResultStage 5 (collect at a1.scala:32)
2016-10-12 17:55:05 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 4)
2016-10-12 17:55:05 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 4)
2016-10-12 17:55:05 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 4 (MapPartitionsRDD[10] at map at a1.scala:32), which has no missing parents
2016-10-12 17:55:05 INFO  MemoryStore:54 - Block broadcast_5 stored as values in memory (estimated size 4.0 KB, free 366.0 MB)
2016-10-12 17:55:05 INFO  MemoryStore:54 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.4 KB, free 366.0 MB)
2016-10-12 17:55:05 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on 150.212.30.95:38999 (size: 2.4 KB, free: 366.3 MB)
2016-10-12 17:55:05 INFO  SparkContext:54 - Created broadcast 5 from broadcast at DAGScheduler.scala:1012
2016-10-12 17:55:05 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[10] at map at a1.scala:32)
2016-10-12 17:55:05 INFO  TaskSchedulerImpl:54 - Adding task set 4.0 with 1 tasks
2016-10-12 17:55:05 INFO  TaskSetManager:54 - Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5592 bytes)
2016-10-12 17:55:05 INFO  Executor:54 - Running task 0.0 in stage 4.0 (TID 4)
2016-10-12 17:55:05 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 17:55:05 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 17:55:06 INFO  ContextCleaner:54 - Cleaned shuffle 1
2016-10-12 17:55:06 INFO  BlockManagerInfo:54 - Removed broadcast_3_piece0 on 150.212.30.95:38999 in memory (size: 2.5 KB, free: 366.3 MB)
2016-10-12 17:55:06 INFO  BlockManagerInfo:54 - Removed broadcast_4_piece0 on 150.212.30.95:38999 in memory (size: 2.2 KB, free: 366.3 MB)
2016-10-12 17:55:09 INFO  Executor:54 - Finished task 0.0 in stage 4.0 (TID 4). 1490 bytes result sent to driver
2016-10-12 17:55:09 INFO  DAGScheduler:54 - ShuffleMapStage 4 (map at a1.scala:32) finished in 3.171 s
2016-10-12 17:55:09 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 17:55:09 INFO  DAGScheduler:54 - running: Set()
2016-10-12 17:55:09 INFO  DAGScheduler:54 - waiting: Set(ResultStage 5)
2016-10-12 17:55:09 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 17:55:09 INFO  DAGScheduler:54 - Submitting ResultStage 5 (MapPartitionsRDD[13] at map at a1.scala:32), which has no missing parents
2016-10-12 17:55:09 INFO  MemoryStore:54 - Block broadcast_6 stored as values in memory (estimated size 3.8 KB, free 366.0 MB)
2016-10-12 17:55:09 INFO  TaskSetManager:54 - Finished task 0.0 in stage 4.0 (TID 4) in 3169 ms on localhost (1/1)
2016-10-12 17:55:09 INFO  TaskSchedulerImpl:54 - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2016-10-12 17:55:09 INFO  MemoryStore:54 - Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.2 KB, free 366.0 MB)
2016-10-12 17:55:09 INFO  BlockManagerInfo:54 - Added broadcast_6_piece0 in memory on 150.212.30.95:38999 (size: 2.2 KB, free: 366.3 MB)
2016-10-12 17:55:09 INFO  SparkContext:54 - Created broadcast 6 from broadcast at DAGScheduler.scala:1012
2016-10-12 17:55:09 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[13] at map at a1.scala:32)
2016-10-12 17:55:09 INFO  TaskSchedulerImpl:54 - Adding task set 5.0 with 1 tasks
2016-10-12 17:55:09 INFO  TaskSetManager:54 - Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, ANY, 5262 bytes)
2016-10-12 17:55:09 INFO  Executor:54 - Running task 0.0 in stage 5.0 (TID 5)
2016-10-12 17:55:09 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 17:55:09 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2016-10-12 17:55:09 INFO  Executor:54 - Finished task 0.0 in stage 5.0 (TID 5). 9861 bytes result sent to driver
2016-10-12 17:55:09 INFO  DAGScheduler:54 - ResultStage 5 (collect at a1.scala:32) finished in 0.048 s
2016-10-12 17:55:09 INFO  DAGScheduler:54 - Job 2 finished: collect at a1.scala:32, took 3.262366 s
2016-10-12 17:55:09 INFO  TaskSetManager:54 - Finished task 0.0 in stage 5.0 (TID 5) in 47 ms on localhost (1/1)
2016-10-12 17:55:09 INFO  TaskSchedulerImpl:54 - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2016-10-12 17:55:09 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2016-10-12 17:55:09 INFO  ServerConnector:306 - Stopped ServerConnector@64337702{HTTP/1.1}{0.0.0.0:4040}
2016-10-12 17:55:09 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,UNAVAILABLE}
2016-10-12 17:55:09 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@62e70ea3{/api,null,UNAVAILABLE}
2016-10-12 17:55:09 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@28276e50{/,null,UNAVAILABLE}
2016-10-12 17:55:09 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a7471ce{/static,null,UNAVAILABLE}
2016-10-12 17:55:09 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,UNAVAILABLE}
2016-10-12 17:55:09 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,UNAVAILABLE}
2016-10-12 17:55:09 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,UNAVAILABLE}
2016-10-12 17:55:09 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@297ea53a{/executors,null,UNAVAILABLE}
2016-10-12 17:55:09 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,UNAVAILABLE}
2016-10-12 17:55:09 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4052274f{/environment,null,UNAVAILABLE}
2016-10-12 17:55:09 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,UNAVAILABLE}
2016-10-12 17:55:09 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,UNAVAILABLE}
2016-10-12 17:55:09 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,UNAVAILABLE}
2016-10-12 17:55:09 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1643d68f{/storage,null,UNAVAILABLE}
2016-10-12 17:55:09 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,UNAVAILABLE}
2016-10-12 17:55:09 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,UNAVAILABLE}
2016-10-12 17:55:09 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,UNAVAILABLE}
2016-10-12 17:55:09 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,UNAVAILABLE}
2016-10-12 17:55:09 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,UNAVAILABLE}
2016-10-12 17:55:09 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,UNAVAILABLE}
2016-10-12 17:55:09 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,UNAVAILABLE}
2016-10-12 17:55:09 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,UNAVAILABLE}
2016-10-12 17:55:09 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,UNAVAILABLE}
2016-10-12 17:55:09 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,UNAVAILABLE}
2016-10-12 17:55:09 INFO  SparkUI:54 - Stopped Spark web UI at http://150.212.30.95:4040
2016-10-12 17:55:09 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2016-10-12 17:55:09 INFO  MemoryStore:54 - MemoryStore cleared
2016-10-12 17:55:09 INFO  BlockManager:54 - BlockManager stopped
2016-10-12 17:55:09 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2016-10-12 17:55:09 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2016-10-12 17:55:09 INFO  SparkContext:54 - Successfully stopped SparkContext
2016-10-12 17:55:09 INFO  ShutdownHookManager:54 - Shutdown hook called
2016-10-12 17:55:09 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-8bc97c7a-25dc-4fdc-8c35-763b1a1ceee8
2016-10-12 17:59:07 INFO  SparkContext:54 - Running Spark version 2.0.0
2016-10-12 17:59:07 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-12 17:59:07 WARN  Utils:66 - Your hostname, aadu-XPS-13-9350 resolves to a loopback address: 127.0.1.1; using 150.212.30.95 instead (on interface wlp58s0)
2016-10-12 17:59:07 WARN  Utils:66 - Set SPARK_LOCAL_IP if you need to bind to another address
2016-10-12 17:59:07 INFO  SecurityManager:54 - Changing view acls to: aadu
2016-10-12 17:59:07 INFO  SecurityManager:54 - Changing modify acls to: aadu
2016-10-12 17:59:07 INFO  SecurityManager:54 - Changing view acls groups to: 
2016-10-12 17:59:07 INFO  SecurityManager:54 - Changing modify acls groups to: 
2016-10-12 17:59:07 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(aadu); groups with view permissions: Set(); users  with modify permissions: Set(aadu); groups with modify permissions: Set()
2016-10-12 17:59:08 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 38502.
2016-10-12 17:59:08 INFO  SparkEnv:54 - Registering MapOutputTracker
2016-10-12 17:59:08 INFO  SparkEnv:54 - Registering BlockManagerMaster
2016-10-12 17:59:08 INFO  DiskBlockManager:54 - Created local directory at /tmp/blockmgr-79e5ab2f-8539-4dc0-bf3c-e00bd53655fa
2016-10-12 17:59:08 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2016-10-12 17:59:08 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2016-10-12 17:59:08 INFO  log:186 - Logging initialized @1440ms
2016-10-12 17:59:08 INFO  Server:327 - jetty-9.2.z-SNAPSHOT
2016-10-12 17:59:08 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,AVAILABLE}
2016-10-12 17:59:08 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,AVAILABLE}
2016-10-12 17:59:08 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,AVAILABLE}
2016-10-12 17:59:08 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,AVAILABLE}
2016-10-12 17:59:08 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,AVAILABLE}
2016-10-12 17:59:08 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,AVAILABLE}
2016-10-12 17:59:08 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,AVAILABLE}
2016-10-12 17:59:08 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,AVAILABLE}
2016-10-12 17:59:08 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,AVAILABLE}
2016-10-12 17:59:08 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,AVAILABLE}
2016-10-12 17:59:08 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1643d68f{/storage,null,AVAILABLE}
2016-10-12 17:59:08 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,AVAILABLE}
2016-10-12 17:59:08 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,AVAILABLE}
2016-10-12 17:59:08 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,AVAILABLE}
2016-10-12 17:59:08 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4052274f{/environment,null,AVAILABLE}
2016-10-12 17:59:08 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,AVAILABLE}
2016-10-12 17:59:08 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@297ea53a{/executors,null,AVAILABLE}
2016-10-12 17:59:08 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,AVAILABLE}
2016-10-12 17:59:08 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,AVAILABLE}
2016-10-12 17:59:08 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,AVAILABLE}
2016-10-12 17:59:08 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a7471ce{/static,null,AVAILABLE}
2016-10-12 17:59:08 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@28276e50{/,null,AVAILABLE}
2016-10-12 17:59:08 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@62e70ea3{/api,null,AVAILABLE}
2016-10-12 17:59:08 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,AVAILABLE}
2016-10-12 17:59:08 INFO  ServerConnector:266 - Started ServerConnector@64337702{HTTP/1.1}{0.0.0.0:4040}
2016-10-12 17:59:08 INFO  Server:379 - Started @1546ms
2016-10-12 17:59:08 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2016-10-12 17:59:08 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://150.212.30.95:4040
2016-10-12 17:59:08 INFO  SparkContext:54 - Added JAR file:/home/aadu/Repos/adam/adam-assembly/target/adam_2.11-0.19.1-SNAPSHOT.jar at spark://150.212.30.95:38502/jars/adam_2.11-0.19.1-SNAPSHOT.jar with timestamp 1476309548609
2016-10-12 17:59:08 INFO  SparkContext:54 - Added JAR file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/a1.jar at spark://150.212.30.95:38502/jars/a1.jar with timestamp 1476309548611
2016-10-12 17:59:08 INFO  Executor:54 - Starting executor ID driver on host localhost
2016-10-12 17:59:08 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34563.
2016-10-12 17:59:08 INFO  NettyBlockTransferService:54 - Server created on 150.212.30.95:34563
2016-10-12 17:59:08 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 150.212.30.95, 34563)
2016-10-12 17:59:08 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 150.212.30.95:34563 with 366.3 MB RAM, BlockManagerId(driver, 150.212.30.95, 34563)
2016-10-12 17:59:08 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 150.212.30.95, 34563)
2016-10-12 17:59:08 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@199e4c2b{/metrics/json,null,AVAILABLE}
2016-10-12 17:59:08 INFO  ADAMContext:1336 - Loading small.adam as Parquet containing Genotypes. Sequence dictionary for translation is ignored.
2016-10-12 17:59:08 INFO  ADAMContext:257 - Reading the ADAM file at small.adam to create RDD
2016-10-12 17:59:09 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 268.7 KB, free 366.0 MB)
2016-10-12 17:59:09 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 22.8 KB, free 366.0 MB)
2016-10-12 17:59:09 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 150.212.30.95:34563 (size: 22.8 KB, free: 366.3 MB)
2016-10-12 17:59:09 INFO  SparkContext:54 - Created broadcast 0 from newAPIHadoopFile at ADAMContext.scala:271
2016-10-12 17:59:10 INFO  FileInputFormat:283 - Total input paths to process : 1
2016-10-12 17:59:10 INFO  SparkContext:54 - Starting job: count at a1.scala:30
2016-10-12 17:59:10 INFO  DAGScheduler:54 - Registering RDD 3 (distinct at a1.scala:30)
2016-10-12 17:59:10 INFO  DAGScheduler:54 - Got job 0 (count at a1.scala:30) with 1 output partitions
2016-10-12 17:59:10 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (count at a1.scala:30)
2016-10-12 17:59:10 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 0)
2016-10-12 17:59:10 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 0)
2016-10-12 17:59:10 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at distinct at a1.scala:30), which has no missing parents
2016-10-12 17:59:10 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 4.2 KB, free 366.0 MB)
2016-10-12 17:59:10 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.5 KB, free 366.0 MB)
2016-10-12 17:59:10 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 150.212.30.95:34563 (size: 2.5 KB, free: 366.3 MB)
2016-10-12 17:59:10 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1012
2016-10-12 17:59:10 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at distinct at a1.scala:30)
2016-10-12 17:59:10 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2016-10-12 17:59:10 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5507 bytes)
2016-10-12 17:59:10 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2016-10-12 17:59:10 INFO  Executor:54 - Fetching spark://150.212.30.95:38502/jars/adam_2.11-0.19.1-SNAPSHOT.jar with timestamp 1476309548609
2016-10-12 17:59:10 INFO  TransportClientFactory:250 - Successfully created connection to /150.212.30.95:38502 after 22 ms (0 ms spent in bootstraps)
2016-10-12 17:59:10 INFO  Utils:54 - Fetching spark://150.212.30.95:38502/jars/adam_2.11-0.19.1-SNAPSHOT.jar to /tmp/spark-cb8eaee3-2a40-419f-8390-200d9c3f9ae0/userFiles-e267a768-4baf-49a9-b07a-071e9f88470c/fetchFileTemp1119733754721264323.tmp
2016-10-12 17:59:10 INFO  Executor:54 - Adding file:/tmp/spark-cb8eaee3-2a40-419f-8390-200d9c3f9ae0/userFiles-e267a768-4baf-49a9-b07a-071e9f88470c/adam_2.11-0.19.1-SNAPSHOT.jar to class loader
2016-10-12 17:59:10 INFO  Executor:54 - Fetching spark://150.212.30.95:38502/jars/a1.jar with timestamp 1476309548611
2016-10-12 17:59:10 INFO  Utils:54 - Fetching spark://150.212.30.95:38502/jars/a1.jar to /tmp/spark-cb8eaee3-2a40-419f-8390-200d9c3f9ae0/userFiles-e267a768-4baf-49a9-b07a-071e9f88470c/fetchFileTemp1025002491061558329.tmp
2016-10-12 17:59:10 INFO  Executor:54 - Adding file:/tmp/spark-cb8eaee3-2a40-419f-8390-200d9c3f9ae0/userFiles-e267a768-4baf-49a9-b07a-071e9f88470c/a1.jar to class loader
2016-10-12 17:59:10 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 17:59:10 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 17:59:14 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1490 bytes result sent to driver
2016-10-12 17:59:14 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 4269 ms on localhost (1/1)
2016-10-12 17:59:14 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2016-10-12 17:59:14 INFO  DAGScheduler:54 - ShuffleMapStage 0 (distinct at a1.scala:30) finished in 4.286 s
2016-10-12 17:59:14 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 17:59:14 INFO  DAGScheduler:54 - running: Set()
2016-10-12 17:59:14 INFO  DAGScheduler:54 - waiting: Set(ResultStage 1)
2016-10-12 17:59:14 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 17:59:14 INFO  DAGScheduler:54 - Submitting ResultStage 1 (MapPartitionsRDD[5] at distinct at a1.scala:30), which has no missing parents
2016-10-12 17:59:14 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 3.7 KB, free 366.0 MB)
2016-10-12 17:59:14 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.2 KB, free 366.0 MB)
2016-10-12 17:59:14 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on 150.212.30.95:34563 (size: 2.2 KB, free: 366.3 MB)
2016-10-12 17:59:14 INFO  SparkContext:54 - Created broadcast 2 from broadcast at DAGScheduler.scala:1012
2016-10-12 17:59:14 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at distinct at a1.scala:30)
2016-10-12 17:59:14 INFO  TaskSchedulerImpl:54 - Adding task set 1.0 with 1 tasks
2016-10-12 17:59:14 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, ANY, 5177 bytes)
2016-10-12 17:59:14 INFO  Executor:54 - Running task 0.0 in stage 1.0 (TID 1)
2016-10-12 17:59:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 17:59:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 5 ms
2016-10-12 17:59:14 INFO  Executor:54 - Finished task 0.0 in stage 1.0 (TID 1). 1512 bytes result sent to driver
2016-10-12 17:59:14 INFO  DAGScheduler:54 - ResultStage 1 (count at a1.scala:30) finished in 0.086 s
2016-10-12 17:59:14 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 1) in 86 ms on localhost (1/1)
2016-10-12 17:59:14 INFO  TaskSchedulerImpl:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2016-10-12 17:59:14 INFO  DAGScheduler:54 - Job 0 finished: count at a1.scala:30, took 4.553794 s
2016-10-12 17:59:14 INFO  SparkContext:54 - Starting job: count at a1.scala:31
2016-10-12 17:59:14 INFO  DAGScheduler:54 - Registering RDD 7 (distinct at a1.scala:31)
2016-10-12 17:59:14 INFO  DAGScheduler:54 - Got job 1 (count at a1.scala:31) with 1 output partitions
2016-10-12 17:59:14 INFO  DAGScheduler:54 - Final stage: ResultStage 3 (count at a1.scala:31)
2016-10-12 17:59:14 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 2)
2016-10-12 17:59:14 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 2)
2016-10-12 17:59:14 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 2 (MapPartitionsRDD[7] at distinct at a1.scala:31), which has no missing parents
2016-10-12 17:59:14 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 4.2 KB, free 366.0 MB)
2016-10-12 17:59:14 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.5 KB, free 366.0 MB)
2016-10-12 17:59:14 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on 150.212.30.95:34563 (size: 2.5 KB, free: 366.3 MB)
2016-10-12 17:59:14 INFO  SparkContext:54 - Created broadcast 3 from broadcast at DAGScheduler.scala:1012
2016-10-12 17:59:14 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[7] at distinct at a1.scala:31)
2016-10-12 17:59:14 INFO  TaskSchedulerImpl:54 - Adding task set 2.0 with 1 tasks
2016-10-12 17:59:14 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5507 bytes)
2016-10-12 17:59:14 INFO  Executor:54 - Running task 0.0 in stage 2.0 (TID 2)
2016-10-12 17:59:14 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 17:59:14 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 17:59:15 INFO  ContextCleaner:54 - Cleaned shuffle 0
2016-10-12 17:59:15 INFO  BlockManagerInfo:54 - Removed broadcast_1_piece0 on 150.212.30.95:34563 in memory (size: 2.5 KB, free: 366.3 MB)
2016-10-12 17:59:15 INFO  BlockManagerInfo:54 - Removed broadcast_2_piece0 on 150.212.30.95:34563 in memory (size: 2.2 KB, free: 366.3 MB)
2016-10-12 17:59:18 INFO  Executor:54 - Finished task 0.0 in stage 2.0 (TID 2). 1490 bytes result sent to driver
2016-10-12 17:59:18 INFO  DAGScheduler:54 - ShuffleMapStage 2 (distinct at a1.scala:31) finished in 3.401 s
2016-10-12 17:59:18 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 17:59:18 INFO  DAGScheduler:54 - running: Set()
2016-10-12 17:59:18 INFO  DAGScheduler:54 - waiting: Set(ResultStage 3)
2016-10-12 17:59:18 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 17:59:18 INFO  DAGScheduler:54 - Submitting ResultStage 3 (MapPartitionsRDD[9] at distinct at a1.scala:31), which has no missing parents
2016-10-12 17:59:18 INFO  TaskSetManager:54 - Finished task 0.0 in stage 2.0 (TID 2) in 3401 ms on localhost (1/1)
2016-10-12 17:59:18 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 3.8 KB, free 366.0 MB)
2016-10-12 17:59:18 INFO  TaskSchedulerImpl:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2016-10-12 17:59:18 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.2 KB, free 366.0 MB)
2016-10-12 17:59:18 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on 150.212.30.95:34563 (size: 2.2 KB, free: 366.3 MB)
2016-10-12 17:59:18 INFO  SparkContext:54 - Created broadcast 4 from broadcast at DAGScheduler.scala:1012
2016-10-12 17:59:18 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[9] at distinct at a1.scala:31)
2016-10-12 17:59:18 INFO  TaskSchedulerImpl:54 - Adding task set 3.0 with 1 tasks
2016-10-12 17:59:18 INFO  TaskSetManager:54 - Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, ANY, 5177 bytes)
2016-10-12 17:59:18 INFO  Executor:54 - Running task 0.0 in stage 3.0 (TID 3)
2016-10-12 17:59:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 17:59:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2016-10-12 17:59:18 INFO  Executor:54 - Finished task 0.0 in stage 3.0 (TID 3). 1512 bytes result sent to driver
2016-10-12 17:59:18 INFO  TaskSetManager:54 - Finished task 0.0 in stage 3.0 (TID 3) in 42 ms on localhost (1/1)
2016-10-12 17:59:18 INFO  DAGScheduler:54 - ResultStage 3 (count at a1.scala:31) finished in 0.042 s
2016-10-12 17:59:18 INFO  DAGScheduler:54 - Job 1 finished: count at a1.scala:31, took 3.502485 s
2016-10-12 17:59:18 INFO  TaskSchedulerImpl:54 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2016-10-12 17:59:18 INFO  SparkContext:54 - Starting job: collect at a1.scala:32
2016-10-12 17:59:18 INFO  DAGScheduler:54 - Registering RDD 10 (map at a1.scala:32)
2016-10-12 17:59:18 INFO  DAGScheduler:54 - Got job 2 (collect at a1.scala:32) with 1 output partitions
2016-10-12 17:59:18 INFO  DAGScheduler:54 - Final stage: ResultStage 5 (collect at a1.scala:32)
2016-10-12 17:59:18 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 4)
2016-10-12 17:59:18 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 4)
2016-10-12 17:59:18 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 4 (MapPartitionsRDD[10] at map at a1.scala:32), which has no missing parents
2016-10-12 17:59:18 INFO  MemoryStore:54 - Block broadcast_5 stored as values in memory (estimated size 4.0 KB, free 366.0 MB)
2016-10-12 17:59:18 INFO  MemoryStore:54 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.4 KB, free 366.0 MB)
2016-10-12 17:59:18 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on 150.212.30.95:34563 (size: 2.4 KB, free: 366.3 MB)
2016-10-12 17:59:18 INFO  SparkContext:54 - Created broadcast 5 from broadcast at DAGScheduler.scala:1012
2016-10-12 17:59:18 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[10] at map at a1.scala:32)
2016-10-12 17:59:18 INFO  TaskSchedulerImpl:54 - Adding task set 4.0 with 1 tasks
2016-10-12 17:59:18 INFO  TaskSetManager:54 - Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5592 bytes)
2016-10-12 17:59:18 INFO  Executor:54 - Running task 0.0 in stage 4.0 (TID 4)
2016-10-12 17:59:18 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 17:59:18 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 17:59:18 INFO  ContextCleaner:54 - Cleaned shuffle 1
2016-10-12 17:59:18 INFO  BlockManagerInfo:54 - Removed broadcast_3_piece0 on 150.212.30.95:34563 in memory (size: 2.5 KB, free: 366.3 MB)
2016-10-12 17:59:18 INFO  BlockManagerInfo:54 - Removed broadcast_4_piece0 on 150.212.30.95:34563 in memory (size: 2.2 KB, free: 366.3 MB)
2016-10-12 18:03:52 INFO  SparkContext:54 - Running Spark version 2.0.0
2016-10-12 18:03:52 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-12 18:03:52 WARN  Utils:66 - Your hostname, aadu-XPS-13-9350 resolves to a loopback address: 127.0.1.1; using 150.212.30.95 instead (on interface wlp58s0)
2016-10-12 18:03:52 WARN  Utils:66 - Set SPARK_LOCAL_IP if you need to bind to another address
2016-10-12 18:03:52 INFO  SecurityManager:54 - Changing view acls to: aadu
2016-10-12 18:03:52 INFO  SecurityManager:54 - Changing modify acls to: aadu
2016-10-12 18:03:52 INFO  SecurityManager:54 - Changing view acls groups to: 
2016-10-12 18:03:52 INFO  SecurityManager:54 - Changing modify acls groups to: 
2016-10-12 18:03:52 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(aadu); groups with view permissions: Set(); users  with modify permissions: Set(aadu); groups with modify permissions: Set()
2016-10-12 18:03:52 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 32839.
2016-10-12 18:03:52 INFO  SparkEnv:54 - Registering MapOutputTracker
2016-10-12 18:03:52 INFO  SparkEnv:54 - Registering BlockManagerMaster
2016-10-12 18:03:52 INFO  DiskBlockManager:54 - Created local directory at /tmp/blockmgr-7b95d0e6-bcf2-4433-a8a1-7e13e1675b4b
2016-10-12 18:03:52 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2016-10-12 18:03:52 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2016-10-12 18:03:52 INFO  log:186 - Logging initialized @1492ms
2016-10-12 18:03:53 INFO  Server:327 - jetty-9.2.z-SNAPSHOT
2016-10-12 18:03:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,AVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,AVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,AVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,AVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,AVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,AVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,AVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,AVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,AVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,AVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1643d68f{/storage,null,AVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,AVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,AVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,AVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4052274f{/environment,null,AVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,AVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@297ea53a{/executors,null,AVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,AVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,AVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,AVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a7471ce{/static,null,AVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@28276e50{/,null,AVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@62e70ea3{/api,null,AVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,AVAILABLE}
2016-10-12 18:03:53 WARN  AbstractLifeCycle:212 - FAILED ServerConnector@4fe89c24{HTTP/1.1}{0.0.0.0:4040}: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2071)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2062)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:139)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:451)
	at Assign1$.main(a1.scala:16)
	at Assign1.main(a1.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2016-10-12 18:03:53 WARN  AbstractLifeCycle:212 - FAILED org.spark_project.jetty.server.Server@6175619b: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2071)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2062)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:139)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:451)
	at Assign1$.main(a1.scala:16)
	at Assign1.main(a1.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2016-10-12 18:03:53 INFO  ServerConnector:306 - Stopped ServerConnector@4fe89c24{HTTP/1.1}{0.0.0.0:4040}
2016-10-12 18:03:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,UNAVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@62e70ea3{/api,null,UNAVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@28276e50{/,null,UNAVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a7471ce{/static,null,UNAVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,UNAVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,UNAVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,UNAVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@297ea53a{/executors,null,UNAVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,UNAVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4052274f{/environment,null,UNAVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,UNAVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,UNAVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,UNAVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1643d68f{/storage,null,UNAVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,UNAVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,UNAVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,UNAVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,UNAVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,UNAVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,UNAVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,UNAVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,UNAVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,UNAVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,UNAVAILABLE}
2016-10-12 18:03:53 WARN  Utils:66 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2016-10-12 18:03:53 INFO  Server:327 - jetty-9.2.z-SNAPSHOT
2016-10-12 18:03:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,AVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,AVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,AVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,AVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,AVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,AVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,AVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,AVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,AVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,AVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1643d68f{/storage,null,AVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,AVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,AVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,AVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4052274f{/environment,null,AVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,AVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@297ea53a{/executors,null,AVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,AVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,AVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,AVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a7471ce{/static,null,AVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@28276e50{/,null,AVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@62e70ea3{/api,null,AVAILABLE}
2016-10-12 18:03:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,AVAILABLE}
2016-10-12 18:03:53 INFO  ServerConnector:266 - Started ServerConnector@6c67e137{HTTP/1.1}{0.0.0.0:4041}
2016-10-12 18:03:53 INFO  Server:379 - Started @1655ms
2016-10-12 18:03:53 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4041.
2016-10-12 18:03:53 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://150.212.30.95:4041
2016-10-12 18:03:53 INFO  SparkContext:54 - Added JAR file:/home/aadu/Repos/adam/adam-assembly/target/adam_2.11-0.19.1-SNAPSHOT.jar at spark://150.212.30.95:32839/jars/adam_2.11-0.19.1-SNAPSHOT.jar with timestamp 1476309833144
2016-10-12 18:03:53 INFO  SparkContext:54 - Added JAR file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/a1.jar at spark://150.212.30.95:32839/jars/a1.jar with timestamp 1476309833145
2016-10-12 18:03:53 INFO  Executor:54 - Starting executor ID driver on host localhost
2016-10-12 18:03:53 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40679.
2016-10-12 18:03:53 INFO  NettyBlockTransferService:54 - Server created on 150.212.30.95:40679
2016-10-12 18:03:53 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 150.212.30.95, 40679)
2016-10-12 18:03:53 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 150.212.30.95:40679 with 366.3 MB RAM, BlockManagerId(driver, 150.212.30.95, 40679)
2016-10-12 18:03:53 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 150.212.30.95, 40679)
2016-10-12 18:03:53 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2472c7d8{/metrics/json,null,AVAILABLE}
2016-10-12 18:03:53 INFO  ADAMContext:1336 - Loading small.adam as Parquet containing Genotypes. Sequence dictionary for translation is ignored.
2016-10-12 18:03:53 INFO  ADAMContext:257 - Reading the ADAM file at small.adam to create RDD
2016-10-12 18:03:53 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 268.7 KB, free 366.0 MB)
2016-10-12 18:03:54 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 22.8 KB, free 366.0 MB)
2016-10-12 18:03:54 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 150.212.30.95:40679 (size: 22.8 KB, free: 366.3 MB)
2016-10-12 18:03:54 INFO  SparkContext:54 - Created broadcast 0 from newAPIHadoopFile at ADAMContext.scala:271
2016-10-12 18:03:54 INFO  FileInputFormat:283 - Total input paths to process : 1
2016-10-12 18:03:54 INFO  SparkContext:54 - Starting job: count at a1.scala:30
2016-10-12 18:03:54 INFO  DAGScheduler:54 - Registering RDD 3 (distinct at a1.scala:30)
2016-10-12 18:03:54 INFO  DAGScheduler:54 - Got job 0 (count at a1.scala:30) with 1 output partitions
2016-10-12 18:03:54 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (count at a1.scala:30)
2016-10-12 18:03:54 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 0)
2016-10-12 18:03:54 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 0)
2016-10-12 18:03:54 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at distinct at a1.scala:30), which has no missing parents
2016-10-12 18:03:54 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 4.2 KB, free 366.0 MB)
2016-10-12 18:03:54 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.5 KB, free 366.0 MB)
2016-10-12 18:03:54 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 150.212.30.95:40679 (size: 2.5 KB, free: 366.3 MB)
2016-10-12 18:03:54 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1012
2016-10-12 18:03:54 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at distinct at a1.scala:30)
2016-10-12 18:03:54 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2016-10-12 18:03:54 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5507 bytes)
2016-10-12 18:03:54 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2016-10-12 18:03:54 INFO  Executor:54 - Fetching spark://150.212.30.95:32839/jars/a1.jar with timestamp 1476309833145
2016-10-12 18:03:54 INFO  TransportClientFactory:250 - Successfully created connection to /150.212.30.95:32839 after 36 ms (0 ms spent in bootstraps)
2016-10-12 18:03:55 INFO  Utils:54 - Fetching spark://150.212.30.95:32839/jars/a1.jar to /tmp/spark-f66ac101-a788-4c40-8fc9-dfaa3f30f9cf/userFiles-a26774a6-3dc7-4d4b-9b4f-0f3fd7d6133e/fetchFileTemp7675304692298805454.tmp
2016-10-12 18:03:55 INFO  Executor:54 - Adding file:/tmp/spark-f66ac101-a788-4c40-8fc9-dfaa3f30f9cf/userFiles-a26774a6-3dc7-4d4b-9b4f-0f3fd7d6133e/a1.jar to class loader
2016-10-12 18:03:55 INFO  Executor:54 - Fetching spark://150.212.30.95:32839/jars/adam_2.11-0.19.1-SNAPSHOT.jar with timestamp 1476309833144
2016-10-12 18:03:55 INFO  Utils:54 - Fetching spark://150.212.30.95:32839/jars/adam_2.11-0.19.1-SNAPSHOT.jar to /tmp/spark-f66ac101-a788-4c40-8fc9-dfaa3f30f9cf/userFiles-a26774a6-3dc7-4d4b-9b4f-0f3fd7d6133e/fetchFileTemp88979695868152120.tmp
2016-10-12 18:03:55 INFO  Executor:54 - Adding file:/tmp/spark-f66ac101-a788-4c40-8fc9-dfaa3f30f9cf/userFiles-a26774a6-3dc7-4d4b-9b4f-0f3fd7d6133e/adam_2.11-0.19.1-SNAPSHOT.jar to class loader
2016-10-12 18:03:55 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 18:03:55 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 18:03:59 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1577 bytes result sent to driver
2016-10-12 18:03:59 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 4989 ms on localhost (1/1)
2016-10-12 18:03:59 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2016-10-12 18:03:59 INFO  DAGScheduler:54 - ShuffleMapStage 0 (distinct at a1.scala:30) finished in 5.009 s
2016-10-12 18:03:59 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 18:03:59 INFO  DAGScheduler:54 - running: Set()
2016-10-12 18:03:59 INFO  DAGScheduler:54 - waiting: Set(ResultStage 1)
2016-10-12 18:03:59 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 18:03:59 INFO  DAGScheduler:54 - Submitting ResultStage 1 (MapPartitionsRDD[5] at distinct at a1.scala:30), which has no missing parents
2016-10-12 18:03:59 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 3.7 KB, free 366.0 MB)
2016-10-12 18:03:59 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.2 KB, free 366.0 MB)
2016-10-12 18:03:59 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on 150.212.30.95:40679 (size: 2.2 KB, free: 366.3 MB)
2016-10-12 18:03:59 INFO  SparkContext:54 - Created broadcast 2 from broadcast at DAGScheduler.scala:1012
2016-10-12 18:03:59 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at distinct at a1.scala:30)
2016-10-12 18:03:59 INFO  TaskSchedulerImpl:54 - Adding task set 1.0 with 1 tasks
2016-10-12 18:03:59 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, ANY, 5177 bytes)
2016-10-12 18:03:59 INFO  Executor:54 - Running task 0.0 in stage 1.0 (TID 1)
2016-10-12 18:03:59 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 18:03:59 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 4 ms
2016-10-12 18:03:59 INFO  Executor:54 - Finished task 0.0 in stage 1.0 (TID 1). 1512 bytes result sent to driver
2016-10-12 18:04:00 INFO  DAGScheduler:54 - ResultStage 1 (count at a1.scala:30) finished in 0.102 s
2016-10-12 18:04:00 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 1) in 101 ms on localhost (1/1)
2016-10-12 18:04:00 INFO  TaskSchedulerImpl:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2016-10-12 18:04:00 INFO  DAGScheduler:54 - Job 0 finished: count at a1.scala:30, took 5.289910 s
2016-10-12 18:04:00 INFO  SparkContext:54 - Starting job: count at a1.scala:31
2016-10-12 18:04:00 INFO  DAGScheduler:54 - Registering RDD 7 (distinct at a1.scala:31)
2016-10-12 18:04:00 INFO  DAGScheduler:54 - Got job 1 (count at a1.scala:31) with 1 output partitions
2016-10-12 18:04:00 INFO  DAGScheduler:54 - Final stage: ResultStage 3 (count at a1.scala:31)
2016-10-12 18:04:00 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 2)
2016-10-12 18:04:00 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 2)
2016-10-12 18:04:00 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 2 (MapPartitionsRDD[7] at distinct at a1.scala:31), which has no missing parents
2016-10-12 18:04:00 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 4.2 KB, free 366.0 MB)
2016-10-12 18:04:00 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.5 KB, free 366.0 MB)
2016-10-12 18:04:00 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on 150.212.30.95:40679 (size: 2.5 KB, free: 366.3 MB)
2016-10-12 18:04:00 INFO  SparkContext:54 - Created broadcast 3 from broadcast at DAGScheduler.scala:1012
2016-10-12 18:04:00 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[7] at distinct at a1.scala:31)
2016-10-12 18:04:00 INFO  TaskSchedulerImpl:54 - Adding task set 2.0 with 1 tasks
2016-10-12 18:04:00 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5507 bytes)
2016-10-12 18:04:00 INFO  Executor:54 - Running task 0.0 in stage 2.0 (TID 2)
2016-10-12 18:04:00 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 18:04:00 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 18:04:00 INFO  ContextCleaner:54 - Cleaned shuffle 0
2016-10-12 18:04:00 INFO  BlockManagerInfo:54 - Removed broadcast_1_piece0 on 150.212.30.95:40679 in memory (size: 2.5 KB, free: 366.3 MB)
2016-10-12 18:04:00 INFO  BlockManagerInfo:54 - Removed broadcast_2_piece0 on 150.212.30.95:40679 in memory (size: 2.2 KB, free: 366.3 MB)
2016-10-12 18:04:04 INFO  Executor:54 - Finished task 0.0 in stage 2.0 (TID 2). 1577 bytes result sent to driver
2016-10-12 18:04:04 INFO  TaskSetManager:54 - Finished task 0.0 in stage 2.0 (TID 2) in 4093 ms on localhost (1/1)
2016-10-12 18:04:04 INFO  DAGScheduler:54 - ShuffleMapStage 2 (distinct at a1.scala:31) finished in 4.094 s
2016-10-12 18:04:04 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 18:04:04 INFO  DAGScheduler:54 - running: Set()
2016-10-12 18:04:04 INFO  DAGScheduler:54 - waiting: Set(ResultStage 3)
2016-10-12 18:04:04 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 18:04:04 INFO  DAGScheduler:54 - Submitting ResultStage 3 (MapPartitionsRDD[9] at distinct at a1.scala:31), which has no missing parents
2016-10-12 18:04:04 INFO  TaskSchedulerImpl:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2016-10-12 18:04:04 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 3.8 KB, free 366.0 MB)
2016-10-12 18:04:04 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.2 KB, free 366.0 MB)
2016-10-12 18:04:04 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on 150.212.30.95:40679 (size: 2.2 KB, free: 366.3 MB)
2016-10-12 18:04:04 INFO  SparkContext:54 - Created broadcast 4 from broadcast at DAGScheduler.scala:1012
2016-10-12 18:04:04 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[9] at distinct at a1.scala:31)
2016-10-12 18:04:04 INFO  TaskSchedulerImpl:54 - Adding task set 3.0 with 1 tasks
2016-10-12 18:04:04 INFO  TaskSetManager:54 - Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, ANY, 5177 bytes)
2016-10-12 18:04:04 INFO  Executor:54 - Running task 0.0 in stage 3.0 (TID 3)
2016-10-12 18:04:04 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 18:04:04 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 2 ms
2016-10-12 18:04:04 INFO  Executor:54 - Finished task 0.0 in stage 3.0 (TID 3). 1512 bytes result sent to driver
2016-10-12 18:04:04 INFO  TaskSetManager:54 - Finished task 0.0 in stage 3.0 (TID 3) in 64 ms on localhost (1/1)
2016-10-12 18:04:04 INFO  DAGScheduler:54 - ResultStage 3 (count at a1.scala:31) finished in 0.059 s
2016-10-12 18:04:04 INFO  DAGScheduler:54 - Job 1 finished: count at a1.scala:31, took 4.221073 s
2016-10-12 18:04:04 INFO  TaskSchedulerImpl:54 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2016-10-12 18:04:04 INFO  SparkContext:54 - Starting job: collect at a1.scala:32
2016-10-12 18:04:04 INFO  DAGScheduler:54 - Registering RDD 10 (map at a1.scala:32)
2016-10-12 18:04:04 INFO  DAGScheduler:54 - Got job 2 (collect at a1.scala:32) with 1 output partitions
2016-10-12 18:04:04 INFO  DAGScheduler:54 - Final stage: ResultStage 5 (collect at a1.scala:32)
2016-10-12 18:04:04 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 4)
2016-10-12 18:04:04 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 4)
2016-10-12 18:04:04 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 4 (MapPartitionsRDD[10] at map at a1.scala:32), which has no missing parents
2016-10-12 18:04:04 INFO  MemoryStore:54 - Block broadcast_5 stored as values in memory (estimated size 4.0 KB, free 366.0 MB)
2016-10-12 18:04:04 INFO  MemoryStore:54 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.4 KB, free 366.0 MB)
2016-10-12 18:04:04 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on 150.212.30.95:40679 (size: 2.4 KB, free: 366.3 MB)
2016-10-12 18:04:04 INFO  SparkContext:54 - Created broadcast 5 from broadcast at DAGScheduler.scala:1012
2016-10-12 18:04:04 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[10] at map at a1.scala:32)
2016-10-12 18:04:04 INFO  TaskSchedulerImpl:54 - Adding task set 4.0 with 1 tasks
2016-10-12 18:04:04 INFO  TaskSetManager:54 - Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5592 bytes)
2016-10-12 18:04:04 INFO  Executor:54 - Running task 0.0 in stage 4.0 (TID 4)
2016-10-12 18:04:04 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 18:04:04 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 18:04:04 INFO  ContextCleaner:54 - Cleaned shuffle 1
2016-10-12 18:04:04 INFO  BlockManagerInfo:54 - Removed broadcast_3_piece0 on 150.212.30.95:40679 in memory (size: 2.5 KB, free: 366.3 MB)
2016-10-12 18:04:04 INFO  BlockManagerInfo:54 - Removed broadcast_4_piece0 on 150.212.30.95:40679 in memory (size: 2.2 KB, free: 366.3 MB)
2016-10-12 18:04:04 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2016-10-12 18:04:04 INFO  ServerConnector:306 - Stopped ServerConnector@6c67e137{HTTP/1.1}{0.0.0.0:4041}
2016-10-12 18:04:04 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,UNAVAILABLE}
2016-10-12 18:04:04 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@62e70ea3{/api,null,UNAVAILABLE}
2016-10-12 18:04:04 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@28276e50{/,null,UNAVAILABLE}
2016-10-12 18:04:04 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a7471ce{/static,null,UNAVAILABLE}
2016-10-12 18:04:04 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,UNAVAILABLE}
2016-10-12 18:04:04 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,UNAVAILABLE}
2016-10-12 18:04:04 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,UNAVAILABLE}
2016-10-12 18:04:04 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@297ea53a{/executors,null,UNAVAILABLE}
2016-10-12 18:04:04 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,UNAVAILABLE}
2016-10-12 18:04:04 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4052274f{/environment,null,UNAVAILABLE}
2016-10-12 18:04:04 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,UNAVAILABLE}
2016-10-12 18:04:04 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,UNAVAILABLE}
2016-10-12 18:04:04 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,UNAVAILABLE}
2016-10-12 18:04:04 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1643d68f{/storage,null,UNAVAILABLE}
2016-10-12 18:04:04 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,UNAVAILABLE}
2016-10-12 18:04:04 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,UNAVAILABLE}
2016-10-12 18:04:04 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,UNAVAILABLE}
2016-10-12 18:04:04 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,UNAVAILABLE}
2016-10-12 18:04:04 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,UNAVAILABLE}
2016-10-12 18:04:04 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,UNAVAILABLE}
2016-10-12 18:04:04 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,UNAVAILABLE}
2016-10-12 18:04:04 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,UNAVAILABLE}
2016-10-12 18:04:04 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,UNAVAILABLE}
2016-10-12 18:04:04 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,UNAVAILABLE}
2016-10-12 18:04:04 INFO  SparkUI:54 - Stopped Spark web UI at http://150.212.30.95:4041
2016-10-12 18:04:04 INFO  DAGScheduler:54 - Job 2 failed: collect at a1.scala:32, took 0.676972 s
2016-10-12 18:04:04 INFO  DAGScheduler:54 - ShuffleMapStage 4 (map at a1.scala:32) failed in 0.652 s
2016-10-12 18:04:04 ERROR LiveListenerBus:70 - SparkListenerBus has already stopped! Dropping event SparkListenerStageCompleted(org.apache.spark.scheduler.StageInfo@31cd82df)
2016-10-12 18:04:04 ERROR LiveListenerBus:70 - SparkListenerBus has already stopped! Dropping event SparkListenerJobEnd(2,1476309844996,JobFailed(org.apache.spark.SparkException: Job 2 cancelled because SparkContext was shut down))
2016-10-12 18:04:05 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2016-10-12 18:04:05 INFO  MemoryStore:54 - MemoryStore cleared
2016-10-12 18:04:05 INFO  BlockManager:54 - BlockManager stopped
2016-10-12 18:04:05 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2016-10-12 18:04:05 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2016-10-12 18:04:05 INFO  SparkContext:54 - Successfully stopped SparkContext
2016-10-12 18:04:05 INFO  ShutdownHookManager:54 - Shutdown hook called
2016-10-12 18:04:05 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-f66ac101-a788-4c40-8fc9-dfaa3f30f9cf
2016-10-12 18:05:11 INFO  SparkContext:54 - Running Spark version 2.0.0
2016-10-12 18:05:11 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-12 18:05:12 WARN  Utils:66 - Your hostname, aadu-XPS-13-9350 resolves to a loopback address: 127.0.1.1; using 150.212.30.95 instead (on interface wlp58s0)
2016-10-12 18:05:12 WARN  Utils:66 - Set SPARK_LOCAL_IP if you need to bind to another address
2016-10-12 18:05:12 INFO  SecurityManager:54 - Changing view acls to: aadu
2016-10-12 18:05:12 INFO  SecurityManager:54 - Changing modify acls to: aadu
2016-10-12 18:05:12 INFO  SecurityManager:54 - Changing view acls groups to: 
2016-10-12 18:05:12 INFO  SecurityManager:54 - Changing modify acls groups to: 
2016-10-12 18:05:12 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(aadu); groups with view permissions: Set(); users  with modify permissions: Set(aadu); groups with modify permissions: Set()
2016-10-12 18:05:12 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 42695.
2016-10-12 18:05:12 INFO  SparkEnv:54 - Registering MapOutputTracker
2016-10-12 18:05:12 INFO  SparkEnv:54 - Registering BlockManagerMaster
2016-10-12 18:05:12 INFO  DiskBlockManager:54 - Created local directory at /tmp/blockmgr-21fa2031-08e6-40d8-acc5-8589a91bf0b3
2016-10-12 18:05:12 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2016-10-12 18:05:12 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2016-10-12 18:05:12 INFO  log:186 - Logging initialized @1472ms
2016-10-12 18:05:12 INFO  Server:327 - jetty-9.2.z-SNAPSHOT
2016-10-12 18:05:12 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,AVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,AVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,AVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,AVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,AVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,AVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,AVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,AVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,AVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,AVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1643d68f{/storage,null,AVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,AVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,AVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,AVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4052274f{/environment,null,AVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,AVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@297ea53a{/executors,null,AVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,AVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,AVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,AVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a7471ce{/static,null,AVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@28276e50{/,null,AVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@62e70ea3{/api,null,AVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,AVAILABLE}
2016-10-12 18:05:12 WARN  AbstractLifeCycle:212 - FAILED ServerConnector@4fe89c24{HTTP/1.1}{0.0.0.0:4040}: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2071)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2062)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:139)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:451)
	at Assign1$.main(a1.scala:16)
	at Assign1.main(a1.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2016-10-12 18:05:12 WARN  AbstractLifeCycle:212 - FAILED org.spark_project.jetty.server.Server@6175619b: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2071)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2062)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:139)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:451)
	at Assign1$.main(a1.scala:16)
	at Assign1.main(a1.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2016-10-12 18:05:12 INFO  ServerConnector:306 - Stopped ServerConnector@4fe89c24{HTTP/1.1}{0.0.0.0:4040}
2016-10-12 18:05:12 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,UNAVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@62e70ea3{/api,null,UNAVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@28276e50{/,null,UNAVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a7471ce{/static,null,UNAVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,UNAVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,UNAVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,UNAVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@297ea53a{/executors,null,UNAVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,UNAVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4052274f{/environment,null,UNAVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,UNAVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,UNAVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,UNAVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1643d68f{/storage,null,UNAVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,UNAVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,UNAVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,UNAVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,UNAVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,UNAVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,UNAVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,UNAVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,UNAVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,UNAVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,UNAVAILABLE}
2016-10-12 18:05:12 WARN  Utils:66 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2016-10-12 18:05:12 INFO  Server:327 - jetty-9.2.z-SNAPSHOT
2016-10-12 18:05:12 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,AVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,AVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,AVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,AVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,AVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,AVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,AVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,AVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,AVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,AVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1643d68f{/storage,null,AVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,AVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,AVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,AVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4052274f{/environment,null,AVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,AVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@297ea53a{/executors,null,AVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,AVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,AVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,AVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a7471ce{/static,null,AVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@28276e50{/,null,AVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@62e70ea3{/api,null,AVAILABLE}
2016-10-12 18:05:12 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,AVAILABLE}
2016-10-12 18:05:12 INFO  ServerConnector:266 - Started ServerConnector@6c67e137{HTTP/1.1}{0.0.0.0:4041}
2016-10-12 18:05:12 INFO  Server:379 - Started @1626ms
2016-10-12 18:05:12 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4041.
2016-10-12 18:05:12 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://150.212.30.95:4041
2016-10-12 18:05:12 INFO  SparkContext:54 - Added JAR file:/home/aadu/Repos/adam/adam-assembly/target/adam_2.11-0.19.1-SNAPSHOT.jar at spark://150.212.30.95:42695/jars/adam_2.11-0.19.1-SNAPSHOT.jar with timestamp 1476309912723
2016-10-12 18:05:12 INFO  SparkContext:54 - Added JAR file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/a1.jar at spark://150.212.30.95:42695/jars/a1.jar with timestamp 1476309912724
2016-10-12 18:05:12 INFO  Executor:54 - Starting executor ID driver on host localhost
2016-10-12 18:05:12 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34569.
2016-10-12 18:05:12 INFO  NettyBlockTransferService:54 - Server created on 150.212.30.95:34569
2016-10-12 18:05:12 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 150.212.30.95, 34569)
2016-10-12 18:05:12 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 150.212.30.95:34569 with 366.3 MB RAM, BlockManagerId(driver, 150.212.30.95, 34569)
2016-10-12 18:05:12 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 150.212.30.95, 34569)
2016-10-12 18:05:12 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2472c7d8{/metrics/json,null,AVAILABLE}
2016-10-12 18:05:13 INFO  ADAMContext:1336 - Loading small.adam as Parquet containing Genotypes. Sequence dictionary for translation is ignored.
2016-10-12 18:05:13 INFO  ADAMContext:257 - Reading the ADAM file at small.adam to create RDD
2016-10-12 18:05:13 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 268.7 KB, free 366.0 MB)
2016-10-12 18:05:14 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 22.8 KB, free 366.0 MB)
2016-10-12 18:05:14 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 150.212.30.95:34569 (size: 22.8 KB, free: 366.3 MB)
2016-10-12 18:05:14 INFO  SparkContext:54 - Created broadcast 0 from newAPIHadoopFile at ADAMContext.scala:271
2016-10-12 18:05:14 INFO  FileInputFormat:283 - Total input paths to process : 1
2016-10-12 18:05:14 INFO  SparkContext:54 - Starting job: count at a1.scala:30
2016-10-12 18:05:14 INFO  DAGScheduler:54 - Registering RDD 3 (distinct at a1.scala:30)
2016-10-12 18:05:14 INFO  DAGScheduler:54 - Got job 0 (count at a1.scala:30) with 1 output partitions
2016-10-12 18:05:14 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (count at a1.scala:30)
2016-10-12 18:05:14 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 0)
2016-10-12 18:05:14 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 0)
2016-10-12 18:05:14 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at distinct at a1.scala:30), which has no missing parents
2016-10-12 18:05:14 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 4.2 KB, free 366.0 MB)
2016-10-12 18:05:14 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.5 KB, free 366.0 MB)
2016-10-12 18:05:14 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 150.212.30.95:34569 (size: 2.5 KB, free: 366.3 MB)
2016-10-12 18:05:14 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1012
2016-10-12 18:05:14 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at distinct at a1.scala:30)
2016-10-12 18:05:14 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2016-10-12 18:05:14 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5507 bytes)
2016-10-12 18:05:14 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2016-10-12 18:05:14 INFO  Executor:54 - Fetching spark://150.212.30.95:42695/jars/a1.jar with timestamp 1476309912724
2016-10-12 18:05:14 INFO  TransportClientFactory:250 - Successfully created connection to /150.212.30.95:42695 after 37 ms (0 ms spent in bootstraps)
2016-10-12 18:05:14 INFO  Utils:54 - Fetching spark://150.212.30.95:42695/jars/a1.jar to /tmp/spark-6152872f-0a5c-4561-9a0c-2d3d706234eb/userFiles-d1021bde-2063-44b7-809c-29ede91433fc/fetchFileTemp6876863720365534249.tmp
2016-10-12 18:05:14 INFO  Executor:54 - Adding file:/tmp/spark-6152872f-0a5c-4561-9a0c-2d3d706234eb/userFiles-d1021bde-2063-44b7-809c-29ede91433fc/a1.jar to class loader
2016-10-12 18:05:14 INFO  Executor:54 - Fetching spark://150.212.30.95:42695/jars/adam_2.11-0.19.1-SNAPSHOT.jar with timestamp 1476309912723
2016-10-12 18:05:14 INFO  Utils:54 - Fetching spark://150.212.30.95:42695/jars/adam_2.11-0.19.1-SNAPSHOT.jar to /tmp/spark-6152872f-0a5c-4561-9a0c-2d3d706234eb/userFiles-d1021bde-2063-44b7-809c-29ede91433fc/fetchFileTemp988773787124925223.tmp
2016-10-12 18:05:14 INFO  Executor:54 - Adding file:/tmp/spark-6152872f-0a5c-4561-9a0c-2d3d706234eb/userFiles-d1021bde-2063-44b7-809c-29ede91433fc/adam_2.11-0.19.1-SNAPSHOT.jar to class loader
2016-10-12 18:05:14 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 18:05:14 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 18:05:18 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1490 bytes result sent to driver
2016-10-12 18:05:18 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 4214 ms on localhost (1/1)
2016-10-12 18:05:18 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2016-10-12 18:05:18 INFO  DAGScheduler:54 - ShuffleMapStage 0 (distinct at a1.scala:30) finished in 4.228 s
2016-10-12 18:05:18 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 18:05:18 INFO  DAGScheduler:54 - running: Set()
2016-10-12 18:05:18 INFO  DAGScheduler:54 - waiting: Set(ResultStage 1)
2016-10-12 18:05:18 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 18:05:18 INFO  DAGScheduler:54 - Submitting ResultStage 1 (MapPartitionsRDD[5] at distinct at a1.scala:30), which has no missing parents
2016-10-12 18:05:18 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 3.7 KB, free 366.0 MB)
2016-10-12 18:05:18 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.2 KB, free 366.0 MB)
2016-10-12 18:05:18 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on 150.212.30.95:34569 (size: 2.2 KB, free: 366.3 MB)
2016-10-12 18:05:18 INFO  SparkContext:54 - Created broadcast 2 from broadcast at DAGScheduler.scala:1012
2016-10-12 18:05:18 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at distinct at a1.scala:30)
2016-10-12 18:05:18 INFO  TaskSchedulerImpl:54 - Adding task set 1.0 with 1 tasks
2016-10-12 18:05:18 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, ANY, 5177 bytes)
2016-10-12 18:05:18 INFO  Executor:54 - Running task 0.0 in stage 1.0 (TID 1)
2016-10-12 18:05:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 18:05:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 3 ms
2016-10-12 18:05:18 INFO  Executor:54 - Finished task 0.0 in stage 1.0 (TID 1). 1512 bytes result sent to driver
2016-10-12 18:05:18 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 1) in 86 ms on localhost (1/1)
2016-10-12 18:05:18 INFO  DAGScheduler:54 - ResultStage 1 (count at a1.scala:30) finished in 0.086 s
2016-10-12 18:05:18 INFO  TaskSchedulerImpl:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2016-10-12 18:05:18 INFO  DAGScheduler:54 - Job 0 finished: count at a1.scala:30, took 4.497830 s
2016-10-12 18:05:18 INFO  SparkContext:54 - Starting job: count at a1.scala:31
2016-10-12 18:05:18 INFO  DAGScheduler:54 - Registering RDD 7 (distinct at a1.scala:31)
2016-10-12 18:05:18 INFO  DAGScheduler:54 - Got job 1 (count at a1.scala:31) with 1 output partitions
2016-10-12 18:05:18 INFO  DAGScheduler:54 - Final stage: ResultStage 3 (count at a1.scala:31)
2016-10-12 18:05:18 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 2)
2016-10-12 18:05:18 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 2)
2016-10-12 18:05:18 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 2 (MapPartitionsRDD[7] at distinct at a1.scala:31), which has no missing parents
2016-10-12 18:05:18 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 4.2 KB, free 366.0 MB)
2016-10-12 18:05:18 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.5 KB, free 366.0 MB)
2016-10-12 18:05:18 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on 150.212.30.95:34569 (size: 2.5 KB, free: 366.3 MB)
2016-10-12 18:05:18 INFO  SparkContext:54 - Created broadcast 3 from broadcast at DAGScheduler.scala:1012
2016-10-12 18:05:18 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[7] at distinct at a1.scala:31)
2016-10-12 18:05:18 INFO  TaskSchedulerImpl:54 - Adding task set 2.0 with 1 tasks
2016-10-12 18:05:18 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5507 bytes)
2016-10-12 18:05:18 INFO  Executor:54 - Running task 0.0 in stage 2.0 (TID 2)
2016-10-12 18:05:18 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 18:05:18 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 18:05:19 INFO  ContextCleaner:54 - Cleaned shuffle 0
2016-10-12 18:05:19 INFO  BlockManagerInfo:54 - Removed broadcast_1_piece0 on 150.212.30.95:34569 in memory (size: 2.5 KB, free: 366.3 MB)
2016-10-12 18:05:19 INFO  BlockManagerInfo:54 - Removed broadcast_2_piece0 on 150.212.30.95:34569 in memory (size: 2.2 KB, free: 366.3 MB)
2016-10-12 18:05:22 INFO  Executor:54 - Finished task 0.0 in stage 2.0 (TID 2). 1490 bytes result sent to driver
2016-10-12 18:05:22 INFO  TaskSetManager:54 - Finished task 0.0 in stage 2.0 (TID 2) in 3795 ms on localhost (1/1)
2016-10-12 18:05:22 INFO  TaskSchedulerImpl:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2016-10-12 18:05:22 INFO  DAGScheduler:54 - ShuffleMapStage 2 (distinct at a1.scala:31) finished in 3.798 s
2016-10-12 18:05:22 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 18:05:22 INFO  DAGScheduler:54 - running: Set()
2016-10-12 18:05:22 INFO  DAGScheduler:54 - waiting: Set(ResultStage 3)
2016-10-12 18:05:22 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 18:05:22 INFO  DAGScheduler:54 - Submitting ResultStage 3 (MapPartitionsRDD[9] at distinct at a1.scala:31), which has no missing parents
2016-10-12 18:05:22 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 3.8 KB, free 366.0 MB)
2016-10-12 18:05:22 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.2 KB, free 366.0 MB)
2016-10-12 18:05:22 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on 150.212.30.95:34569 (size: 2.2 KB, free: 366.3 MB)
2016-10-12 18:05:22 INFO  SparkContext:54 - Created broadcast 4 from broadcast at DAGScheduler.scala:1012
2016-10-12 18:05:22 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[9] at distinct at a1.scala:31)
2016-10-12 18:05:22 INFO  TaskSchedulerImpl:54 - Adding task set 3.0 with 1 tasks
2016-10-12 18:05:22 INFO  TaskSetManager:54 - Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, ANY, 5177 bytes)
2016-10-12 18:05:22 INFO  Executor:54 - Running task 0.0 in stage 3.0 (TID 3)
2016-10-12 18:05:22 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 18:05:22 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2016-10-12 18:05:22 INFO  Executor:54 - Finished task 0.0 in stage 3.0 (TID 3). 1512 bytes result sent to driver
2016-10-12 18:05:22 INFO  TaskSetManager:54 - Finished task 0.0 in stage 3.0 (TID 3) in 104 ms on localhost (1/1)
2016-10-12 18:05:22 INFO  TaskSchedulerImpl:54 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2016-10-12 18:05:22 INFO  DAGScheduler:54 - ResultStage 3 (count at a1.scala:31) finished in 0.109 s
2016-10-12 18:05:22 INFO  DAGScheduler:54 - Job 1 finished: count at a1.scala:31, took 3.983703 s
2016-10-12 18:05:22 INFO  SparkContext:54 - Starting job: collect at a1.scala:32
2016-10-12 18:05:22 INFO  DAGScheduler:54 - Registering RDD 10 (map at a1.scala:32)
2016-10-12 18:05:22 INFO  DAGScheduler:54 - Got job 2 (collect at a1.scala:32) with 1 output partitions
2016-10-12 18:05:22 INFO  DAGScheduler:54 - Final stage: ResultStage 5 (collect at a1.scala:32)
2016-10-12 18:05:22 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 4)
2016-10-12 18:05:22 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 4)
2016-10-12 18:05:22 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 4 (MapPartitionsRDD[10] at map at a1.scala:32), which has no missing parents
2016-10-12 18:05:22 INFO  MemoryStore:54 - Block broadcast_5 stored as values in memory (estimated size 4.0 KB, free 366.0 MB)
2016-10-12 18:05:22 INFO  MemoryStore:54 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.4 KB, free 366.0 MB)
2016-10-12 18:05:22 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on 150.212.30.95:34569 (size: 2.4 KB, free: 366.3 MB)
2016-10-12 18:05:22 INFO  SparkContext:54 - Created broadcast 5 from broadcast at DAGScheduler.scala:1012
2016-10-12 18:05:22 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[10] at map at a1.scala:32)
2016-10-12 18:05:22 INFO  TaskSchedulerImpl:54 - Adding task set 4.0 with 1 tasks
2016-10-12 18:05:22 INFO  TaskSetManager:54 - Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5592 bytes)
2016-10-12 18:05:22 INFO  Executor:54 - Running task 0.0 in stage 4.0 (TID 4)
2016-10-12 18:05:22 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 18:05:22 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 18:05:23 INFO  ContextCleaner:54 - Cleaned shuffle 1
2016-10-12 18:05:23 INFO  BlockManagerInfo:54 - Removed broadcast_3_piece0 on 150.212.30.95:34569 in memory (size: 2.5 KB, free: 366.3 MB)
2016-10-12 18:05:23 INFO  BlockManagerInfo:54 - Removed broadcast_4_piece0 on 150.212.30.95:34569 in memory (size: 2.2 KB, free: 366.3 MB)
2016-10-12 18:05:26 INFO  Executor:54 - Finished task 0.0 in stage 4.0 (TID 4). 1490 bytes result sent to driver
2016-10-12 18:05:26 INFO  TaskSetManager:54 - Finished task 0.0 in stage 4.0 (TID 4) in 3812 ms on localhost (1/1)
2016-10-12 18:05:26 INFO  DAGScheduler:54 - ShuffleMapStage 4 (map at a1.scala:32) finished in 3.813 s
2016-10-12 18:05:26 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 18:05:26 INFO  DAGScheduler:54 - running: Set()
2016-10-12 18:05:26 INFO  DAGScheduler:54 - waiting: Set(ResultStage 5)
2016-10-12 18:05:26 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 18:05:26 INFO  DAGScheduler:54 - Submitting ResultStage 5 (MapPartitionsRDD[13] at map at a1.scala:32), which has no missing parents
2016-10-12 18:05:26 INFO  MemoryStore:54 - Block broadcast_6 stored as values in memory (estimated size 3.8 KB, free 366.0 MB)
2016-10-12 18:05:26 INFO  TaskSchedulerImpl:54 - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2016-10-12 18:05:26 INFO  MemoryStore:54 - Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.2 KB, free 366.0 MB)
2016-10-12 18:05:26 INFO  BlockManagerInfo:54 - Added broadcast_6_piece0 in memory on 150.212.30.95:34569 (size: 2.2 KB, free: 366.3 MB)
2016-10-12 18:05:26 INFO  SparkContext:54 - Created broadcast 6 from broadcast at DAGScheduler.scala:1012
2016-10-12 18:05:26 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[13] at map at a1.scala:32)
2016-10-12 18:05:26 INFO  TaskSchedulerImpl:54 - Adding task set 5.0 with 1 tasks
2016-10-12 18:05:26 INFO  TaskSetManager:54 - Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, ANY, 5262 bytes)
2016-10-12 18:05:26 INFO  Executor:54 - Running task 0.0 in stage 5.0 (TID 5)
2016-10-12 18:05:26 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 18:05:26 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2016-10-12 18:05:26 INFO  Executor:54 - Finished task 0.0 in stage 5.0 (TID 5). 9861 bytes result sent to driver
2016-10-12 18:05:26 INFO  DAGScheduler:54 - ResultStage 5 (collect at a1.scala:32) finished in 0.054 s
2016-10-12 18:05:26 INFO  TaskSetManager:54 - Finished task 0.0 in stage 5.0 (TID 5) in 54 ms on localhost (1/1)
2016-10-12 18:05:26 INFO  DAGScheduler:54 - Job 2 finished: collect at a1.scala:32, took 3.919792 s
2016-10-12 18:05:26 INFO  TaskSchedulerImpl:54 - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2016-10-12 18:05:26 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2016-10-12 18:05:26 INFO  ServerConnector:306 - Stopped ServerConnector@6c67e137{HTTP/1.1}{0.0.0.0:4041}
2016-10-12 18:05:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,UNAVAILABLE}
2016-10-12 18:05:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@62e70ea3{/api,null,UNAVAILABLE}
2016-10-12 18:05:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@28276e50{/,null,UNAVAILABLE}
2016-10-12 18:05:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a7471ce{/static,null,UNAVAILABLE}
2016-10-12 18:05:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,UNAVAILABLE}
2016-10-12 18:05:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,UNAVAILABLE}
2016-10-12 18:05:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,UNAVAILABLE}
2016-10-12 18:05:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@297ea53a{/executors,null,UNAVAILABLE}
2016-10-12 18:05:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,UNAVAILABLE}
2016-10-12 18:05:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4052274f{/environment,null,UNAVAILABLE}
2016-10-12 18:05:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,UNAVAILABLE}
2016-10-12 18:05:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,UNAVAILABLE}
2016-10-12 18:05:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,UNAVAILABLE}
2016-10-12 18:05:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1643d68f{/storage,null,UNAVAILABLE}
2016-10-12 18:05:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,UNAVAILABLE}
2016-10-12 18:05:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,UNAVAILABLE}
2016-10-12 18:05:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,UNAVAILABLE}
2016-10-12 18:05:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,UNAVAILABLE}
2016-10-12 18:05:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,UNAVAILABLE}
2016-10-12 18:05:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,UNAVAILABLE}
2016-10-12 18:05:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,UNAVAILABLE}
2016-10-12 18:05:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,UNAVAILABLE}
2016-10-12 18:05:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,UNAVAILABLE}
2016-10-12 18:05:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,UNAVAILABLE}
2016-10-12 18:05:26 INFO  SparkUI:54 - Stopped Spark web UI at http://150.212.30.95:4041
2016-10-12 18:05:26 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2016-10-12 18:05:26 INFO  MemoryStore:54 - MemoryStore cleared
2016-10-12 18:05:26 INFO  BlockManager:54 - BlockManager stopped
2016-10-12 18:05:26 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2016-10-12 18:05:26 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2016-10-12 18:05:26 INFO  SparkContext:54 - Successfully stopped SparkContext
2016-10-12 18:05:26 INFO  ShutdownHookManager:54 - Shutdown hook called
2016-10-12 18:05:26 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-6152872f-0a5c-4561-9a0c-2d3d706234eb
2016-10-12 18:05:56 INFO  SparkContext:54 - Running Spark version 2.0.0
2016-10-12 18:05:57 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-12 18:05:57 WARN  Utils:66 - Your hostname, aadu-XPS-13-9350 resolves to a loopback address: 127.0.1.1; using 150.212.30.95 instead (on interface wlp58s0)
2016-10-12 18:05:57 WARN  Utils:66 - Set SPARK_LOCAL_IP if you need to bind to another address
2016-10-12 18:05:57 INFO  SecurityManager:54 - Changing view acls to: aadu
2016-10-12 18:05:57 INFO  SecurityManager:54 - Changing modify acls to: aadu
2016-10-12 18:05:57 INFO  SecurityManager:54 - Changing view acls groups to: 
2016-10-12 18:05:57 INFO  SecurityManager:54 - Changing modify acls groups to: 
2016-10-12 18:05:57 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(aadu); groups with view permissions: Set(); users  with modify permissions: Set(aadu); groups with modify permissions: Set()
2016-10-12 18:05:57 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 37671.
2016-10-12 18:05:57 INFO  SparkEnv:54 - Registering MapOutputTracker
2016-10-12 18:05:57 INFO  SparkEnv:54 - Registering BlockManagerMaster
2016-10-12 18:05:57 INFO  DiskBlockManager:54 - Created local directory at /tmp/blockmgr-609dd44c-448b-4118-aa3d-f1141e309a96
2016-10-12 18:05:57 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2016-10-12 18:05:57 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2016-10-12 18:05:57 INFO  log:186 - Logging initialized @1509ms
2016-10-12 18:05:57 INFO  Server:327 - jetty-9.2.z-SNAPSHOT
2016-10-12 18:05:58 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,AVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,AVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,AVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,AVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,AVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,AVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,AVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,AVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,AVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,AVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1643d68f{/storage,null,AVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,AVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,AVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,AVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4052274f{/environment,null,AVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,AVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@297ea53a{/executors,null,AVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,AVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,AVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,AVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a7471ce{/static,null,AVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@28276e50{/,null,AVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@62e70ea3{/api,null,AVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,AVAILABLE}
2016-10-12 18:05:58 WARN  AbstractLifeCycle:212 - FAILED ServerConnector@4fe89c24{HTTP/1.1}{0.0.0.0:4040}: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2071)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2062)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:139)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:451)
	at Assign1$.main(a1.scala:16)
	at Assign1.main(a1.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2016-10-12 18:05:58 WARN  AbstractLifeCycle:212 - FAILED org.spark_project.jetty.server.Server@6175619b: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2071)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2062)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:139)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:451)
	at Assign1$.main(a1.scala:16)
	at Assign1.main(a1.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2016-10-12 18:05:58 INFO  ServerConnector:306 - Stopped ServerConnector@4fe89c24{HTTP/1.1}{0.0.0.0:4040}
2016-10-12 18:05:58 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,UNAVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@62e70ea3{/api,null,UNAVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@28276e50{/,null,UNAVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a7471ce{/static,null,UNAVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,UNAVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,UNAVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,UNAVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@297ea53a{/executors,null,UNAVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,UNAVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4052274f{/environment,null,UNAVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,UNAVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,UNAVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,UNAVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1643d68f{/storage,null,UNAVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,UNAVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,UNAVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,UNAVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,UNAVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,UNAVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,UNAVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,UNAVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,UNAVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,UNAVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,UNAVAILABLE}
2016-10-12 18:05:58 WARN  Utils:66 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2016-10-12 18:05:58 INFO  Server:327 - jetty-9.2.z-SNAPSHOT
2016-10-12 18:05:58 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,AVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,AVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,AVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,AVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,AVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,AVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,AVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,AVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,AVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,AVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1643d68f{/storage,null,AVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,AVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,AVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,AVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4052274f{/environment,null,AVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,AVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@297ea53a{/executors,null,AVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,AVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,AVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,AVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a7471ce{/static,null,AVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@28276e50{/,null,AVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@62e70ea3{/api,null,AVAILABLE}
2016-10-12 18:05:58 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,AVAILABLE}
2016-10-12 18:05:58 INFO  ServerConnector:266 - Started ServerConnector@6c67e137{HTTP/1.1}{0.0.0.0:4041}
2016-10-12 18:05:58 INFO  Server:379 - Started @1666ms
2016-10-12 18:05:58 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4041.
2016-10-12 18:05:58 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://150.212.30.95:4041
2016-10-12 18:05:58 INFO  SparkContext:54 - Added JAR file:/home/aadu/Repos/adam/adam-assembly/target/adam_2.11-0.19.1-SNAPSHOT.jar at spark://150.212.30.95:37671/jars/adam_2.11-0.19.1-SNAPSHOT.jar with timestamp 1476309958117
2016-10-12 18:05:58 INFO  SparkContext:54 - Added JAR file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/a1.jar at spark://150.212.30.95:37671/jars/a1.jar with timestamp 1476309958119
2016-10-12 18:05:58 INFO  Executor:54 - Starting executor ID driver on host localhost
2016-10-12 18:05:58 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39712.
2016-10-12 18:05:58 INFO  NettyBlockTransferService:54 - Server created on 150.212.30.95:39712
2016-10-12 18:05:58 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 150.212.30.95, 39712)
2016-10-12 18:05:58 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 150.212.30.95:39712 with 366.3 MB RAM, BlockManagerId(driver, 150.212.30.95, 39712)
2016-10-12 18:05:58 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 150.212.30.95, 39712)
2016-10-12 18:05:58 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2472c7d8{/metrics/json,null,AVAILABLE}
2016-10-12 18:05:58 INFO  ADAMContext:1336 - Loading small.adam as Parquet containing Genotypes. Sequence dictionary for translation is ignored.
2016-10-12 18:05:58 INFO  ADAMContext:257 - Reading the ADAM file at small.adam to create RDD
2016-10-12 18:05:58 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 268.7 KB, free 366.0 MB)
2016-10-12 18:05:59 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 22.8 KB, free 366.0 MB)
2016-10-12 18:05:59 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 150.212.30.95:39712 (size: 22.8 KB, free: 366.3 MB)
2016-10-12 18:05:59 INFO  SparkContext:54 - Created broadcast 0 from newAPIHadoopFile at ADAMContext.scala:271
2016-10-12 18:05:59 INFO  FileInputFormat:283 - Total input paths to process : 1
2016-10-12 18:05:59 INFO  SparkContext:54 - Starting job: count at a1.scala:30
2016-10-12 18:05:59 INFO  DAGScheduler:54 - Registering RDD 3 (distinct at a1.scala:30)
2016-10-12 18:05:59 INFO  DAGScheduler:54 - Got job 0 (count at a1.scala:30) with 1 output partitions
2016-10-12 18:05:59 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (count at a1.scala:30)
2016-10-12 18:05:59 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 0)
2016-10-12 18:05:59 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 0)
2016-10-12 18:05:59 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at distinct at a1.scala:30), which has no missing parents
2016-10-12 18:05:59 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 4.2 KB, free 366.0 MB)
2016-10-12 18:05:59 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.5 KB, free 366.0 MB)
2016-10-12 18:05:59 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 150.212.30.95:39712 (size: 2.5 KB, free: 366.3 MB)
2016-10-12 18:05:59 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1012
2016-10-12 18:05:59 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at distinct at a1.scala:30)
2016-10-12 18:05:59 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2016-10-12 18:05:59 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5507 bytes)
2016-10-12 18:05:59 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2016-10-12 18:05:59 INFO  Executor:54 - Fetching spark://150.212.30.95:37671/jars/a1.jar with timestamp 1476309958119
2016-10-12 18:05:59 INFO  TransportClientFactory:250 - Successfully created connection to /150.212.30.95:37671 after 30 ms (0 ms spent in bootstraps)
2016-10-12 18:05:59 INFO  Utils:54 - Fetching spark://150.212.30.95:37671/jars/a1.jar to /tmp/spark-8d65a5cd-5945-45f0-832e-5048295f0b7d/userFiles-fa204e2a-7e3c-430b-8f86-83fd981c02e4/fetchFileTemp3558884560491551702.tmp
2016-10-12 18:05:59 INFO  Executor:54 - Adding file:/tmp/spark-8d65a5cd-5945-45f0-832e-5048295f0b7d/userFiles-fa204e2a-7e3c-430b-8f86-83fd981c02e4/a1.jar to class loader
2016-10-12 18:05:59 INFO  Executor:54 - Fetching spark://150.212.30.95:37671/jars/adam_2.11-0.19.1-SNAPSHOT.jar with timestamp 1476309958117
2016-10-12 18:05:59 INFO  Utils:54 - Fetching spark://150.212.30.95:37671/jars/adam_2.11-0.19.1-SNAPSHOT.jar to /tmp/spark-8d65a5cd-5945-45f0-832e-5048295f0b7d/userFiles-fa204e2a-7e3c-430b-8f86-83fd981c02e4/fetchFileTemp5366455646257801572.tmp
2016-10-12 18:06:00 INFO  Executor:54 - Adding file:/tmp/spark-8d65a5cd-5945-45f0-832e-5048295f0b7d/userFiles-fa204e2a-7e3c-430b-8f86-83fd981c02e4/adam_2.11-0.19.1-SNAPSHOT.jar to class loader
2016-10-12 18:06:00 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 18:06:00 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 18:06:02 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2016-10-12 18:06:02 INFO  ServerConnector:306 - Stopped ServerConnector@6c67e137{HTTP/1.1}{0.0.0.0:4041}
2016-10-12 18:06:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,UNAVAILABLE}
2016-10-12 18:06:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@62e70ea3{/api,null,UNAVAILABLE}
2016-10-12 18:06:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@28276e50{/,null,UNAVAILABLE}
2016-10-12 18:06:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a7471ce{/static,null,UNAVAILABLE}
2016-10-12 18:06:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,UNAVAILABLE}
2016-10-12 18:06:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,UNAVAILABLE}
2016-10-12 18:06:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,UNAVAILABLE}
2016-10-12 18:06:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@297ea53a{/executors,null,UNAVAILABLE}
2016-10-12 18:06:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,UNAVAILABLE}
2016-10-12 18:06:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4052274f{/environment,null,UNAVAILABLE}
2016-10-12 18:06:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,UNAVAILABLE}
2016-10-12 18:06:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,UNAVAILABLE}
2016-10-12 18:06:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,UNAVAILABLE}
2016-10-12 18:06:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1643d68f{/storage,null,UNAVAILABLE}
2016-10-12 18:06:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,UNAVAILABLE}
2016-10-12 18:06:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,UNAVAILABLE}
2016-10-12 18:06:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,UNAVAILABLE}
2016-10-12 18:06:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,UNAVAILABLE}
2016-10-12 18:06:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,UNAVAILABLE}
2016-10-12 18:06:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,UNAVAILABLE}
2016-10-12 18:06:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,UNAVAILABLE}
2016-10-12 18:06:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,UNAVAILABLE}
2016-10-12 18:06:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,UNAVAILABLE}
2016-10-12 18:06:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,UNAVAILABLE}
2016-10-12 18:06:02 INFO  SparkUI:54 - Stopped Spark web UI at http://150.212.30.95:4041
2016-10-12 18:06:02 INFO  DAGScheduler:54 - Job 0 failed: count at a1.scala:30, took 3.244164 s
2016-10-12 18:06:02 INFO  DAGScheduler:54 - ShuffleMapStage 0 (distinct at a1.scala:30) failed in 3.106 s
2016-10-12 18:06:02 ERROR LiveListenerBus:70 - SparkListenerBus has already stopped! Dropping event SparkListenerStageCompleted(org.apache.spark.scheduler.StageInfo@66798ea3)
2016-10-12 18:06:02 ERROR LiveListenerBus:70 - SparkListenerBus has already stopped! Dropping event SparkListenerJobEnd(0,1476309962862,JobFailed(org.apache.spark.SparkException: Job 0 cancelled because SparkContext was shut down))
2016-10-12 18:06:02 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2016-10-12 18:06:02 INFO  MemoryStore:54 - MemoryStore cleared
2016-10-12 18:06:02 INFO  BlockManager:54 - BlockManager stopped
2016-10-12 18:06:02 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2016-10-12 18:06:02 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2016-10-12 18:06:02 INFO  SparkContext:54 - Successfully stopped SparkContext
2016-10-12 18:06:02 INFO  ShutdownHookManager:54 - Shutdown hook called
2016-10-12 18:06:02 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-8d65a5cd-5945-45f0-832e-5048295f0b7d
2016-10-12 18:06:25 INFO  SparkContext:54 - Running Spark version 2.0.0
2016-10-12 18:06:26 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-12 18:06:26 WARN  Utils:66 - Your hostname, aadu-XPS-13-9350 resolves to a loopback address: 127.0.1.1; using 150.212.30.95 instead (on interface wlp58s0)
2016-10-12 18:06:26 WARN  Utils:66 - Set SPARK_LOCAL_IP if you need to bind to another address
2016-10-12 18:06:26 INFO  SecurityManager:54 - Changing view acls to: aadu
2016-10-12 18:06:26 INFO  SecurityManager:54 - Changing modify acls to: aadu
2016-10-12 18:06:26 INFO  SecurityManager:54 - Changing view acls groups to: 
2016-10-12 18:06:26 INFO  SecurityManager:54 - Changing modify acls groups to: 
2016-10-12 18:06:26 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(aadu); groups with view permissions: Set(); users  with modify permissions: Set(aadu); groups with modify permissions: Set()
2016-10-12 18:06:26 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 41587.
2016-10-12 18:06:26 INFO  SparkEnv:54 - Registering MapOutputTracker
2016-10-12 18:06:26 INFO  SparkEnv:54 - Registering BlockManagerMaster
2016-10-12 18:06:26 INFO  DiskBlockManager:54 - Created local directory at /tmp/blockmgr-1a1b66c9-5cd7-4162-aabc-fa8873461a21
2016-10-12 18:06:26 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2016-10-12 18:06:26 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2016-10-12 18:06:26 INFO  log:186 - Logging initialized @1481ms
2016-10-12 18:06:26 INFO  Server:327 - jetty-9.2.z-SNAPSHOT
2016-10-12 18:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,AVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,AVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,AVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,AVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,AVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,AVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,AVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,AVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,AVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,AVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1643d68f{/storage,null,AVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,AVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,AVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,AVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4052274f{/environment,null,AVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,AVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@297ea53a{/executors,null,AVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,AVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,AVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,AVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a7471ce{/static,null,AVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@28276e50{/,null,AVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@62e70ea3{/api,null,AVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,AVAILABLE}
2016-10-12 18:06:26 WARN  AbstractLifeCycle:212 - FAILED ServerConnector@4fe89c24{HTTP/1.1}{0.0.0.0:4040}: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2071)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2062)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:139)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:451)
	at Assign1$.main(a1.scala:16)
	at Assign1.main(a1.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2016-10-12 18:06:26 WARN  AbstractLifeCycle:212 - FAILED org.spark_project.jetty.server.Server@6175619b: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2071)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2062)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:139)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:451)
	at Assign1$.main(a1.scala:16)
	at Assign1.main(a1.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2016-10-12 18:06:26 INFO  ServerConnector:306 - Stopped ServerConnector@4fe89c24{HTTP/1.1}{0.0.0.0:4040}
2016-10-12 18:06:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,UNAVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@62e70ea3{/api,null,UNAVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@28276e50{/,null,UNAVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a7471ce{/static,null,UNAVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,UNAVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,UNAVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,UNAVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@297ea53a{/executors,null,UNAVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,UNAVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4052274f{/environment,null,UNAVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,UNAVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,UNAVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,UNAVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1643d68f{/storage,null,UNAVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,UNAVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,UNAVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,UNAVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,UNAVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,UNAVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,UNAVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,UNAVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,UNAVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,UNAVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,UNAVAILABLE}
2016-10-12 18:06:26 WARN  Utils:66 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2016-10-12 18:06:26 INFO  Server:327 - jetty-9.2.z-SNAPSHOT
2016-10-12 18:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,AVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,AVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,AVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,AVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,AVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,AVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,AVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,AVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,AVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,AVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1643d68f{/storage,null,AVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,AVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,AVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,AVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4052274f{/environment,null,AVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,AVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@297ea53a{/executors,null,AVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,AVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,AVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,AVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a7471ce{/static,null,AVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@28276e50{/,null,AVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@62e70ea3{/api,null,AVAILABLE}
2016-10-12 18:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,AVAILABLE}
2016-10-12 18:06:26 INFO  ServerConnector:266 - Started ServerConnector@6c67e137{HTTP/1.1}{0.0.0.0:4041}
2016-10-12 18:06:26 INFO  Server:379 - Started @1640ms
2016-10-12 18:06:26 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4041.
2016-10-12 18:06:26 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://150.212.30.95:4041
2016-10-12 18:06:26 INFO  SparkContext:54 - Added JAR file:/home/aadu/Repos/adam/adam-assembly/target/adam_2.11-0.19.1-SNAPSHOT.jar at spark://150.212.30.95:41587/jars/adam_2.11-0.19.1-SNAPSHOT.jar with timestamp 1476309986984
2016-10-12 18:06:26 INFO  SparkContext:54 - Added JAR file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/a1.jar at spark://150.212.30.95:41587/jars/a1.jar with timestamp 1476309986986
2016-10-12 18:06:27 INFO  Executor:54 - Starting executor ID driver on host localhost
2016-10-12 18:06:27 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43023.
2016-10-12 18:06:27 INFO  NettyBlockTransferService:54 - Server created on 150.212.30.95:43023
2016-10-12 18:06:27 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 150.212.30.95, 43023)
2016-10-12 18:06:27 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 150.212.30.95:43023 with 366.3 MB RAM, BlockManagerId(driver, 150.212.30.95, 43023)
2016-10-12 18:06:27 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 150.212.30.95, 43023)
2016-10-12 18:06:27 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2472c7d8{/metrics/json,null,AVAILABLE}
2016-10-12 18:06:27 INFO  ADAMContext:1336 - Loading small.adam as Parquet containing Genotypes. Sequence dictionary for translation is ignored.
2016-10-12 18:06:27 INFO  ADAMContext:257 - Reading the ADAM file at small.adam to create RDD
2016-10-12 18:06:27 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 268.7 KB, free 366.0 MB)
2016-10-12 18:06:28 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 22.8 KB, free 366.0 MB)
2016-10-12 18:06:28 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 150.212.30.95:43023 (size: 22.8 KB, free: 366.3 MB)
2016-10-12 18:06:28 INFO  SparkContext:54 - Created broadcast 0 from newAPIHadoopFile at ADAMContext.scala:271
2016-10-12 18:06:28 INFO  FileInputFormat:283 - Total input paths to process : 1
2016-10-12 18:06:28 INFO  SparkContext:54 - Starting job: count at a1.scala:30
2016-10-12 18:06:28 INFO  DAGScheduler:54 - Registering RDD 3 (distinct at a1.scala:30)
2016-10-12 18:06:28 INFO  DAGScheduler:54 - Got job 0 (count at a1.scala:30) with 1 output partitions
2016-10-12 18:06:28 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (count at a1.scala:30)
2016-10-12 18:06:28 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 0)
2016-10-12 18:06:28 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 0)
2016-10-12 18:06:28 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at distinct at a1.scala:30), which has no missing parents
2016-10-12 18:06:28 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 4.2 KB, free 366.0 MB)
2016-10-12 18:06:28 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.5 KB, free 366.0 MB)
2016-10-12 18:06:28 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 150.212.30.95:43023 (size: 2.5 KB, free: 366.3 MB)
2016-10-12 18:06:28 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1012
2016-10-12 18:06:28 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at distinct at a1.scala:30)
2016-10-12 18:06:28 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2016-10-12 18:06:28 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5507 bytes)
2016-10-12 18:06:28 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2016-10-12 18:06:28 INFO  Executor:54 - Fetching spark://150.212.30.95:41587/jars/adam_2.11-0.19.1-SNAPSHOT.jar with timestamp 1476309986984
2016-10-12 18:06:28 INFO  TransportClientFactory:250 - Successfully created connection to /150.212.30.95:41587 after 28 ms (0 ms spent in bootstraps)
2016-10-12 18:06:28 INFO  Utils:54 - Fetching spark://150.212.30.95:41587/jars/adam_2.11-0.19.1-SNAPSHOT.jar to /tmp/spark-66a1279c-63c5-444d-8c90-e44eb3b75159/userFiles-4780e8b2-4d8e-4c86-bacd-f921d3aeef45/fetchFileTemp2580044797684176006.tmp
2016-10-12 18:06:29 INFO  Executor:54 - Adding file:/tmp/spark-66a1279c-63c5-444d-8c90-e44eb3b75159/userFiles-4780e8b2-4d8e-4c86-bacd-f921d3aeef45/adam_2.11-0.19.1-SNAPSHOT.jar to class loader
2016-10-12 18:06:29 INFO  Executor:54 - Fetching spark://150.212.30.95:41587/jars/a1.jar with timestamp 1476309986986
2016-10-12 18:06:29 INFO  Utils:54 - Fetching spark://150.212.30.95:41587/jars/a1.jar to /tmp/spark-66a1279c-63c5-444d-8c90-e44eb3b75159/userFiles-4780e8b2-4d8e-4c86-bacd-f921d3aeef45/fetchFileTemp6317263823545242856.tmp
2016-10-12 18:06:29 INFO  Executor:54 - Adding file:/tmp/spark-66a1279c-63c5-444d-8c90-e44eb3b75159/userFiles-4780e8b2-4d8e-4c86-bacd-f921d3aeef45/a1.jar to class loader
2016-10-12 18:06:29 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 18:06:29 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 18:06:32 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1490 bytes result sent to driver
2016-10-12 18:06:32 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 4197 ms on localhost (1/1)
2016-10-12 18:06:32 INFO  DAGScheduler:54 - ShuffleMapStage 0 (distinct at a1.scala:30) finished in 4.210 s
2016-10-12 18:06:32 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 18:06:32 INFO  DAGScheduler:54 - running: Set()
2016-10-12 18:06:32 INFO  DAGScheduler:54 - waiting: Set(ResultStage 1)
2016-10-12 18:06:32 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 18:06:32 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2016-10-12 18:06:32 INFO  DAGScheduler:54 - Submitting ResultStage 1 (MapPartitionsRDD[5] at distinct at a1.scala:30), which has no missing parents
2016-10-12 18:06:32 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 3.7 KB, free 366.0 MB)
2016-10-12 18:06:33 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.2 KB, free 366.0 MB)
2016-10-12 18:06:33 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on 150.212.30.95:43023 (size: 2.2 KB, free: 366.3 MB)
2016-10-12 18:06:33 INFO  SparkContext:54 - Created broadcast 2 from broadcast at DAGScheduler.scala:1012
2016-10-12 18:06:33 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at distinct at a1.scala:30)
2016-10-12 18:06:33 INFO  TaskSchedulerImpl:54 - Adding task set 1.0 with 1 tasks
2016-10-12 18:06:33 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, ANY, 5177 bytes)
2016-10-12 18:06:33 INFO  Executor:54 - Running task 0.0 in stage 1.0 (TID 1)
2016-10-12 18:06:33 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 18:06:33 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 5 ms
2016-10-12 18:06:33 INFO  Executor:54 - Finished task 0.0 in stage 1.0 (TID 1). 1512 bytes result sent to driver
2016-10-12 18:06:33 INFO  DAGScheduler:54 - ResultStage 1 (count at a1.scala:30) finished in 0.099 s
2016-10-12 18:06:33 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 1) in 98 ms on localhost (1/1)
2016-10-12 18:06:33 INFO  TaskSchedulerImpl:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2016-10-12 18:06:33 INFO  DAGScheduler:54 - Job 0 finished: count at a1.scala:30, took 4.510902 s
2016-10-12 18:06:33 INFO  SparkContext:54 - Starting job: count at a1.scala:31
2016-10-12 18:06:33 INFO  DAGScheduler:54 - Registering RDD 7 (distinct at a1.scala:31)
2016-10-12 18:06:33 INFO  DAGScheduler:54 - Got job 1 (count at a1.scala:31) with 1 output partitions
2016-10-12 18:06:33 INFO  DAGScheduler:54 - Final stage: ResultStage 3 (count at a1.scala:31)
2016-10-12 18:06:33 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 2)
2016-10-12 18:06:33 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 2)
2016-10-12 18:06:33 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 2 (MapPartitionsRDD[7] at distinct at a1.scala:31), which has no missing parents
2016-10-12 18:06:33 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 4.2 KB, free 366.0 MB)
2016-10-12 18:06:33 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.5 KB, free 366.0 MB)
2016-10-12 18:06:33 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on 150.212.30.95:43023 (size: 2.5 KB, free: 366.3 MB)
2016-10-12 18:06:33 INFO  SparkContext:54 - Created broadcast 3 from broadcast at DAGScheduler.scala:1012
2016-10-12 18:06:33 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[7] at distinct at a1.scala:31)
2016-10-12 18:06:33 INFO  TaskSchedulerImpl:54 - Adding task set 2.0 with 1 tasks
2016-10-12 18:06:33 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5507 bytes)
2016-10-12 18:06:33 INFO  Executor:54 - Running task 0.0 in stage 2.0 (TID 2)
2016-10-12 18:06:33 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 18:06:33 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 18:06:33 INFO  ContextCleaner:54 - Cleaned shuffle 0
2016-10-12 18:06:33 INFO  BlockManagerInfo:54 - Removed broadcast_1_piece0 on 150.212.30.95:43023 in memory (size: 2.5 KB, free: 366.3 MB)
2016-10-12 18:06:33 INFO  BlockManagerInfo:54 - Removed broadcast_2_piece0 on 150.212.30.95:43023 in memory (size: 2.2 KB, free: 366.3 MB)
2016-10-12 18:06:36 INFO  Executor:54 - Finished task 0.0 in stage 2.0 (TID 2). 1490 bytes result sent to driver
2016-10-12 18:06:36 INFO  DAGScheduler:54 - ShuffleMapStage 2 (distinct at a1.scala:31) finished in 3.425 s
2016-10-12 18:06:36 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 18:06:36 INFO  DAGScheduler:54 - running: Set()
2016-10-12 18:06:36 INFO  DAGScheduler:54 - waiting: Set(ResultStage 3)
2016-10-12 18:06:36 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 18:06:36 INFO  DAGScheduler:54 - Submitting ResultStage 3 (MapPartitionsRDD[9] at distinct at a1.scala:31), which has no missing parents
2016-10-12 18:06:36 INFO  TaskSetManager:54 - Finished task 0.0 in stage 2.0 (TID 2) in 3424 ms on localhost (1/1)
2016-10-12 18:06:36 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 3.8 KB, free 366.0 MB)
2016-10-12 18:06:36 INFO  TaskSchedulerImpl:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2016-10-12 18:06:36 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.2 KB, free 366.0 MB)
2016-10-12 18:06:36 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on 150.212.30.95:43023 (size: 2.2 KB, free: 366.3 MB)
2016-10-12 18:06:36 INFO  SparkContext:54 - Created broadcast 4 from broadcast at DAGScheduler.scala:1012
2016-10-12 18:06:36 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[9] at distinct at a1.scala:31)
2016-10-12 18:06:36 INFO  TaskSchedulerImpl:54 - Adding task set 3.0 with 1 tasks
2016-10-12 18:06:36 INFO  TaskSetManager:54 - Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, ANY, 5177 bytes)
2016-10-12 18:06:36 INFO  Executor:54 - Running task 0.0 in stage 3.0 (TID 3)
2016-10-12 18:06:36 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 18:06:36 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2016-10-12 18:06:36 INFO  Executor:54 - Finished task 0.0 in stage 3.0 (TID 3). 1512 bytes result sent to driver
2016-10-12 18:06:36 INFO  DAGScheduler:54 - ResultStage 3 (count at a1.scala:31) finished in 0.065 s
2016-10-12 18:06:36 INFO  TaskSetManager:54 - Finished task 0.0 in stage 3.0 (TID 3) in 65 ms on localhost (1/1)
2016-10-12 18:06:36 INFO  DAGScheduler:54 - Job 1 finished: count at a1.scala:31, took 3.552208 s
2016-10-12 18:06:36 INFO  TaskSchedulerImpl:54 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2016-10-12 18:06:36 INFO  SparkContext:54 - Starting job: collect at a1.scala:32
2016-10-12 18:06:36 INFO  DAGScheduler:54 - Registering RDD 10 (map at a1.scala:32)
2016-10-12 18:06:36 INFO  DAGScheduler:54 - Got job 2 (collect at a1.scala:32) with 1 output partitions
2016-10-12 18:06:36 INFO  DAGScheduler:54 - Final stage: ResultStage 5 (collect at a1.scala:32)
2016-10-12 18:06:36 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 4)
2016-10-12 18:06:36 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 4)
2016-10-12 18:06:36 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 4 (MapPartitionsRDD[10] at map at a1.scala:32), which has no missing parents
2016-10-12 18:06:36 INFO  MemoryStore:54 - Block broadcast_5 stored as values in memory (estimated size 4.0 KB, free 366.0 MB)
2016-10-12 18:06:36 INFO  MemoryStore:54 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.4 KB, free 366.0 MB)
2016-10-12 18:06:36 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on 150.212.30.95:43023 (size: 2.4 KB, free: 366.3 MB)
2016-10-12 18:06:36 INFO  SparkContext:54 - Created broadcast 5 from broadcast at DAGScheduler.scala:1012
2016-10-12 18:06:36 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[10] at map at a1.scala:32)
2016-10-12 18:06:36 INFO  TaskSchedulerImpl:54 - Adding task set 4.0 with 1 tasks
2016-10-12 18:06:36 INFO  TaskSetManager:54 - Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5592 bytes)
2016-10-12 18:06:36 INFO  Executor:54 - Running task 0.0 in stage 4.0 (TID 4)
2016-10-12 18:06:36 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 18:06:36 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 18:06:37 INFO  ContextCleaner:54 - Cleaned shuffle 1
2016-10-12 18:06:37 INFO  BlockManagerInfo:54 - Removed broadcast_3_piece0 on 150.212.30.95:43023 in memory (size: 2.5 KB, free: 366.3 MB)
2016-10-12 18:06:37 INFO  BlockManagerInfo:54 - Removed broadcast_4_piece0 on 150.212.30.95:43023 in memory (size: 2.2 KB, free: 366.3 MB)
2016-10-12 18:06:40 INFO  Executor:54 - Finished task 0.0 in stage 4.0 (TID 4). 1490 bytes result sent to driver
2016-10-12 18:06:40 INFO  DAGScheduler:54 - ShuffleMapStage 4 (map at a1.scala:32) finished in 3.252 s
2016-10-12 18:06:40 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 18:06:40 INFO  TaskSetManager:54 - Finished task 0.0 in stage 4.0 (TID 4) in 3254 ms on localhost (1/1)
2016-10-12 18:06:40 INFO  TaskSchedulerImpl:54 - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2016-10-12 18:06:40 INFO  DAGScheduler:54 - running: Set()
2016-10-12 18:06:40 INFO  DAGScheduler:54 - waiting: Set(ResultStage 5)
2016-10-12 18:06:40 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 18:06:40 INFO  DAGScheduler:54 - Submitting ResultStage 5 (MapPartitionsRDD[13] at map at a1.scala:32), which has no missing parents
2016-10-12 18:06:40 INFO  MemoryStore:54 - Block broadcast_6 stored as values in memory (estimated size 3.8 KB, free 366.0 MB)
2016-10-12 18:06:40 INFO  MemoryStore:54 - Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.2 KB, free 366.0 MB)
2016-10-12 18:06:40 INFO  BlockManagerInfo:54 - Added broadcast_6_piece0 in memory on 150.212.30.95:43023 (size: 2.2 KB, free: 366.3 MB)
2016-10-12 18:06:40 INFO  SparkContext:54 - Created broadcast 6 from broadcast at DAGScheduler.scala:1012
2016-10-12 18:06:40 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[13] at map at a1.scala:32)
2016-10-12 18:06:40 INFO  TaskSchedulerImpl:54 - Adding task set 5.0 with 1 tasks
2016-10-12 18:06:40 INFO  TaskSetManager:54 - Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, ANY, 5262 bytes)
2016-10-12 18:06:40 INFO  Executor:54 - Running task 0.0 in stage 5.0 (TID 5)
2016-10-12 18:06:40 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 18:06:40 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2016-10-12 18:06:40 INFO  Executor:54 - Finished task 0.0 in stage 5.0 (TID 5). 9861 bytes result sent to driver
2016-10-12 18:06:40 INFO  DAGScheduler:54 - ResultStage 5 (collect at a1.scala:32) finished in 0.054 s
2016-10-12 18:06:40 INFO  DAGScheduler:54 - Job 2 finished: collect at a1.scala:32, took 3.364396 s
2016-10-12 18:06:40 INFO  TaskSetManager:54 - Finished task 0.0 in stage 5.0 (TID 5) in 52 ms on localhost (1/1)
2016-10-12 18:06:40 INFO  TaskSchedulerImpl:54 - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2016-10-12 18:06:40 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2016-10-12 18:06:40 INFO  ServerConnector:306 - Stopped ServerConnector@6c67e137{HTTP/1.1}{0.0.0.0:4041}
2016-10-12 18:06:40 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,UNAVAILABLE}
2016-10-12 18:06:40 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@62e70ea3{/api,null,UNAVAILABLE}
2016-10-12 18:06:40 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@28276e50{/,null,UNAVAILABLE}
2016-10-12 18:06:40 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a7471ce{/static,null,UNAVAILABLE}
2016-10-12 18:06:40 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,UNAVAILABLE}
2016-10-12 18:06:40 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,UNAVAILABLE}
2016-10-12 18:06:40 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,UNAVAILABLE}
2016-10-12 18:06:40 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@297ea53a{/executors,null,UNAVAILABLE}
2016-10-12 18:06:40 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,UNAVAILABLE}
2016-10-12 18:06:40 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4052274f{/environment,null,UNAVAILABLE}
2016-10-12 18:06:40 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,UNAVAILABLE}
2016-10-12 18:06:40 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,UNAVAILABLE}
2016-10-12 18:06:40 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,UNAVAILABLE}
2016-10-12 18:06:40 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1643d68f{/storage,null,UNAVAILABLE}
2016-10-12 18:06:40 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,UNAVAILABLE}
2016-10-12 18:06:40 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,UNAVAILABLE}
2016-10-12 18:06:40 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,UNAVAILABLE}
2016-10-12 18:06:40 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,UNAVAILABLE}
2016-10-12 18:06:40 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,UNAVAILABLE}
2016-10-12 18:06:40 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,UNAVAILABLE}
2016-10-12 18:06:40 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,UNAVAILABLE}
2016-10-12 18:06:40 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,UNAVAILABLE}
2016-10-12 18:06:40 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,UNAVAILABLE}
2016-10-12 18:06:40 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,UNAVAILABLE}
2016-10-12 18:06:40 INFO  SparkUI:54 - Stopped Spark web UI at http://150.212.30.95:4041
2016-10-12 18:06:40 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2016-10-12 18:06:40 INFO  MemoryStore:54 - MemoryStore cleared
2016-10-12 18:06:40 INFO  BlockManager:54 - BlockManager stopped
2016-10-12 18:06:40 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2016-10-12 18:06:40 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2016-10-12 18:06:40 INFO  SparkContext:54 - Successfully stopped SparkContext
2016-10-12 18:06:40 INFO  ShutdownHookManager:54 - Shutdown hook called
2016-10-12 18:06:40 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-66a1279c-63c5-444d-8c90-e44eb3b75159
2016-10-12 18:28:33 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-12 18:28:34 WARN  Utils:66 - Your hostname, aadu-XPS-13-9350 resolves to a loopback address: 127.0.1.1; using 150.212.30.95 instead (on interface wlp58s0)
2016-10-12 18:28:34 WARN  Utils:66 - Set SPARK_LOCAL_IP if you need to bind to another address
2016-10-12 18:28:34 WARN  AbstractLifeCycle:212 - FAILED ServerConnector@9c93d16{HTTP/1.1}{0.0.0.0:4040}: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2071)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2062)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:139)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:451)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2256)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$8.apply(SparkSession.scala:831)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$8.apply(SparkSession.scala:823)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:823)
	at org.apache.spark.repl.Main$.createSparkSession(Main.scala:95)
	at $line3.$read$$iw$$iw.<init>(<console>:15)
	at $line3.$read$$iw.<init>(<console>:31)
	at $line3.$read.<init>(<console>:33)
	at $line3.$read$.<init>(<console>:37)
	at $line3.$read$.<clinit>(<console>)
	at $line3.$eval$.$print$lzycompute(<console>:7)
	at $line3.$eval$.$print(<console>:6)
	at $line3.$eval.$print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at scala.tools.nsc.interpreter.IMain$ReadEvalPrint.call(IMain.scala:786)
	at scala.tools.nsc.interpreter.IMain$Request.loadAndRun(IMain.scala:1047)
	at scala.tools.nsc.interpreter.IMain$WrappedRequest$$anonfun$loadAndRunReq$1.apply(IMain.scala:638)
	at scala.tools.nsc.interpreter.IMain$WrappedRequest$$anonfun$loadAndRunReq$1.apply(IMain.scala:637)
	at scala.reflect.internal.util.ScalaClassLoader$class.asContext(ScalaClassLoader.scala:31)
	at scala.reflect.internal.util.AbstractFileClassLoader.asContext(AbstractFileClassLoader.scala:19)
	at scala.tools.nsc.interpreter.IMain$WrappedRequest.loadAndRunReq(IMain.scala:637)
	at scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:569)
	at scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:565)
	at scala.tools.nsc.interpreter.ILoop.interpretStartingWith(ILoop.scala:807)
	at scala.tools.nsc.interpreter.ILoop.command(ILoop.scala:681)
	at scala.tools.nsc.interpreter.ILoop.processLine(ILoop.scala:395)
	at org.apache.spark.repl.SparkILoop$$anonfun$initializeSpark$1.apply$mcV$sp(SparkILoop.scala:38)
	at org.apache.spark.repl.SparkILoop$$anonfun$initializeSpark$1.apply(SparkILoop.scala:37)
	at org.apache.spark.repl.SparkILoop$$anonfun$initializeSpark$1.apply(SparkILoop.scala:37)
	at scala.tools.nsc.interpreter.IMain.beQuietDuring(IMain.scala:214)
	at org.apache.spark.repl.SparkILoop.initializeSpark(SparkILoop.scala:37)
	at org.apache.spark.repl.SparkILoop.loadFiles(SparkILoop.scala:94)
	at scala.tools.nsc.interpreter.ILoop$$anonfun$process$1.apply$mcZ$sp(ILoop.scala:920)
	at scala.tools.nsc.interpreter.ILoop$$anonfun$process$1.apply(ILoop.scala:909)
	at scala.tools.nsc.interpreter.ILoop$$anonfun$process$1.apply(ILoop.scala:909)
	at scala.reflect.internal.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:97)
	at scala.tools.nsc.interpreter.ILoop.process(ILoop.scala:909)
	at org.apache.spark.repl.Main$.doMain(Main.scala:68)
	at org.apache.spark.repl.Main$.main(Main.scala:51)
	at org.apache.spark.repl.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2016-10-12 18:28:34 WARN  AbstractLifeCycle:212 - FAILED org.spark_project.jetty.server.Server@4faf104: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2071)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2062)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:139)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:451)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2256)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$8.apply(SparkSession.scala:831)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$8.apply(SparkSession.scala:823)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:823)
	at org.apache.spark.repl.Main$.createSparkSession(Main.scala:95)
	at $line3.$read$$iw$$iw.<init>(<console>:15)
	at $line3.$read$$iw.<init>(<console>:31)
	at $line3.$read.<init>(<console>:33)
	at $line3.$read$.<init>(<console>:37)
	at $line3.$read$.<clinit>(<console>)
	at $line3.$eval$.$print$lzycompute(<console>:7)
	at $line3.$eval$.$print(<console>:6)
	at $line3.$eval.$print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at scala.tools.nsc.interpreter.IMain$ReadEvalPrint.call(IMain.scala:786)
	at scala.tools.nsc.interpreter.IMain$Request.loadAndRun(IMain.scala:1047)
	at scala.tools.nsc.interpreter.IMain$WrappedRequest$$anonfun$loadAndRunReq$1.apply(IMain.scala:638)
	at scala.tools.nsc.interpreter.IMain$WrappedRequest$$anonfun$loadAndRunReq$1.apply(IMain.scala:637)
	at scala.reflect.internal.util.ScalaClassLoader$class.asContext(ScalaClassLoader.scala:31)
	at scala.reflect.internal.util.AbstractFileClassLoader.asContext(AbstractFileClassLoader.scala:19)
	at scala.tools.nsc.interpreter.IMain$WrappedRequest.loadAndRunReq(IMain.scala:637)
	at scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:569)
	at scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:565)
	at scala.tools.nsc.interpreter.ILoop.interpretStartingWith(ILoop.scala:807)
	at scala.tools.nsc.interpreter.ILoop.command(ILoop.scala:681)
	at scala.tools.nsc.interpreter.ILoop.processLine(ILoop.scala:395)
	at org.apache.spark.repl.SparkILoop$$anonfun$initializeSpark$1.apply$mcV$sp(SparkILoop.scala:38)
	at org.apache.spark.repl.SparkILoop$$anonfun$initializeSpark$1.apply(SparkILoop.scala:37)
	at org.apache.spark.repl.SparkILoop$$anonfun$initializeSpark$1.apply(SparkILoop.scala:37)
	at scala.tools.nsc.interpreter.IMain.beQuietDuring(IMain.scala:214)
	at org.apache.spark.repl.SparkILoop.initializeSpark(SparkILoop.scala:37)
	at org.apache.spark.repl.SparkILoop.loadFiles(SparkILoop.scala:94)
	at scala.tools.nsc.interpreter.ILoop$$anonfun$process$1.apply$mcZ$sp(ILoop.scala:920)
	at scala.tools.nsc.interpreter.ILoop$$anonfun$process$1.apply(ILoop.scala:909)
	at scala.tools.nsc.interpreter.ILoop$$anonfun$process$1.apply(ILoop.scala:909)
	at scala.reflect.internal.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:97)
	at scala.tools.nsc.interpreter.ILoop.process(ILoop.scala:909)
	at org.apache.spark.repl.Main$.doMain(Main.scala:68)
	at org.apache.spark.repl.Main$.main(Main.scala:51)
	at org.apache.spark.repl.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2016-10-12 18:28:34 WARN  Utils:66 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2016-10-12 18:28:34 WARN  SparkContext:66 - Use an existing SparkContext, some configuration may not take effect.
2016-10-12 18:29:44 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-12 18:29:44 WARN  Utils:66 - Your hostname, aadu-XPS-13-9350 resolves to a loopback address: 127.0.1.1; using 150.212.30.95 instead (on interface wlp58s0)
2016-10-12 18:29:44 WARN  Utils:66 - Set SPARK_LOCAL_IP if you need to bind to another address
2016-10-12 18:29:45 WARN  AbstractLifeCycle:212 - FAILED ServerConnector@2e1b374c{HTTP/1.1}{0.0.0.0:4040}: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2071)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2062)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:139)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:451)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2256)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$8.apply(SparkSession.scala:831)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$8.apply(SparkSession.scala:823)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:823)
	at org.apache.spark.repl.Main$.createSparkSession(Main.scala:95)
	at $line3.$read$$iw$$iw.<init>(<console>:15)
	at $line3.$read$$iw.<init>(<console>:31)
	at $line3.$read.<init>(<console>:33)
	at $line3.$read$.<init>(<console>:37)
	at $line3.$read$.<clinit>(<console>)
	at $line3.$eval$.$print$lzycompute(<console>:7)
	at $line3.$eval$.$print(<console>:6)
	at $line3.$eval.$print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at scala.tools.nsc.interpreter.IMain$ReadEvalPrint.call(IMain.scala:786)
	at scala.tools.nsc.interpreter.IMain$Request.loadAndRun(IMain.scala:1047)
	at scala.tools.nsc.interpreter.IMain$WrappedRequest$$anonfun$loadAndRunReq$1.apply(IMain.scala:638)
	at scala.tools.nsc.interpreter.IMain$WrappedRequest$$anonfun$loadAndRunReq$1.apply(IMain.scala:637)
	at scala.reflect.internal.util.ScalaClassLoader$class.asContext(ScalaClassLoader.scala:31)
	at scala.reflect.internal.util.AbstractFileClassLoader.asContext(AbstractFileClassLoader.scala:19)
	at scala.tools.nsc.interpreter.IMain$WrappedRequest.loadAndRunReq(IMain.scala:637)
	at scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:569)
	at scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:565)
	at scala.tools.nsc.interpreter.ILoop.interpretStartingWith(ILoop.scala:807)
	at scala.tools.nsc.interpreter.ILoop.command(ILoop.scala:681)
	at scala.tools.nsc.interpreter.ILoop.processLine(ILoop.scala:395)
	at org.apache.spark.repl.SparkILoop$$anonfun$initializeSpark$1.apply$mcV$sp(SparkILoop.scala:38)
	at org.apache.spark.repl.SparkILoop$$anonfun$initializeSpark$1.apply(SparkILoop.scala:37)
	at org.apache.spark.repl.SparkILoop$$anonfun$initializeSpark$1.apply(SparkILoop.scala:37)
	at scala.tools.nsc.interpreter.IMain.beQuietDuring(IMain.scala:214)
	at org.apache.spark.repl.SparkILoop.initializeSpark(SparkILoop.scala:37)
	at org.apache.spark.repl.SparkILoop.loadFiles(SparkILoop.scala:94)
	at scala.tools.nsc.interpreter.ILoop$$anonfun$process$1.apply$mcZ$sp(ILoop.scala:920)
	at scala.tools.nsc.interpreter.ILoop$$anonfun$process$1.apply(ILoop.scala:909)
	at scala.tools.nsc.interpreter.ILoop$$anonfun$process$1.apply(ILoop.scala:909)
	at scala.reflect.internal.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:97)
	at scala.tools.nsc.interpreter.ILoop.process(ILoop.scala:909)
	at org.apache.spark.repl.Main$.doMain(Main.scala:68)
	at org.apache.spark.repl.Main$.main(Main.scala:51)
	at org.apache.spark.repl.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2016-10-12 18:29:45 WARN  AbstractLifeCycle:212 - FAILED org.spark_project.jetty.server.Server@49fb0bbd: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2071)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2062)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:139)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:451)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2256)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$8.apply(SparkSession.scala:831)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$8.apply(SparkSession.scala:823)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:823)
	at org.apache.spark.repl.Main$.createSparkSession(Main.scala:95)
	at $line3.$read$$iw$$iw.<init>(<console>:15)
	at $line3.$read$$iw.<init>(<console>:31)
	at $line3.$read.<init>(<console>:33)
	at $line3.$read$.<init>(<console>:37)
	at $line3.$read$.<clinit>(<console>)
	at $line3.$eval$.$print$lzycompute(<console>:7)
	at $line3.$eval$.$print(<console>:6)
	at $line3.$eval.$print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at scala.tools.nsc.interpreter.IMain$ReadEvalPrint.call(IMain.scala:786)
	at scala.tools.nsc.interpreter.IMain$Request.loadAndRun(IMain.scala:1047)
	at scala.tools.nsc.interpreter.IMain$WrappedRequest$$anonfun$loadAndRunReq$1.apply(IMain.scala:638)
	at scala.tools.nsc.interpreter.IMain$WrappedRequest$$anonfun$loadAndRunReq$1.apply(IMain.scala:637)
	at scala.reflect.internal.util.ScalaClassLoader$class.asContext(ScalaClassLoader.scala:31)
	at scala.reflect.internal.util.AbstractFileClassLoader.asContext(AbstractFileClassLoader.scala:19)
	at scala.tools.nsc.interpreter.IMain$WrappedRequest.loadAndRunReq(IMain.scala:637)
	at scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:569)
	at scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:565)
	at scala.tools.nsc.interpreter.ILoop.interpretStartingWith(ILoop.scala:807)
	at scala.tools.nsc.interpreter.ILoop.command(ILoop.scala:681)
	at scala.tools.nsc.interpreter.ILoop.processLine(ILoop.scala:395)
	at org.apache.spark.repl.SparkILoop$$anonfun$initializeSpark$1.apply$mcV$sp(SparkILoop.scala:38)
	at org.apache.spark.repl.SparkILoop$$anonfun$initializeSpark$1.apply(SparkILoop.scala:37)
	at org.apache.spark.repl.SparkILoop$$anonfun$initializeSpark$1.apply(SparkILoop.scala:37)
	at scala.tools.nsc.interpreter.IMain.beQuietDuring(IMain.scala:214)
	at org.apache.spark.repl.SparkILoop.initializeSpark(SparkILoop.scala:37)
	at org.apache.spark.repl.SparkILoop.loadFiles(SparkILoop.scala:94)
	at scala.tools.nsc.interpreter.ILoop$$anonfun$process$1.apply$mcZ$sp(ILoop.scala:920)
	at scala.tools.nsc.interpreter.ILoop$$anonfun$process$1.apply(ILoop.scala:909)
	at scala.tools.nsc.interpreter.ILoop$$anonfun$process$1.apply(ILoop.scala:909)
	at scala.reflect.internal.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:97)
	at scala.tools.nsc.interpreter.ILoop.process(ILoop.scala:909)
	at org.apache.spark.repl.Main$.doMain(Main.scala:68)
	at org.apache.spark.repl.Main$.main(Main.scala:51)
	at org.apache.spark.repl.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2016-10-12 18:29:45 WARN  Utils:66 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2016-10-12 18:29:45 WARN  SparkContext:66 - Use an existing SparkContext, some configuration may not take effect.
2016-10-12 18:30:48 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-12 18:30:48 WARN  Utils:66 - Your hostname, aadu-XPS-13-9350 resolves to a loopback address: 127.0.1.1; using 150.212.30.95 instead (on interface wlp58s0)
2016-10-12 18:30:48 WARN  Utils:66 - Set SPARK_LOCAL_IP if you need to bind to another address
2016-10-12 18:30:49 WARN  AbstractLifeCycle:212 - FAILED ServerConnector@2e1b374c{HTTP/1.1}{0.0.0.0:4040}: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2071)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2062)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:139)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:451)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2256)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$8.apply(SparkSession.scala:831)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$8.apply(SparkSession.scala:823)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:823)
	at org.apache.spark.repl.Main$.createSparkSession(Main.scala:95)
	at $line3.$read$$iw$$iw.<init>(<console>:15)
	at $line3.$read$$iw.<init>(<console>:31)
	at $line3.$read.<init>(<console>:33)
	at $line3.$read$.<init>(<console>:37)
	at $line3.$read$.<clinit>(<console>)
	at $line3.$eval$.$print$lzycompute(<console>:7)
	at $line3.$eval$.$print(<console>:6)
	at $line3.$eval.$print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at scala.tools.nsc.interpreter.IMain$ReadEvalPrint.call(IMain.scala:786)
	at scala.tools.nsc.interpreter.IMain$Request.loadAndRun(IMain.scala:1047)
	at scala.tools.nsc.interpreter.IMain$WrappedRequest$$anonfun$loadAndRunReq$1.apply(IMain.scala:638)
	at scala.tools.nsc.interpreter.IMain$WrappedRequest$$anonfun$loadAndRunReq$1.apply(IMain.scala:637)
	at scala.reflect.internal.util.ScalaClassLoader$class.asContext(ScalaClassLoader.scala:31)
	at scala.reflect.internal.util.AbstractFileClassLoader.asContext(AbstractFileClassLoader.scala:19)
	at scala.tools.nsc.interpreter.IMain$WrappedRequest.loadAndRunReq(IMain.scala:637)
	at scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:569)
	at scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:565)
	at scala.tools.nsc.interpreter.ILoop.interpretStartingWith(ILoop.scala:807)
	at scala.tools.nsc.interpreter.ILoop.command(ILoop.scala:681)
	at scala.tools.nsc.interpreter.ILoop.processLine(ILoop.scala:395)
	at org.apache.spark.repl.SparkILoop$$anonfun$initializeSpark$1.apply$mcV$sp(SparkILoop.scala:38)
	at org.apache.spark.repl.SparkILoop$$anonfun$initializeSpark$1.apply(SparkILoop.scala:37)
	at org.apache.spark.repl.SparkILoop$$anonfun$initializeSpark$1.apply(SparkILoop.scala:37)
	at scala.tools.nsc.interpreter.IMain.beQuietDuring(IMain.scala:214)
	at org.apache.spark.repl.SparkILoop.initializeSpark(SparkILoop.scala:37)
	at org.apache.spark.repl.SparkILoop.loadFiles(SparkILoop.scala:94)
	at scala.tools.nsc.interpreter.ILoop$$anonfun$process$1.apply$mcZ$sp(ILoop.scala:920)
	at scala.tools.nsc.interpreter.ILoop$$anonfun$process$1.apply(ILoop.scala:909)
	at scala.tools.nsc.interpreter.ILoop$$anonfun$process$1.apply(ILoop.scala:909)
	at scala.reflect.internal.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:97)
	at scala.tools.nsc.interpreter.ILoop.process(ILoop.scala:909)
	at org.apache.spark.repl.Main$.doMain(Main.scala:68)
	at org.apache.spark.repl.Main$.main(Main.scala:51)
	at org.apache.spark.repl.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2016-10-12 18:30:49 WARN  AbstractLifeCycle:212 - FAILED org.spark_project.jetty.server.Server@49fb0bbd: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2071)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2062)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:139)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:451)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2256)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$8.apply(SparkSession.scala:831)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$8.apply(SparkSession.scala:823)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:823)
	at org.apache.spark.repl.Main$.createSparkSession(Main.scala:95)
	at $line3.$read$$iw$$iw.<init>(<console>:15)
	at $line3.$read$$iw.<init>(<console>:31)
	at $line3.$read.<init>(<console>:33)
	at $line3.$read$.<init>(<console>:37)
	at $line3.$read$.<clinit>(<console>)
	at $line3.$eval$.$print$lzycompute(<console>:7)
	at $line3.$eval$.$print(<console>:6)
	at $line3.$eval.$print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at scala.tools.nsc.interpreter.IMain$ReadEvalPrint.call(IMain.scala:786)
	at scala.tools.nsc.interpreter.IMain$Request.loadAndRun(IMain.scala:1047)
	at scala.tools.nsc.interpreter.IMain$WrappedRequest$$anonfun$loadAndRunReq$1.apply(IMain.scala:638)
	at scala.tools.nsc.interpreter.IMain$WrappedRequest$$anonfun$loadAndRunReq$1.apply(IMain.scala:637)
	at scala.reflect.internal.util.ScalaClassLoader$class.asContext(ScalaClassLoader.scala:31)
	at scala.reflect.internal.util.AbstractFileClassLoader.asContext(AbstractFileClassLoader.scala:19)
	at scala.tools.nsc.interpreter.IMain$WrappedRequest.loadAndRunReq(IMain.scala:637)
	at scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:569)
	at scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:565)
	at scala.tools.nsc.interpreter.ILoop.interpretStartingWith(ILoop.scala:807)
	at scala.tools.nsc.interpreter.ILoop.command(ILoop.scala:681)
	at scala.tools.nsc.interpreter.ILoop.processLine(ILoop.scala:395)
	at org.apache.spark.repl.SparkILoop$$anonfun$initializeSpark$1.apply$mcV$sp(SparkILoop.scala:38)
	at org.apache.spark.repl.SparkILoop$$anonfun$initializeSpark$1.apply(SparkILoop.scala:37)
	at org.apache.spark.repl.SparkILoop$$anonfun$initializeSpark$1.apply(SparkILoop.scala:37)
	at scala.tools.nsc.interpreter.IMain.beQuietDuring(IMain.scala:214)
	at org.apache.spark.repl.SparkILoop.initializeSpark(SparkILoop.scala:37)
	at org.apache.spark.repl.SparkILoop.loadFiles(SparkILoop.scala:94)
	at scala.tools.nsc.interpreter.ILoop$$anonfun$process$1.apply$mcZ$sp(ILoop.scala:920)
	at scala.tools.nsc.interpreter.ILoop$$anonfun$process$1.apply(ILoop.scala:909)
	at scala.tools.nsc.interpreter.ILoop$$anonfun$process$1.apply(ILoop.scala:909)
	at scala.reflect.internal.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:97)
	at scala.tools.nsc.interpreter.ILoop.process(ILoop.scala:909)
	at org.apache.spark.repl.Main$.doMain(Main.scala:68)
	at org.apache.spark.repl.Main$.main(Main.scala:51)
	at org.apache.spark.repl.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2016-10-12 18:30:49 WARN  Utils:66 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2016-10-12 18:30:49 WARN  SparkContext:66 - Use an existing SparkContext, some configuration may not take effect.
2016-10-12 18:31:35 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-12 18:31:36 WARN  Utils:66 - Your hostname, aadu-XPS-13-9350 resolves to a loopback address: 127.0.1.1; using 150.212.30.95 instead (on interface wlp58s0)
2016-10-12 18:31:36 WARN  Utils:66 - Set SPARK_LOCAL_IP if you need to bind to another address
2016-10-12 18:31:36 WARN  AbstractLifeCycle:212 - FAILED ServerConnector@9c93d16{HTTP/1.1}{0.0.0.0:4040}: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2071)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2062)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:139)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:451)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2256)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$8.apply(SparkSession.scala:831)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$8.apply(SparkSession.scala:823)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:823)
	at org.apache.spark.repl.Main$.createSparkSession(Main.scala:95)
	at $line3.$read$$iw$$iw.<init>(<console>:15)
	at $line3.$read$$iw.<init>(<console>:31)
	at $line3.$read.<init>(<console>:33)
	at $line3.$read$.<init>(<console>:37)
	at $line3.$read$.<clinit>(<console>)
	at $line3.$eval$.$print$lzycompute(<console>:7)
	at $line3.$eval$.$print(<console>:6)
	at $line3.$eval.$print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at scala.tools.nsc.interpreter.IMain$ReadEvalPrint.call(IMain.scala:786)
	at scala.tools.nsc.interpreter.IMain$Request.loadAndRun(IMain.scala:1047)
	at scala.tools.nsc.interpreter.IMain$WrappedRequest$$anonfun$loadAndRunReq$1.apply(IMain.scala:638)
	at scala.tools.nsc.interpreter.IMain$WrappedRequest$$anonfun$loadAndRunReq$1.apply(IMain.scala:637)
	at scala.reflect.internal.util.ScalaClassLoader$class.asContext(ScalaClassLoader.scala:31)
	at scala.reflect.internal.util.AbstractFileClassLoader.asContext(AbstractFileClassLoader.scala:19)
	at scala.tools.nsc.interpreter.IMain$WrappedRequest.loadAndRunReq(IMain.scala:637)
	at scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:569)
	at scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:565)
	at scala.tools.nsc.interpreter.ILoop.interpretStartingWith(ILoop.scala:807)
	at scala.tools.nsc.interpreter.ILoop.command(ILoop.scala:681)
	at scala.tools.nsc.interpreter.ILoop.processLine(ILoop.scala:395)
	at org.apache.spark.repl.SparkILoop$$anonfun$initializeSpark$1.apply$mcV$sp(SparkILoop.scala:38)
	at org.apache.spark.repl.SparkILoop$$anonfun$initializeSpark$1.apply(SparkILoop.scala:37)
	at org.apache.spark.repl.SparkILoop$$anonfun$initializeSpark$1.apply(SparkILoop.scala:37)
	at scala.tools.nsc.interpreter.IMain.beQuietDuring(IMain.scala:214)
	at org.apache.spark.repl.SparkILoop.initializeSpark(SparkILoop.scala:37)
	at org.apache.spark.repl.SparkILoop.loadFiles(SparkILoop.scala:94)
	at scala.tools.nsc.interpreter.ILoop$$anonfun$process$1.apply$mcZ$sp(ILoop.scala:920)
	at scala.tools.nsc.interpreter.ILoop$$anonfun$process$1.apply(ILoop.scala:909)
	at scala.tools.nsc.interpreter.ILoop$$anonfun$process$1.apply(ILoop.scala:909)
	at scala.reflect.internal.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:97)
	at scala.tools.nsc.interpreter.ILoop.process(ILoop.scala:909)
	at org.apache.spark.repl.Main$.doMain(Main.scala:68)
	at org.apache.spark.repl.Main$.main(Main.scala:51)
	at org.apache.spark.repl.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2016-10-12 18:31:36 WARN  AbstractLifeCycle:212 - FAILED org.spark_project.jetty.server.Server@4faf104: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2071)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2062)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:139)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:451)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2256)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$8.apply(SparkSession.scala:831)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$8.apply(SparkSession.scala:823)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:823)
	at org.apache.spark.repl.Main$.createSparkSession(Main.scala:95)
	at $line3.$read$$iw$$iw.<init>(<console>:15)
	at $line3.$read$$iw.<init>(<console>:31)
	at $line3.$read.<init>(<console>:33)
	at $line3.$read$.<init>(<console>:37)
	at $line3.$read$.<clinit>(<console>)
	at $line3.$eval$.$print$lzycompute(<console>:7)
	at $line3.$eval$.$print(<console>:6)
	at $line3.$eval.$print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at scala.tools.nsc.interpreter.IMain$ReadEvalPrint.call(IMain.scala:786)
	at scala.tools.nsc.interpreter.IMain$Request.loadAndRun(IMain.scala:1047)
	at scala.tools.nsc.interpreter.IMain$WrappedRequest$$anonfun$loadAndRunReq$1.apply(IMain.scala:638)
	at scala.tools.nsc.interpreter.IMain$WrappedRequest$$anonfun$loadAndRunReq$1.apply(IMain.scala:637)
	at scala.reflect.internal.util.ScalaClassLoader$class.asContext(ScalaClassLoader.scala:31)
	at scala.reflect.internal.util.AbstractFileClassLoader.asContext(AbstractFileClassLoader.scala:19)
	at scala.tools.nsc.interpreter.IMain$WrappedRequest.loadAndRunReq(IMain.scala:637)
	at scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:569)
	at scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:565)
	at scala.tools.nsc.interpreter.ILoop.interpretStartingWith(ILoop.scala:807)
	at scala.tools.nsc.interpreter.ILoop.command(ILoop.scala:681)
	at scala.tools.nsc.interpreter.ILoop.processLine(ILoop.scala:395)
	at org.apache.spark.repl.SparkILoop$$anonfun$initializeSpark$1.apply$mcV$sp(SparkILoop.scala:38)
	at org.apache.spark.repl.SparkILoop$$anonfun$initializeSpark$1.apply(SparkILoop.scala:37)
	at org.apache.spark.repl.SparkILoop$$anonfun$initializeSpark$1.apply(SparkILoop.scala:37)
	at scala.tools.nsc.interpreter.IMain.beQuietDuring(IMain.scala:214)
	at org.apache.spark.repl.SparkILoop.initializeSpark(SparkILoop.scala:37)
	at org.apache.spark.repl.SparkILoop.loadFiles(SparkILoop.scala:94)
	at scala.tools.nsc.interpreter.ILoop$$anonfun$process$1.apply$mcZ$sp(ILoop.scala:920)
	at scala.tools.nsc.interpreter.ILoop$$anonfun$process$1.apply(ILoop.scala:909)
	at scala.tools.nsc.interpreter.ILoop$$anonfun$process$1.apply(ILoop.scala:909)
	at scala.reflect.internal.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:97)
	at scala.tools.nsc.interpreter.ILoop.process(ILoop.scala:909)
	at org.apache.spark.repl.Main$.doMain(Main.scala:68)
	at org.apache.spark.repl.Main$.main(Main.scala:51)
	at org.apache.spark.repl.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2016-10-12 18:31:36 WARN  Utils:66 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2016-10-12 18:31:36 WARN  AbstractLifeCycle:212 - FAILED ServerConnector@9f86dc3{HTTP/1.1}{0.0.0.0:4041}: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2071)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2062)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:139)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:451)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2256)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$8.apply(SparkSession.scala:831)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$8.apply(SparkSession.scala:823)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:823)
	at org.apache.spark.repl.Main$.createSparkSession(Main.scala:95)
	at $line3.$read$$iw$$iw.<init>(<console>:15)
	at $line3.$read$$iw.<init>(<console>:31)
	at $line3.$read.<init>(<console>:33)
	at $line3.$read$.<init>(<console>:37)
	at $line3.$read$.<clinit>(<console>)
	at $line3.$eval$.$print$lzycompute(<console>:7)
	at $line3.$eval$.$print(<console>:6)
	at $line3.$eval.$print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at scala.tools.nsc.interpreter.IMain$ReadEvalPrint.call(IMain.scala:786)
	at scala.tools.nsc.interpreter.IMain$Request.loadAndRun(IMain.scala:1047)
	at scala.tools.nsc.interpreter.IMain$WrappedRequest$$anonfun$loadAndRunReq$1.apply(IMain.scala:638)
	at scala.tools.nsc.interpreter.IMain$WrappedRequest$$anonfun$loadAndRunReq$1.apply(IMain.scala:637)
	at scala.reflect.internal.util.ScalaClassLoader$class.asContext(ScalaClassLoader.scala:31)
	at scala.reflect.internal.util.AbstractFileClassLoader.asContext(AbstractFileClassLoader.scala:19)
	at scala.tools.nsc.interpreter.IMain$WrappedRequest.loadAndRunReq(IMain.scala:637)
	at scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:569)
	at scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:565)
	at scala.tools.nsc.interpreter.ILoop.interpretStartingWith(ILoop.scala:807)
	at scala.tools.nsc.interpreter.ILoop.command(ILoop.scala:681)
	at scala.tools.nsc.interpreter.ILoop.processLine(ILoop.scala:395)
	at org.apache.spark.repl.SparkILoop$$anonfun$initializeSpark$1.apply$mcV$sp(SparkILoop.scala:38)
	at org.apache.spark.repl.SparkILoop$$anonfun$initializeSpark$1.apply(SparkILoop.scala:37)
	at org.apache.spark.repl.SparkILoop$$anonfun$initializeSpark$1.apply(SparkILoop.scala:37)
	at scala.tools.nsc.interpreter.IMain.beQuietDuring(IMain.scala:214)
	at org.apache.spark.repl.SparkILoop.initializeSpark(SparkILoop.scala:37)
	at org.apache.spark.repl.SparkILoop.loadFiles(SparkILoop.scala:94)
	at scala.tools.nsc.interpreter.ILoop$$anonfun$process$1.apply$mcZ$sp(ILoop.scala:920)
	at scala.tools.nsc.interpreter.ILoop$$anonfun$process$1.apply(ILoop.scala:909)
	at scala.tools.nsc.interpreter.ILoop$$anonfun$process$1.apply(ILoop.scala:909)
	at scala.reflect.internal.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:97)
	at scala.tools.nsc.interpreter.ILoop.process(ILoop.scala:909)
	at org.apache.spark.repl.Main$.doMain(Main.scala:68)
	at org.apache.spark.repl.Main$.main(Main.scala:51)
	at org.apache.spark.repl.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2016-10-12 18:31:36 WARN  AbstractLifeCycle:212 - FAILED org.spark_project.jetty.server.Server@662e682a: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2071)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2062)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:139)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:451)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2256)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$8.apply(SparkSession.scala:831)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$8.apply(SparkSession.scala:823)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:823)
	at org.apache.spark.repl.Main$.createSparkSession(Main.scala:95)
	at $line3.$read$$iw$$iw.<init>(<console>:15)
	at $line3.$read$$iw.<init>(<console>:31)
	at $line3.$read.<init>(<console>:33)
	at $line3.$read$.<init>(<console>:37)
	at $line3.$read$.<clinit>(<console>)
	at $line3.$eval$.$print$lzycompute(<console>:7)
	at $line3.$eval$.$print(<console>:6)
	at $line3.$eval.$print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at scala.tools.nsc.interpreter.IMain$ReadEvalPrint.call(IMain.scala:786)
	at scala.tools.nsc.interpreter.IMain$Request.loadAndRun(IMain.scala:1047)
	at scala.tools.nsc.interpreter.IMain$WrappedRequest$$anonfun$loadAndRunReq$1.apply(IMain.scala:638)
	at scala.tools.nsc.interpreter.IMain$WrappedRequest$$anonfun$loadAndRunReq$1.apply(IMain.scala:637)
	at scala.reflect.internal.util.ScalaClassLoader$class.asContext(ScalaClassLoader.scala:31)
	at scala.reflect.internal.util.AbstractFileClassLoader.asContext(AbstractFileClassLoader.scala:19)
	at scala.tools.nsc.interpreter.IMain$WrappedRequest.loadAndRunReq(IMain.scala:637)
	at scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:569)
	at scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:565)
	at scala.tools.nsc.interpreter.ILoop.interpretStartingWith(ILoop.scala:807)
	at scala.tools.nsc.interpreter.ILoop.command(ILoop.scala:681)
	at scala.tools.nsc.interpreter.ILoop.processLine(ILoop.scala:395)
	at org.apache.spark.repl.SparkILoop$$anonfun$initializeSpark$1.apply$mcV$sp(SparkILoop.scala:38)
	at org.apache.spark.repl.SparkILoop$$anonfun$initializeSpark$1.apply(SparkILoop.scala:37)
	at org.apache.spark.repl.SparkILoop$$anonfun$initializeSpark$1.apply(SparkILoop.scala:37)
	at scala.tools.nsc.interpreter.IMain.beQuietDuring(IMain.scala:214)
	at org.apache.spark.repl.SparkILoop.initializeSpark(SparkILoop.scala:37)
	at org.apache.spark.repl.SparkILoop.loadFiles(SparkILoop.scala:94)
	at scala.tools.nsc.interpreter.ILoop$$anonfun$process$1.apply$mcZ$sp(ILoop.scala:920)
	at scala.tools.nsc.interpreter.ILoop$$anonfun$process$1.apply(ILoop.scala:909)
	at scala.tools.nsc.interpreter.ILoop$$anonfun$process$1.apply(ILoop.scala:909)
	at scala.reflect.internal.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:97)
	at scala.tools.nsc.interpreter.ILoop.process(ILoop.scala:909)
	at org.apache.spark.repl.Main$.doMain(Main.scala:68)
	at org.apache.spark.repl.Main$.main(Main.scala:51)
	at org.apache.spark.repl.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2016-10-12 18:31:36 WARN  Utils:66 - Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
2016-10-12 18:31:36 WARN  SparkContext:66 - Use an existing SparkContext, some configuration may not take effect.
2016-10-12 18:58:49 INFO  SparkContext:54 - Running Spark version 2.0.0
2016-10-12 18:58:50 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-12 18:58:50 WARN  Utils:66 - Your hostname, aadu-XPS-13-9350 resolves to a loopback address: 127.0.1.1; using 150.212.30.95 instead (on interface wlp58s0)
2016-10-12 18:58:50 WARN  Utils:66 - Set SPARK_LOCAL_IP if you need to bind to another address
2016-10-12 18:58:50 INFO  SecurityManager:54 - Changing view acls to: aadu
2016-10-12 18:58:50 INFO  SecurityManager:54 - Changing modify acls to: aadu
2016-10-12 18:58:50 INFO  SecurityManager:54 - Changing view acls groups to: 
2016-10-12 18:58:50 INFO  SecurityManager:54 - Changing modify acls groups to: 
2016-10-12 18:58:50 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(aadu); groups with view permissions: Set(); users  with modify permissions: Set(aadu); groups with modify permissions: Set()
2016-10-12 18:58:50 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 34207.
2016-10-12 18:58:50 INFO  SparkEnv:54 - Registering MapOutputTracker
2016-10-12 18:58:50 INFO  SparkEnv:54 - Registering BlockManagerMaster
2016-10-12 18:58:50 INFO  DiskBlockManager:54 - Created local directory at /tmp/blockmgr-ec711e82-0b63-48fa-b564-2e26257c775e
2016-10-12 18:58:50 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2016-10-12 18:58:50 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2016-10-12 18:58:50 INFO  log:186 - Logging initialized @1608ms
2016-10-12 18:58:50 INFO  Server:327 - jetty-9.2.z-SNAPSHOT
2016-10-12 18:58:50 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@18f20260{/jobs,null,AVAILABLE}
2016-10-12 18:58:50 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4ae33a11{/jobs/json,null,AVAILABLE}
2016-10-12 18:58:50 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a48e6e2{/jobs/job,null,AVAILABLE}
2016-10-12 18:58:50 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@b40bb6e{/jobs/job/json,null,AVAILABLE}
2016-10-12 18:58:50 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3a94964{/stages,null,AVAILABLE}
2016-10-12 18:58:50 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5049d8b2{/stages/json,null,AVAILABLE}
2016-10-12 18:58:50 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6d0b5baf{/stages/stage,null,AVAILABLE}
2016-10-12 18:58:50 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@631e06ab{/stages/stage/json,null,AVAILABLE}
2016-10-12 18:58:50 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2a3591c5{/stages/pool,null,AVAILABLE}
2016-10-12 18:58:50 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@34a75079{/stages/pool/json,null,AVAILABLE}
2016-10-12 18:58:50 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@346a361{/storage,null,AVAILABLE}
2016-10-12 18:58:50 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@107ed6fc{/storage/json,null,AVAILABLE}
2016-10-12 18:58:50 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1643d68f{/storage/rdd,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@186978a6{/storage/rdd/json,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2e029d61{/environment,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@482d776b{/environment/json,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4052274f{/executors,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@132ddbab{/executors/json,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@297ea53a{/executors/threadDump,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@acb0951{/executors/threadDump/json,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5bf22f18{/static,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@267f474e{/,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a7471ce{/api,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@28276e50{/stages/stage/kill,null,AVAILABLE}
2016-10-12 18:58:51 WARN  AbstractLifeCycle:212 - FAILED ServerConnector@89c10b7{HTTP/1.1}{0.0.0.0:4040}: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2071)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2062)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:139)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:451)
	at Assign1$.main(a1.scala:19)
	at Assign1.main(a1.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2016-10-12 18:58:51 WARN  AbstractLifeCycle:212 - FAILED org.spark_project.jetty.server.Server@7fd4acee: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2071)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2062)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:139)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:451)
	at Assign1$.main(a1.scala:19)
	at Assign1.main(a1.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2016-10-12 18:58:51 INFO  ServerConnector:306 - Stopped ServerConnector@89c10b7{HTTP/1.1}{0.0.0.0:4040}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@28276e50{/stages/stage/kill,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a7471ce{/api,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@267f474e{/,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5bf22f18{/static,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@acb0951{/executors/threadDump/json,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@297ea53a{/executors/threadDump,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@132ddbab{/executors/json,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4052274f{/executors,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@482d776b{/environment/json,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2e029d61{/environment,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@186978a6{/storage/rdd/json,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1643d68f{/storage/rdd,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@107ed6fc{/storage/json,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@346a361{/storage,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@34a75079{/stages/pool/json,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2a3591c5{/stages/pool,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@631e06ab{/stages/stage/json,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6d0b5baf{/stages/stage,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5049d8b2{/stages/json,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3a94964{/stages,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@b40bb6e{/jobs/job/json,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a48e6e2{/jobs/job,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4ae33a11{/jobs/json,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@18f20260{/jobs,null,UNAVAILABLE}
2016-10-12 18:58:51 WARN  Utils:66 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2016-10-12 18:58:51 INFO  Server:327 - jetty-9.2.z-SNAPSHOT
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@18f20260{/jobs,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4ae33a11{/jobs/json,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a48e6e2{/jobs/job,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@b40bb6e{/jobs/job/json,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3a94964{/stages,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5049d8b2{/stages/json,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6d0b5baf{/stages/stage,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@631e06ab{/stages/stage/json,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2a3591c5{/stages/pool,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@34a75079{/stages/pool/json,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@346a361{/storage,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@107ed6fc{/storage/json,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1643d68f{/storage/rdd,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@186978a6{/storage/rdd/json,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2e029d61{/environment,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@482d776b{/environment/json,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4052274f{/executors,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@132ddbab{/executors/json,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@297ea53a{/executors/threadDump,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@acb0951{/executors/threadDump/json,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5bf22f18{/static,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@267f474e{/,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a7471ce{/api,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@28276e50{/stages/stage/kill,null,AVAILABLE}
2016-10-12 18:58:51 WARN  AbstractLifeCycle:212 - FAILED ServerConnector@4215838f{HTTP/1.1}{0.0.0.0:4041}: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2071)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2062)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:139)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:451)
	at Assign1$.main(a1.scala:19)
	at Assign1.main(a1.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2016-10-12 18:58:51 WARN  AbstractLifeCycle:212 - FAILED org.spark_project.jetty.server.Server@2289aca5: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2071)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2062)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:139)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:451)
	at Assign1$.main(a1.scala:19)
	at Assign1.main(a1.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2016-10-12 18:58:51 INFO  ServerConnector:306 - Stopped ServerConnector@4215838f{HTTP/1.1}{0.0.0.0:4041}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@28276e50{/stages/stage/kill,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a7471ce{/api,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@267f474e{/,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5bf22f18{/static,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@acb0951{/executors/threadDump/json,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@297ea53a{/executors/threadDump,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@132ddbab{/executors/json,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4052274f{/executors,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@482d776b{/environment/json,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2e029d61{/environment,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@186978a6{/storage/rdd/json,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1643d68f{/storage/rdd,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@107ed6fc{/storage/json,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@346a361{/storage,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@34a75079{/stages/pool/json,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2a3591c5{/stages/pool,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@631e06ab{/stages/stage/json,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6d0b5baf{/stages/stage,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5049d8b2{/stages/json,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3a94964{/stages,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@b40bb6e{/jobs/job/json,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a48e6e2{/jobs/job,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4ae33a11{/jobs/json,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@18f20260{/jobs,null,UNAVAILABLE}
2016-10-12 18:58:51 WARN  Utils:66 - Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
2016-10-12 18:58:51 INFO  Server:327 - jetty-9.2.z-SNAPSHOT
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@18f20260{/jobs,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4ae33a11{/jobs/json,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a48e6e2{/jobs/job,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@b40bb6e{/jobs/job/json,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3a94964{/stages,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5049d8b2{/stages/json,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6d0b5baf{/stages/stage,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@631e06ab{/stages/stage/json,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2a3591c5{/stages/pool,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@34a75079{/stages/pool/json,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@346a361{/storage,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@107ed6fc{/storage/json,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1643d68f{/storage/rdd,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@186978a6{/storage/rdd/json,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2e029d61{/environment,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@482d776b{/environment/json,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4052274f{/executors,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@132ddbab{/executors/json,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@297ea53a{/executors/threadDump,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@acb0951{/executors/threadDump/json,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5bf22f18{/static,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@267f474e{/,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a7471ce{/api,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@28276e50{/stages/stage/kill,null,AVAILABLE}
2016-10-12 18:58:51 WARN  AbstractLifeCycle:212 - FAILED ServerConnector@5ac86ba5{HTTP/1.1}{0.0.0.0:4042}: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2071)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2062)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:139)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:451)
	at Assign1$.main(a1.scala:19)
	at Assign1.main(a1.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2016-10-12 18:58:51 WARN  AbstractLifeCycle:212 - FAILED org.spark_project.jetty.server.Server@2c9399a4: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2071)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2062)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:139)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:451)
	at Assign1$.main(a1.scala:19)
	at Assign1.main(a1.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2016-10-12 18:58:51 INFO  ServerConnector:306 - Stopped ServerConnector@5ac86ba5{HTTP/1.1}{0.0.0.0:4042}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@28276e50{/stages/stage/kill,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a7471ce{/api,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@267f474e{/,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5bf22f18{/static,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@acb0951{/executors/threadDump/json,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@297ea53a{/executors/threadDump,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@132ddbab{/executors/json,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4052274f{/executors,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@482d776b{/environment/json,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2e029d61{/environment,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@186978a6{/storage/rdd/json,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1643d68f{/storage/rdd,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@107ed6fc{/storage/json,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@346a361{/storage,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@34a75079{/stages/pool/json,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2a3591c5{/stages/pool,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@631e06ab{/stages/stage/json,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6d0b5baf{/stages/stage,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5049d8b2{/stages/json,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3a94964{/stages,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@b40bb6e{/jobs/job/json,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a48e6e2{/jobs/job,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4ae33a11{/jobs/json,null,UNAVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@18f20260{/jobs,null,UNAVAILABLE}
2016-10-12 18:58:51 WARN  Utils:66 - Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
2016-10-12 18:58:51 INFO  Server:327 - jetty-9.2.z-SNAPSHOT
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@18f20260{/jobs,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4ae33a11{/jobs/json,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a48e6e2{/jobs/job,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@b40bb6e{/jobs/job/json,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3a94964{/stages,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5049d8b2{/stages/json,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6d0b5baf{/stages/stage,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@631e06ab{/stages/stage/json,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2a3591c5{/stages/pool,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@34a75079{/stages/pool/json,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@346a361{/storage,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@107ed6fc{/storage/json,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1643d68f{/storage/rdd,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@186978a6{/storage/rdd/json,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2e029d61{/environment,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@482d776b{/environment/json,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4052274f{/executors,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@132ddbab{/executors/json,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@297ea53a{/executors/threadDump,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@acb0951{/executors/threadDump/json,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5bf22f18{/static,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@267f474e{/,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a7471ce{/api,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@28276e50{/stages/stage/kill,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ServerConnector:266 - Started ServerConnector@69c79f09{HTTP/1.1}{0.0.0.0:4043}
2016-10-12 18:58:51 INFO  Server:379 - Started @1811ms
2016-10-12 18:58:51 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4043.
2016-10-12 18:58:51 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://150.212.30.95:4043
2016-10-12 18:58:51 INFO  SparkContext:54 - Added JAR file:/home/aadu/Repos/adam/adam-assembly/target/adam_2.11-0.19.1-SNAPSHOT.jar at spark://150.212.30.95:34207/jars/adam_2.11-0.19.1-SNAPSHOT.jar with timestamp 1476313131142
2016-10-12 18:58:51 INFO  SparkContext:54 - Added JAR file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/a1.jar at spark://150.212.30.95:34207/jars/a1.jar with timestamp 1476313131144
2016-10-12 18:58:51 INFO  Executor:54 - Starting executor ID driver on host localhost
2016-10-12 18:58:51 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34631.
2016-10-12 18:58:51 INFO  NettyBlockTransferService:54 - Server created on 150.212.30.95:34631
2016-10-12 18:58:51 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 150.212.30.95, 34631)
2016-10-12 18:58:51 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 150.212.30.95:34631 with 366.3 MB RAM, BlockManagerId(driver, 150.212.30.95, 34631)
2016-10-12 18:58:51 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 150.212.30.95, 34631)
2016-10-12 18:58:51 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4d666b41{/metrics/json,null,AVAILABLE}
2016-10-12 18:58:51 INFO  ADAMContext:1336 - Loading small.adam as Parquet containing Genotypes. Sequence dictionary for translation is ignored.
2016-10-12 18:58:51 INFO  ADAMContext:257 - Reading the ADAM file at small.adam to create RDD
2016-10-12 18:58:51 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 268.7 KB, free 366.0 MB)
2016-10-12 18:58:52 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 22.8 KB, free 366.0 MB)
2016-10-12 18:58:52 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 150.212.30.95:34631 (size: 22.8 KB, free: 366.3 MB)
2016-10-12 18:58:52 INFO  SparkContext:54 - Created broadcast 0 from newAPIHadoopFile at ADAMContext.scala:271
2016-10-12 18:58:52 INFO  FileInputFormat:283 - Total input paths to process : 1
2016-10-12 18:58:52 INFO  SparkContext:54 - Starting job: count at a1.scala:32
2016-10-12 18:58:52 INFO  DAGScheduler:54 - Registering RDD 3 (distinct at a1.scala:32)
2016-10-12 18:58:52 INFO  DAGScheduler:54 - Got job 0 (count at a1.scala:32) with 1 output partitions
2016-10-12 18:58:52 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (count at a1.scala:32)
2016-10-12 18:58:52 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 0)
2016-10-12 18:58:52 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 0)
2016-10-12 18:58:52 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at distinct at a1.scala:32), which has no missing parents
2016-10-12 18:58:52 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 4.2 KB, free 366.0 MB)
2016-10-12 18:58:52 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.5 KB, free 366.0 MB)
2016-10-12 18:58:52 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 150.212.30.95:34631 (size: 2.5 KB, free: 366.3 MB)
2016-10-12 18:58:52 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1012
2016-10-12 18:58:52 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at distinct at a1.scala:32)
2016-10-12 18:58:52 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2016-10-12 18:58:53 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5507 bytes)
2016-10-12 18:58:53 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2016-10-12 18:58:53 INFO  Executor:54 - Fetching spark://150.212.30.95:34207/jars/adam_2.11-0.19.1-SNAPSHOT.jar with timestamp 1476313131142
2016-10-12 18:58:53 INFO  TransportClientFactory:250 - Successfully created connection to /150.212.30.95:34207 after 28 ms (0 ms spent in bootstraps)
2016-10-12 18:58:53 INFO  Utils:54 - Fetching spark://150.212.30.95:34207/jars/adam_2.11-0.19.1-SNAPSHOT.jar to /tmp/spark-e40c5a64-8814-4e96-a1e1-3e84d8884642/userFiles-7ca48ae9-4400-4bcc-9564-b9966f88b919/fetchFileTemp2236668382176005977.tmp
2016-10-12 18:58:53 INFO  Executor:54 - Adding file:/tmp/spark-e40c5a64-8814-4e96-a1e1-3e84d8884642/userFiles-7ca48ae9-4400-4bcc-9564-b9966f88b919/adam_2.11-0.19.1-SNAPSHOT.jar to class loader
2016-10-12 18:58:53 INFO  Executor:54 - Fetching spark://150.212.30.95:34207/jars/a1.jar with timestamp 1476313131144
2016-10-12 18:58:53 INFO  Utils:54 - Fetching spark://150.212.30.95:34207/jars/a1.jar to /tmp/spark-e40c5a64-8814-4e96-a1e1-3e84d8884642/userFiles-7ca48ae9-4400-4bcc-9564-b9966f88b919/fetchFileTemp7062335206433496046.tmp
2016-10-12 18:58:53 INFO  Executor:54 - Adding file:/tmp/spark-e40c5a64-8814-4e96-a1e1-3e84d8884642/userFiles-7ca48ae9-4400-4bcc-9564-b9966f88b919/a1.jar to class loader
2016-10-12 18:58:53 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 18:58:53 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 18:58:57 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1490 bytes result sent to driver
2016-10-12 18:58:57 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 4737 ms on localhost (1/1)
2016-10-12 18:58:57 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2016-10-12 18:58:57 INFO  DAGScheduler:54 - ShuffleMapStage 0 (distinct at a1.scala:32) finished in 4.754 s
2016-10-12 18:58:57 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 18:58:57 INFO  DAGScheduler:54 - running: Set()
2016-10-12 18:58:57 INFO  DAGScheduler:54 - waiting: Set(ResultStage 1)
2016-10-12 18:58:57 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 18:58:57 INFO  DAGScheduler:54 - Submitting ResultStage 1 (MapPartitionsRDD[5] at distinct at a1.scala:32), which has no missing parents
2016-10-12 18:58:57 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 3.7 KB, free 366.0 MB)
2016-10-12 18:58:57 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.2 KB, free 366.0 MB)
2016-10-12 18:58:57 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on 150.212.30.95:34631 (size: 2.2 KB, free: 366.3 MB)
2016-10-12 18:58:57 INFO  SparkContext:54 - Created broadcast 2 from broadcast at DAGScheduler.scala:1012
2016-10-12 18:58:57 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at distinct at a1.scala:32)
2016-10-12 18:58:57 INFO  TaskSchedulerImpl:54 - Adding task set 1.0 with 1 tasks
2016-10-12 18:58:57 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, ANY, 5177 bytes)
2016-10-12 18:58:57 INFO  Executor:54 - Running task 0.0 in stage 1.0 (TID 1)
2016-10-12 18:58:57 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 18:58:57 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 3 ms
2016-10-12 18:58:57 INFO  Executor:54 - Finished task 0.0 in stage 1.0 (TID 1). 1512 bytes result sent to driver
2016-10-12 18:58:57 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 1) in 88 ms on localhost (1/1)
2016-10-12 18:58:57 INFO  DAGScheduler:54 - ResultStage 1 (count at a1.scala:32) finished in 0.090 s
2016-10-12 18:58:57 INFO  TaskSchedulerImpl:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2016-10-12 18:58:57 INFO  DAGScheduler:54 - Job 0 finished: count at a1.scala:32, took 5.031392 s
2016-10-12 18:58:57 INFO  SparkContext:54 - Starting job: count at a1.scala:33
2016-10-12 18:58:57 INFO  DAGScheduler:54 - Registering RDD 7 (distinct at a1.scala:33)
2016-10-12 18:58:57 INFO  DAGScheduler:54 - Got job 1 (count at a1.scala:33) with 1 output partitions
2016-10-12 18:58:57 INFO  DAGScheduler:54 - Final stage: ResultStage 3 (count at a1.scala:33)
2016-10-12 18:58:57 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 2)
2016-10-12 18:58:57 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 2)
2016-10-12 18:58:57 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 2 (MapPartitionsRDD[7] at distinct at a1.scala:33), which has no missing parents
2016-10-12 18:58:57 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 4.2 KB, free 366.0 MB)
2016-10-12 18:58:57 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.5 KB, free 366.0 MB)
2016-10-12 18:58:57 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on 150.212.30.95:34631 (size: 2.5 KB, free: 366.3 MB)
2016-10-12 18:58:57 INFO  SparkContext:54 - Created broadcast 3 from broadcast at DAGScheduler.scala:1012
2016-10-12 18:58:57 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[7] at distinct at a1.scala:33)
2016-10-12 18:58:57 INFO  TaskSchedulerImpl:54 - Adding task set 2.0 with 1 tasks
2016-10-12 18:58:57 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5507 bytes)
2016-10-12 18:58:57 INFO  Executor:54 - Running task 0.0 in stage 2.0 (TID 2)
2016-10-12 18:58:57 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 18:58:57 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 18:58:58 INFO  BlockManagerInfo:54 - Removed broadcast_2_piece0 on 150.212.30.95:34631 in memory (size: 2.2 KB, free: 366.3 MB)
2016-10-12 18:59:01 INFO  Executor:54 - Finished task 0.0 in stage 2.0 (TID 2). 1490 bytes result sent to driver
2016-10-12 18:59:01 INFO  TaskSetManager:54 - Finished task 0.0 in stage 2.0 (TID 2) in 3583 ms on localhost (1/1)
2016-10-12 18:59:01 INFO  DAGScheduler:54 - ShuffleMapStage 2 (distinct at a1.scala:33) finished in 3.585 s
2016-10-12 18:59:01 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 18:59:01 INFO  DAGScheduler:54 - running: Set()
2016-10-12 18:59:01 INFO  DAGScheduler:54 - waiting: Set(ResultStage 3)
2016-10-12 18:59:01 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 18:59:01 INFO  DAGScheduler:54 - Submitting ResultStage 3 (MapPartitionsRDD[9] at distinct at a1.scala:33), which has no missing parents
2016-10-12 18:59:01 INFO  TaskSchedulerImpl:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2016-10-12 18:59:01 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 3.8 KB, free 366.0 MB)
2016-10-12 18:59:01 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.2 KB, free 366.0 MB)
2016-10-12 18:59:01 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on 150.212.30.95:34631 (size: 2.2 KB, free: 366.3 MB)
2016-10-12 18:59:01 INFO  SparkContext:54 - Created broadcast 4 from broadcast at DAGScheduler.scala:1012
2016-10-12 18:59:01 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[9] at distinct at a1.scala:33)
2016-10-12 18:59:01 INFO  TaskSchedulerImpl:54 - Adding task set 3.0 with 1 tasks
2016-10-12 18:59:01 INFO  TaskSetManager:54 - Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, ANY, 5177 bytes)
2016-10-12 18:59:01 INFO  Executor:54 - Running task 0.0 in stage 3.0 (TID 3)
2016-10-12 18:59:01 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 18:59:01 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2016-10-12 18:59:01 INFO  Executor:54 - Finished task 0.0 in stage 3.0 (TID 3). 1512 bytes result sent to driver
2016-10-12 18:59:01 INFO  TaskSetManager:54 - Finished task 0.0 in stage 3.0 (TID 3) in 56 ms on localhost (1/1)
2016-10-12 18:59:01 INFO  DAGScheduler:54 - ResultStage 3 (count at a1.scala:33) finished in 0.057 s
2016-10-12 18:59:01 INFO  DAGScheduler:54 - Job 1 finished: count at a1.scala:33, took 3.701722 s
2016-10-12 18:59:01 INFO  TaskSchedulerImpl:54 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2016-10-12 18:59:01 INFO  SparkContext:54 - Starting job: collect at a1.scala:34
2016-10-12 18:59:01 INFO  DAGScheduler:54 - Registering RDD 10 (map at a1.scala:34)
2016-10-12 18:59:01 INFO  DAGScheduler:54 - Got job 2 (collect at a1.scala:34) with 1 output partitions
2016-10-12 18:59:01 INFO  DAGScheduler:54 - Final stage: ResultStage 5 (collect at a1.scala:34)
2016-10-12 18:59:01 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 4)
2016-10-12 18:59:01 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 4)
2016-10-12 18:59:01 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 4 (MapPartitionsRDD[10] at map at a1.scala:34), which has no missing parents
2016-10-12 18:59:01 INFO  MemoryStore:54 - Block broadcast_5 stored as values in memory (estimated size 4.0 KB, free 366.0 MB)
2016-10-12 18:59:01 INFO  MemoryStore:54 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.4 KB, free 366.0 MB)
2016-10-12 18:59:01 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on 150.212.30.95:34631 (size: 2.4 KB, free: 366.3 MB)
2016-10-12 18:59:01 INFO  SparkContext:54 - Created broadcast 5 from broadcast at DAGScheduler.scala:1012
2016-10-12 18:59:01 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[10] at map at a1.scala:34)
2016-10-12 18:59:01 INFO  TaskSchedulerImpl:54 - Adding task set 4.0 with 1 tasks
2016-10-12 18:59:01 INFO  TaskSetManager:54 - Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5592 bytes)
2016-10-12 18:59:01 INFO  Executor:54 - Running task 0.0 in stage 4.0 (TID 4)
2016-10-12 18:59:01 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 18:59:01 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 18:59:02 INFO  BlockManagerInfo:54 - Removed broadcast_4_piece0 on 150.212.30.95:34631 in memory (size: 2.2 KB, free: 366.3 MB)
2016-10-12 18:59:02 INFO  ContextCleaner:54 - Cleaned shuffle 1
2016-10-12 18:59:02 INFO  BlockManagerInfo:54 - Removed broadcast_3_piece0 on 150.212.30.95:34631 in memory (size: 2.5 KB, free: 366.3 MB)
2016-10-12 18:59:05 INFO  Executor:54 - Finished task 0.0 in stage 4.0 (TID 4). 1490 bytes result sent to driver
2016-10-12 18:59:05 INFO  TaskSetManager:54 - Finished task 0.0 in stage 4.0 (TID 4) in 3472 ms on localhost (1/1)
2016-10-12 18:59:05 INFO  DAGScheduler:54 - ShuffleMapStage 4 (map at a1.scala:34) finished in 3.470 s
2016-10-12 18:59:05 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 18:59:05 INFO  DAGScheduler:54 - running: Set()
2016-10-12 18:59:05 INFO  DAGScheduler:54 - waiting: Set(ResultStage 5)
2016-10-12 18:59:05 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 18:59:05 INFO  DAGScheduler:54 - Submitting ResultStage 5 (MapPartitionsRDD[13] at map at a1.scala:34), which has no missing parents
2016-10-12 18:59:05 INFO  MemoryStore:54 - Block broadcast_6 stored as values in memory (estimated size 3.8 KB, free 366.0 MB)
2016-10-12 18:59:05 INFO  TaskSchedulerImpl:54 - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2016-10-12 18:59:05 INFO  MemoryStore:54 - Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.2 KB, free 366.0 MB)
2016-10-12 18:59:05 INFO  BlockManagerInfo:54 - Added broadcast_6_piece0 in memory on 150.212.30.95:34631 (size: 2.2 KB, free: 366.3 MB)
2016-10-12 18:59:05 INFO  SparkContext:54 - Created broadcast 6 from broadcast at DAGScheduler.scala:1012
2016-10-12 18:59:05 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[13] at map at a1.scala:34)
2016-10-12 18:59:05 INFO  TaskSchedulerImpl:54 - Adding task set 5.0 with 1 tasks
2016-10-12 18:59:05 INFO  TaskSetManager:54 - Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, ANY, 5262 bytes)
2016-10-12 18:59:05 INFO  Executor:54 - Running task 0.0 in stage 5.0 (TID 5)
2016-10-12 18:59:05 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 18:59:05 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2016-10-12 18:59:05 INFO  Executor:54 - Finished task 0.0 in stage 5.0 (TID 5). 9861 bytes result sent to driver
2016-10-12 18:59:05 INFO  DAGScheduler:54 - ResultStage 5 (collect at a1.scala:34) finished in 0.039 s
2016-10-12 18:59:05 INFO  TaskSetManager:54 - Finished task 0.0 in stage 5.0 (TID 5) in 48 ms on localhost (1/1)
2016-10-12 18:59:05 INFO  DAGScheduler:54 - Job 2 finished: collect at a1.scala:34, took 3.556371 s
2016-10-12 18:59:05 INFO  TaskSchedulerImpl:54 - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2016-10-12 18:59:05 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2016-10-12 18:59:05 INFO  ServerConnector:306 - Stopped ServerConnector@69c79f09{HTTP/1.1}{0.0.0.0:4043}
2016-10-12 18:59:05 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@28276e50{/stages/stage/kill,null,UNAVAILABLE}
2016-10-12 18:59:05 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a7471ce{/api,null,UNAVAILABLE}
2016-10-12 18:59:05 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@267f474e{/,null,UNAVAILABLE}
2016-10-12 18:59:05 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5bf22f18{/static,null,UNAVAILABLE}
2016-10-12 18:59:05 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@acb0951{/executors/threadDump/json,null,UNAVAILABLE}
2016-10-12 18:59:05 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@297ea53a{/executors/threadDump,null,UNAVAILABLE}
2016-10-12 18:59:05 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@132ddbab{/executors/json,null,UNAVAILABLE}
2016-10-12 18:59:05 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4052274f{/executors,null,UNAVAILABLE}
2016-10-12 18:59:05 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@482d776b{/environment/json,null,UNAVAILABLE}
2016-10-12 18:59:05 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2e029d61{/environment,null,UNAVAILABLE}
2016-10-12 18:59:05 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@186978a6{/storage/rdd/json,null,UNAVAILABLE}
2016-10-12 18:59:05 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1643d68f{/storage/rdd,null,UNAVAILABLE}
2016-10-12 18:59:05 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@107ed6fc{/storage/json,null,UNAVAILABLE}
2016-10-12 18:59:05 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@346a361{/storage,null,UNAVAILABLE}
2016-10-12 18:59:05 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@34a75079{/stages/pool/json,null,UNAVAILABLE}
2016-10-12 18:59:05 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2a3591c5{/stages/pool,null,UNAVAILABLE}
2016-10-12 18:59:05 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@631e06ab{/stages/stage/json,null,UNAVAILABLE}
2016-10-12 18:59:05 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6d0b5baf{/stages/stage,null,UNAVAILABLE}
2016-10-12 18:59:05 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5049d8b2{/stages/json,null,UNAVAILABLE}
2016-10-12 18:59:05 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3a94964{/stages,null,UNAVAILABLE}
2016-10-12 18:59:05 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@b40bb6e{/jobs/job/json,null,UNAVAILABLE}
2016-10-12 18:59:05 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a48e6e2{/jobs/job,null,UNAVAILABLE}
2016-10-12 18:59:05 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4ae33a11{/jobs/json,null,UNAVAILABLE}
2016-10-12 18:59:05 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@18f20260{/jobs,null,UNAVAILABLE}
2016-10-12 18:59:05 INFO  SparkUI:54 - Stopped Spark web UI at http://150.212.30.95:4043
2016-10-12 18:59:05 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2016-10-12 18:59:05 INFO  MemoryStore:54 - MemoryStore cleared
2016-10-12 18:59:05 INFO  BlockManager:54 - BlockManager stopped
2016-10-12 18:59:05 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2016-10-12 18:59:05 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2016-10-12 18:59:05 INFO  SparkContext:54 - Successfully stopped SparkContext
2016-10-12 18:59:05 INFO  ShutdownHookManager:54 - Shutdown hook called
2016-10-12 18:59:05 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-e40c5a64-8814-4e96-a1e1-3e84d8884642
2016-10-12 18:59:34 INFO  SparkContext:54 - Running Spark version 2.0.0
2016-10-12 18:59:34 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-12 18:59:34 WARN  Utils:66 - Your hostname, aadu-XPS-13-9350 resolves to a loopback address: 127.0.1.1; using 150.212.30.95 instead (on interface wlp58s0)
2016-10-12 18:59:34 WARN  Utils:66 - Set SPARK_LOCAL_IP if you need to bind to another address
2016-10-12 18:59:34 INFO  SecurityManager:54 - Changing view acls to: aadu
2016-10-12 18:59:34 INFO  SecurityManager:54 - Changing modify acls to: aadu
2016-10-12 18:59:34 INFO  SecurityManager:54 - Changing view acls groups to: 
2016-10-12 18:59:34 INFO  SecurityManager:54 - Changing modify acls groups to: 
2016-10-12 18:59:34 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(aadu); groups with view permissions: Set(); users  with modify permissions: Set(aadu); groups with modify permissions: Set()
2016-10-12 18:59:35 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 38035.
2016-10-12 18:59:35 INFO  SparkEnv:54 - Registering MapOutputTracker
2016-10-12 18:59:35 INFO  SparkEnv:54 - Registering BlockManagerMaster
2016-10-12 18:59:35 INFO  DiskBlockManager:54 - Created local directory at /tmp/blockmgr-0d96d604-d120-461f-bcc9-af0fbcc00c53
2016-10-12 18:59:35 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2016-10-12 18:59:35 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2016-10-12 18:59:35 INFO  log:186 - Logging initialized @1515ms
2016-10-12 18:59:35 INFO  Server:327 - jetty-9.2.z-SNAPSHOT
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1643d68f{/storage,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4052274f{/environment,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@297ea53a{/executors,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a7471ce{/static,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@28276e50{/,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@62e70ea3{/api,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,AVAILABLE}
2016-10-12 18:59:35 WARN  AbstractLifeCycle:212 - FAILED ServerConnector@4fe89c24{HTTP/1.1}{0.0.0.0:4040}: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2071)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2062)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:139)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:451)
	at Assign1$.main(a1.scala:19)
	at Assign1.main(a1.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2016-10-12 18:59:35 WARN  AbstractLifeCycle:212 - FAILED org.spark_project.jetty.server.Server@6175619b: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2071)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2062)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:139)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:451)
	at Assign1$.main(a1.scala:19)
	at Assign1.main(a1.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2016-10-12 18:59:35 INFO  ServerConnector:306 - Stopped ServerConnector@4fe89c24{HTTP/1.1}{0.0.0.0:4040}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@62e70ea3{/api,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@28276e50{/,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a7471ce{/static,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@297ea53a{/executors,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4052274f{/environment,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1643d68f{/storage,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,UNAVAILABLE}
2016-10-12 18:59:35 WARN  Utils:66 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2016-10-12 18:59:35 INFO  Server:327 - jetty-9.2.z-SNAPSHOT
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1643d68f{/storage,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4052274f{/environment,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@297ea53a{/executors,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a7471ce{/static,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@28276e50{/,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@62e70ea3{/api,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,AVAILABLE}
2016-10-12 18:59:35 WARN  AbstractLifeCycle:212 - FAILED ServerConnector@2289aca5{HTTP/1.1}{0.0.0.0:4041}: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2071)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2062)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:139)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:451)
	at Assign1$.main(a1.scala:19)
	at Assign1.main(a1.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2016-10-12 18:59:35 WARN  AbstractLifeCycle:212 - FAILED org.spark_project.jetty.server.Server@184497d1: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2071)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2062)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:139)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:451)
	at Assign1$.main(a1.scala:19)
	at Assign1.main(a1.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2016-10-12 18:59:35 INFO  ServerConnector:306 - Stopped ServerConnector@2289aca5{HTTP/1.1}{0.0.0.0:4041}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@62e70ea3{/api,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@28276e50{/,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a7471ce{/static,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@297ea53a{/executors,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4052274f{/environment,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1643d68f{/storage,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,UNAVAILABLE}
2016-10-12 18:59:35 WARN  Utils:66 - Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
2016-10-12 18:59:35 INFO  Server:327 - jetty-9.2.z-SNAPSHOT
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1643d68f{/storage,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4052274f{/environment,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@297ea53a{/executors,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a7471ce{/static,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@28276e50{/,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@62e70ea3{/api,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,AVAILABLE}
2016-10-12 18:59:35 WARN  AbstractLifeCycle:212 - FAILED ServerConnector@2c9399a4{HTTP/1.1}{0.0.0.0:4042}: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2071)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2062)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:139)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:451)
	at Assign1$.main(a1.scala:19)
	at Assign1.main(a1.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2016-10-12 18:59:35 WARN  AbstractLifeCycle:212 - FAILED org.spark_project.jetty.server.Server@9635fa: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2071)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2062)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:139)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:451)
	at Assign1$.main(a1.scala:19)
	at Assign1.main(a1.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2016-10-12 18:59:35 INFO  ServerConnector:306 - Stopped ServerConnector@2c9399a4{HTTP/1.1}{0.0.0.0:4042}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@62e70ea3{/api,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@28276e50{/,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a7471ce{/static,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@297ea53a{/executors,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4052274f{/environment,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1643d68f{/storage,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,UNAVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,UNAVAILABLE}
2016-10-12 18:59:35 WARN  Utils:66 - Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
2016-10-12 18:59:35 INFO  Server:327 - jetty-9.2.z-SNAPSHOT
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1643d68f{/storage,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4052274f{/environment,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@297ea53a{/executors,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a7471ce{/static,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@28276e50{/,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@62e70ea3{/api,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ServerConnector:266 - Started ServerConnector@5fcacc0{HTTP/1.1}{0.0.0.0:4043}
2016-10-12 18:59:35 INFO  Server:379 - Started @1732ms
2016-10-12 18:59:35 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4043.
2016-10-12 18:59:35 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://150.212.30.95:4043
2016-10-12 18:59:35 INFO  SparkContext:54 - Added JAR file:/home/aadu/Repos/adam/adam-assembly/target/adam_2.11-0.19.1-SNAPSHOT.jar at spark://150.212.30.95:38035/jars/adam_2.11-0.19.1-SNAPSHOT.jar with timestamp 1476313175615
2016-10-12 18:59:35 INFO  SparkContext:54 - Added JAR file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/a1.jar at spark://150.212.30.95:38035/jars/a1.jar with timestamp 1476313175617
2016-10-12 18:59:35 INFO  Executor:54 - Starting executor ID driver on host localhost
2016-10-12 18:59:35 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37475.
2016-10-12 18:59:35 INFO  NettyBlockTransferService:54 - Server created on 150.212.30.95:37475
2016-10-12 18:59:35 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 150.212.30.95, 37475)
2016-10-12 18:59:35 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 150.212.30.95:37475 with 366.3 MB RAM, BlockManagerId(driver, 150.212.30.95, 37475)
2016-10-12 18:59:35 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 150.212.30.95, 37475)
2016-10-12 18:59:35 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@30f4b1a6{/metrics/json,null,AVAILABLE}
2016-10-12 18:59:35 INFO  ADAMContext:1336 - Loading small.adam as Parquet containing Genotypes. Sequence dictionary for translation is ignored.
2016-10-12 18:59:35 INFO  ADAMContext:257 - Reading the ADAM file at small.adam to create RDD
2016-10-12 18:59:36 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 268.7 KB, free 366.0 MB)
2016-10-12 18:59:36 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 22.8 KB, free 366.0 MB)
2016-10-12 18:59:36 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 150.212.30.95:37475 (size: 22.8 KB, free: 366.3 MB)
2016-10-12 18:59:36 INFO  SparkContext:54 - Created broadcast 0 from newAPIHadoopFile at ADAMContext.scala:271
2016-10-12 18:59:37 INFO  FileInputFormat:283 - Total input paths to process : 1
2016-10-12 18:59:37 INFO  SparkContext:54 - Starting job: count at a1.scala:32
2016-10-12 18:59:37 INFO  DAGScheduler:54 - Registering RDD 3 (distinct at a1.scala:32)
2016-10-12 18:59:37 INFO  DAGScheduler:54 - Got job 0 (count at a1.scala:32) with 1 output partitions
2016-10-12 18:59:37 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (count at a1.scala:32)
2016-10-12 18:59:37 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 0)
2016-10-12 18:59:37 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 0)
2016-10-12 18:59:37 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at distinct at a1.scala:32), which has no missing parents
2016-10-12 18:59:37 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 4.2 KB, free 366.0 MB)
2016-10-12 18:59:37 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.5 KB, free 366.0 MB)
2016-10-12 18:59:37 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 150.212.30.95:37475 (size: 2.5 KB, free: 366.3 MB)
2016-10-12 18:59:37 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1012
2016-10-12 18:59:37 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at distinct at a1.scala:32)
2016-10-12 18:59:37 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2016-10-12 18:59:37 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5507 bytes)
2016-10-12 18:59:37 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2016-10-12 18:59:37 INFO  Executor:54 - Fetching spark://150.212.30.95:38035/jars/adam_2.11-0.19.1-SNAPSHOT.jar with timestamp 1476313175615
2016-10-12 18:59:37 INFO  TransportClientFactory:250 - Successfully created connection to /150.212.30.95:38035 after 21 ms (0 ms spent in bootstraps)
2016-10-12 18:59:37 INFO  Utils:54 - Fetching spark://150.212.30.95:38035/jars/adam_2.11-0.19.1-SNAPSHOT.jar to /tmp/spark-7a8b9c3b-8c3e-4698-9e98-7b6537dcb0cb/userFiles-03471557-4366-425a-9720-78f3f955c1a2/fetchFileTemp75391496776736872.tmp
2016-10-12 18:59:37 INFO  Executor:54 - Adding file:/tmp/spark-7a8b9c3b-8c3e-4698-9e98-7b6537dcb0cb/userFiles-03471557-4366-425a-9720-78f3f955c1a2/adam_2.11-0.19.1-SNAPSHOT.jar to class loader
2016-10-12 18:59:37 INFO  Executor:54 - Fetching spark://150.212.30.95:38035/jars/a1.jar with timestamp 1476313175617
2016-10-12 18:59:37 INFO  Utils:54 - Fetching spark://150.212.30.95:38035/jars/a1.jar to /tmp/spark-7a8b9c3b-8c3e-4698-9e98-7b6537dcb0cb/userFiles-03471557-4366-425a-9720-78f3f955c1a2/fetchFileTemp4950507873254147221.tmp
2016-10-12 18:59:37 INFO  Executor:54 - Adding file:/tmp/spark-7a8b9c3b-8c3e-4698-9e98-7b6537dcb0cb/userFiles-03471557-4366-425a-9720-78f3f955c1a2/a1.jar to class loader
2016-10-12 18:59:37 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 18:59:37 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 18:59:41 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1490 bytes result sent to driver
2016-10-12 18:59:41 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 4361 ms on localhost (1/1)
2016-10-12 18:59:41 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2016-10-12 18:59:41 INFO  DAGScheduler:54 - ShuffleMapStage 0 (distinct at a1.scala:32) finished in 4.377 s
2016-10-12 18:59:41 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 18:59:41 INFO  DAGScheduler:54 - running: Set()
2016-10-12 18:59:41 INFO  DAGScheduler:54 - waiting: Set(ResultStage 1)
2016-10-12 18:59:41 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 18:59:41 INFO  DAGScheduler:54 - Submitting ResultStage 1 (MapPartitionsRDD[5] at distinct at a1.scala:32), which has no missing parents
2016-10-12 18:59:41 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 3.7 KB, free 366.0 MB)
2016-10-12 18:59:41 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.2 KB, free 366.0 MB)
2016-10-12 18:59:41 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on 150.212.30.95:37475 (size: 2.2 KB, free: 366.3 MB)
2016-10-12 18:59:41 INFO  SparkContext:54 - Created broadcast 2 from broadcast at DAGScheduler.scala:1012
2016-10-12 18:59:41 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at distinct at a1.scala:32)
2016-10-12 18:59:41 INFO  TaskSchedulerImpl:54 - Adding task set 1.0 with 1 tasks
2016-10-12 18:59:41 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, ANY, 5177 bytes)
2016-10-12 18:59:41 INFO  Executor:54 - Running task 0.0 in stage 1.0 (TID 1)
2016-10-12 18:59:41 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 18:59:41 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 3 ms
2016-10-12 18:59:41 INFO  Executor:54 - Finished task 0.0 in stage 1.0 (TID 1). 1512 bytes result sent to driver
2016-10-12 18:59:41 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 1) in 109 ms on localhost (1/1)
2016-10-12 18:59:41 INFO  DAGScheduler:54 - ResultStage 1 (count at a1.scala:32) finished in 0.110 s
2016-10-12 18:59:41 INFO  TaskSchedulerImpl:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2016-10-12 18:59:41 INFO  DAGScheduler:54 - Job 0 finished: count at a1.scala:32, took 4.678348 s
2016-10-12 18:59:41 INFO  SparkContext:54 - Starting job: count at a1.scala:33
2016-10-12 18:59:41 INFO  DAGScheduler:54 - Registering RDD 7 (distinct at a1.scala:33)
2016-10-12 18:59:41 INFO  DAGScheduler:54 - Got job 1 (count at a1.scala:33) with 1 output partitions
2016-10-12 18:59:41 INFO  DAGScheduler:54 - Final stage: ResultStage 3 (count at a1.scala:33)
2016-10-12 18:59:41 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 2)
2016-10-12 18:59:41 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 2)
2016-10-12 18:59:41 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 2 (MapPartitionsRDD[7] at distinct at a1.scala:33), which has no missing parents
2016-10-12 18:59:41 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 4.2 KB, free 366.0 MB)
2016-10-12 18:59:41 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.5 KB, free 366.0 MB)
2016-10-12 18:59:41 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on 150.212.30.95:37475 (size: 2.5 KB, free: 366.3 MB)
2016-10-12 18:59:41 INFO  SparkContext:54 - Created broadcast 3 from broadcast at DAGScheduler.scala:1012
2016-10-12 18:59:41 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[7] at distinct at a1.scala:33)
2016-10-12 18:59:41 INFO  TaskSchedulerImpl:54 - Adding task set 2.0 with 1 tasks
2016-10-12 18:59:41 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5507 bytes)
2016-10-12 18:59:41 INFO  Executor:54 - Running task 0.0 in stage 2.0 (TID 2)
2016-10-12 18:59:41 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 18:59:41 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 18:59:42 INFO  ContextCleaner:54 - Cleaned shuffle 0
2016-10-12 18:59:42 INFO  BlockManagerInfo:54 - Removed broadcast_1_piece0 on 150.212.30.95:37475 in memory (size: 2.5 KB, free: 366.3 MB)
2016-10-12 18:59:42 INFO  BlockManagerInfo:54 - Removed broadcast_2_piece0 on 150.212.30.95:37475 in memory (size: 2.2 KB, free: 366.3 MB)
2016-10-12 18:59:45 INFO  Executor:54 - Finished task 0.0 in stage 2.0 (TID 2). 1490 bytes result sent to driver
2016-10-12 18:59:45 INFO  TaskSetManager:54 - Finished task 0.0 in stage 2.0 (TID 2) in 3356 ms on localhost (1/1)
2016-10-12 18:59:45 INFO  DAGScheduler:54 - ShuffleMapStage 2 (distinct at a1.scala:33) finished in 3.357 s
2016-10-12 18:59:45 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 18:59:45 INFO  DAGScheduler:54 - running: Set()
2016-10-12 18:59:45 INFO  DAGScheduler:54 - waiting: Set(ResultStage 3)
2016-10-12 18:59:45 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 18:59:45 INFO  TaskSchedulerImpl:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2016-10-12 18:59:45 INFO  DAGScheduler:54 - Submitting ResultStage 3 (MapPartitionsRDD[9] at distinct at a1.scala:33), which has no missing parents
2016-10-12 18:59:45 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 3.8 KB, free 366.0 MB)
2016-10-12 18:59:45 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.2 KB, free 366.0 MB)
2016-10-12 18:59:45 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on 150.212.30.95:37475 (size: 2.2 KB, free: 366.3 MB)
2016-10-12 18:59:45 INFO  SparkContext:54 - Created broadcast 4 from broadcast at DAGScheduler.scala:1012
2016-10-12 18:59:45 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[9] at distinct at a1.scala:33)
2016-10-12 18:59:45 INFO  TaskSchedulerImpl:54 - Adding task set 3.0 with 1 tasks
2016-10-12 18:59:45 INFO  TaskSetManager:54 - Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, ANY, 5177 bytes)
2016-10-12 18:59:45 INFO  Executor:54 - Running task 0.0 in stage 3.0 (TID 3)
2016-10-12 18:59:45 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 18:59:45 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 2 ms
2016-10-12 18:59:45 INFO  Executor:54 - Finished task 0.0 in stage 3.0 (TID 3). 1512 bytes result sent to driver
2016-10-12 18:59:45 INFO  TaskSetManager:54 - Finished task 0.0 in stage 3.0 (TID 3) in 55 ms on localhost (1/1)
2016-10-12 18:59:45 INFO  TaskSchedulerImpl:54 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2016-10-12 18:59:45 INFO  DAGScheduler:54 - ResultStage 3 (count at a1.scala:33) finished in 0.057 s
2016-10-12 18:59:45 INFO  DAGScheduler:54 - Job 1 finished: count at a1.scala:33, took 3.476072 s
2016-10-12 18:59:45 INFO  SparkContext:54 - Starting job: collect at a1.scala:34
2016-10-12 18:59:45 INFO  DAGScheduler:54 - Registering RDD 10 (map at a1.scala:34)
2016-10-12 18:59:45 INFO  DAGScheduler:54 - Got job 2 (collect at a1.scala:34) with 1 output partitions
2016-10-12 18:59:45 INFO  DAGScheduler:54 - Final stage: ResultStage 5 (collect at a1.scala:34)
2016-10-12 18:59:45 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 4)
2016-10-12 18:59:45 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 4)
2016-10-12 18:59:45 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 4 (MapPartitionsRDD[10] at map at a1.scala:34), which has no missing parents
2016-10-12 18:59:45 INFO  MemoryStore:54 - Block broadcast_5 stored as values in memory (estimated size 4.0 KB, free 366.0 MB)
2016-10-12 18:59:45 INFO  MemoryStore:54 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.4 KB, free 366.0 MB)
2016-10-12 18:59:45 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on 150.212.30.95:37475 (size: 2.4 KB, free: 366.3 MB)
2016-10-12 18:59:45 INFO  SparkContext:54 - Created broadcast 5 from broadcast at DAGScheduler.scala:1012
2016-10-12 18:59:45 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[10] at map at a1.scala:34)
2016-10-12 18:59:45 INFO  TaskSchedulerImpl:54 - Adding task set 4.0 with 1 tasks
2016-10-12 18:59:45 INFO  TaskSetManager:54 - Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5592 bytes)
2016-10-12 18:59:45 INFO  Executor:54 - Running task 0.0 in stage 4.0 (TID 4)
2016-10-12 18:59:45 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 18:59:45 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 18:59:45 INFO  ContextCleaner:54 - Cleaned shuffle 1
2016-10-12 18:59:45 INFO  BlockManagerInfo:54 - Removed broadcast_3_piece0 on 150.212.30.95:37475 in memory (size: 2.5 KB, free: 366.3 MB)
2016-10-12 18:59:45 INFO  BlockManagerInfo:54 - Removed broadcast_4_piece0 on 150.212.30.95:37475 in memory (size: 2.2 KB, free: 366.3 MB)
2016-10-12 18:59:48 INFO  Executor:54 - Finished task 0.0 in stage 4.0 (TID 4). 1490 bytes result sent to driver
2016-10-12 18:59:48 INFO  TaskSetManager:54 - Finished task 0.0 in stage 4.0 (TID 4) in 3363 ms on localhost (1/1)
2016-10-12 18:59:48 INFO  TaskSchedulerImpl:54 - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2016-10-12 18:59:48 INFO  DAGScheduler:54 - ShuffleMapStage 4 (map at a1.scala:34) finished in 3.365 s
2016-10-12 18:59:48 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 18:59:48 INFO  DAGScheduler:54 - running: Set()
2016-10-12 18:59:48 INFO  DAGScheduler:54 - waiting: Set(ResultStage 5)
2016-10-12 18:59:48 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 18:59:48 INFO  DAGScheduler:54 - Submitting ResultStage 5 (MapPartitionsRDD[13] at map at a1.scala:34), which has no missing parents
2016-10-12 18:59:48 INFO  MemoryStore:54 - Block broadcast_6 stored as values in memory (estimated size 3.8 KB, free 366.0 MB)
2016-10-12 18:59:48 INFO  MemoryStore:54 - Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.2 KB, free 366.0 MB)
2016-10-12 18:59:48 INFO  BlockManagerInfo:54 - Added broadcast_6_piece0 in memory on 150.212.30.95:37475 (size: 2.2 KB, free: 366.3 MB)
2016-10-12 18:59:48 INFO  SparkContext:54 - Created broadcast 6 from broadcast at DAGScheduler.scala:1012
2016-10-12 18:59:48 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[13] at map at a1.scala:34)
2016-10-12 18:59:48 INFO  TaskSchedulerImpl:54 - Adding task set 5.0 with 1 tasks
2016-10-12 18:59:48 INFO  TaskSetManager:54 - Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, ANY, 5262 bytes)
2016-10-12 18:59:48 INFO  Executor:54 - Running task 0.0 in stage 5.0 (TID 5)
2016-10-12 18:59:48 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 18:59:48 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2016-10-12 18:59:48 INFO  Executor:54 - Finished task 0.0 in stage 5.0 (TID 5). 9861 bytes result sent to driver
2016-10-12 18:59:48 INFO  TaskSetManager:54 - Finished task 0.0 in stage 5.0 (TID 5) in 48 ms on localhost (1/1)
2016-10-12 18:59:48 INFO  DAGScheduler:54 - ResultStage 5 (collect at a1.scala:34) finished in 0.049 s
2016-10-12 18:59:48 INFO  DAGScheduler:54 - Job 2 finished: collect at a1.scala:34, took 3.449810 s
2016-10-12 18:59:48 INFO  TaskSchedulerImpl:54 - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2016-10-12 18:59:48 INFO  SparkContext:54 - Starting job: take at a1.scala:43
2016-10-12 18:59:48 INFO  DAGScheduler:54 - Registering RDD 16 (map at a1.scala:41)
2016-10-12 18:59:48 INFO  DAGScheduler:54 - Got job 3 (take at a1.scala:43) with 1 output partitions
2016-10-12 18:59:48 INFO  DAGScheduler:54 - Final stage: ResultStage 7 (take at a1.scala:43)
2016-10-12 18:59:48 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 6)
2016-10-12 18:59:48 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 6)
2016-10-12 18:59:48 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 6 (MapPartitionsRDD[16] at map at a1.scala:41), which has no missing parents
2016-10-12 18:59:48 INFO  MemoryStore:54 - Block broadcast_7 stored as values in memory (estimated size 45.6 KB, free 366.0 MB)
2016-10-12 18:59:48 INFO  MemoryStore:54 - Block broadcast_7_piece0 stored as bytes in memory (estimated size 21.5 KB, free 365.9 MB)
2016-10-12 18:59:48 INFO  BlockManagerInfo:54 - Added broadcast_7_piece0 in memory on 150.212.30.95:37475 (size: 21.5 KB, free: 366.3 MB)
2016-10-12 18:59:48 INFO  SparkContext:54 - Created broadcast 7 from broadcast at DAGScheduler.scala:1012
2016-10-12 18:59:48 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[16] at map at a1.scala:41)
2016-10-12 18:59:48 INFO  TaskSchedulerImpl:54 - Adding task set 6.0 with 1 tasks
2016-10-12 18:59:48 INFO  TaskSetManager:54 - Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, PROCESS_LOCAL, 5589 bytes)
2016-10-12 18:59:48 INFO  Executor:54 - Running task 0.0 in stage 6.0 (TID 6)
2016-10-12 18:59:48 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 18:59:48 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 18:59:49 INFO  BlockManagerInfo:54 - Removed broadcast_5_piece0 on 150.212.30.95:37475 in memory (size: 2.4 KB, free: 366.3 MB)
2016-10-12 18:59:49 INFO  BlockManagerInfo:54 - Removed broadcast_6_piece0 on 150.212.30.95:37475 in memory (size: 2.2 KB, free: 366.3 MB)
2016-10-12 18:59:49 INFO  ContextCleaner:54 - Cleaned shuffle 2
2016-10-12 18:59:53 INFO  Executor:54 - Finished task 0.0 in stage 6.0 (TID 6). 1577 bytes result sent to driver
2016-10-12 18:59:53 INFO  DAGScheduler:54 - ShuffleMapStage 6 (map at a1.scala:41) finished in 4.471 s
2016-10-12 18:59:53 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 18:59:53 INFO  DAGScheduler:54 - running: Set()
2016-10-12 18:59:53 INFO  DAGScheduler:54 - waiting: Set(ResultStage 7)
2016-10-12 18:59:53 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 18:59:53 INFO  TaskSetManager:54 - Finished task 0.0 in stage 6.0 (TID 6) in 4469 ms on localhost (1/1)
2016-10-12 18:59:53 INFO  TaskSchedulerImpl:54 - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2016-10-12 18:59:53 INFO  DAGScheduler:54 - Submitting ResultStage 7 (ShuffledRDD[17] at reduceByKey at a1.scala:41), which has no missing parents
2016-10-12 18:59:53 INFO  MemoryStore:54 - Block broadcast_8 stored as values in memory (estimated size 3.1 KB, free 365.9 MB)
2016-10-12 18:59:53 INFO  MemoryStore:54 - Block broadcast_8_piece0 stored as bytes in memory (estimated size 1923.0 B, free 365.9 MB)
2016-10-12 18:59:53 INFO  BlockManagerInfo:54 - Added broadcast_8_piece0 in memory on 150.212.30.95:37475 (size: 1923.0 B, free: 366.3 MB)
2016-10-12 18:59:53 INFO  SparkContext:54 - Created broadcast 8 from broadcast at DAGScheduler.scala:1012
2016-10-12 18:59:53 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 7 (ShuffledRDD[17] at reduceByKey at a1.scala:41)
2016-10-12 18:59:53 INFO  TaskSchedulerImpl:54 - Adding task set 7.0 with 1 tasks
2016-10-12 18:59:53 INFO  TaskSetManager:54 - Starting task 0.0 in stage 7.0 (TID 7, localhost, partition 0, ANY, 5259 bytes)
2016-10-12 18:59:53 INFO  Executor:54 - Running task 0.0 in stage 7.0 (TID 7)
2016-10-12 18:59:53 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 18:59:53 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2016-10-12 18:59:53 INFO  Executor:54 - Finished task 0.0 in stage 7.0 (TID 7). 2081 bytes result sent to driver
2016-10-12 18:59:53 INFO  DAGScheduler:54 - ResultStage 7 (take at a1.scala:43) finished in 0.073 s
2016-10-12 18:59:53 INFO  DAGScheduler:54 - Job 3 finished: take at a1.scala:43, took 4.588479 s
2016-10-12 18:59:53 INFO  TaskSetManager:54 - Finished task 0.0 in stage 7.0 (TID 7) in 74 ms on localhost (1/1)
2016-10-12 18:59:53 INFO  TaskSchedulerImpl:54 - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2016-10-12 18:59:53 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2016-10-12 18:59:53 INFO  ServerConnector:306 - Stopped ServerConnector@5fcacc0{HTTP/1.1}{0.0.0.0:4043}
2016-10-12 18:59:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,UNAVAILABLE}
2016-10-12 18:59:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@62e70ea3{/api,null,UNAVAILABLE}
2016-10-12 18:59:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@28276e50{/,null,UNAVAILABLE}
2016-10-12 18:59:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a7471ce{/static,null,UNAVAILABLE}
2016-10-12 18:59:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,UNAVAILABLE}
2016-10-12 18:59:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,UNAVAILABLE}
2016-10-12 18:59:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,UNAVAILABLE}
2016-10-12 18:59:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@297ea53a{/executors,null,UNAVAILABLE}
2016-10-12 18:59:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,UNAVAILABLE}
2016-10-12 18:59:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4052274f{/environment,null,UNAVAILABLE}
2016-10-12 18:59:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,UNAVAILABLE}
2016-10-12 18:59:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,UNAVAILABLE}
2016-10-12 18:59:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,UNAVAILABLE}
2016-10-12 18:59:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1643d68f{/storage,null,UNAVAILABLE}
2016-10-12 18:59:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,UNAVAILABLE}
2016-10-12 18:59:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,UNAVAILABLE}
2016-10-12 18:59:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,UNAVAILABLE}
2016-10-12 18:59:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,UNAVAILABLE}
2016-10-12 18:59:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,UNAVAILABLE}
2016-10-12 18:59:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,UNAVAILABLE}
2016-10-12 18:59:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,UNAVAILABLE}
2016-10-12 18:59:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,UNAVAILABLE}
2016-10-12 18:59:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,UNAVAILABLE}
2016-10-12 18:59:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,UNAVAILABLE}
2016-10-12 18:59:53 INFO  SparkUI:54 - Stopped Spark web UI at http://150.212.30.95:4043
2016-10-12 18:59:53 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2016-10-12 18:59:53 INFO  MemoryStore:54 - MemoryStore cleared
2016-10-12 18:59:53 INFO  BlockManager:54 - BlockManager stopped
2016-10-12 18:59:53 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2016-10-12 18:59:53 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2016-10-12 18:59:53 INFO  SparkContext:54 - Successfully stopped SparkContext
2016-10-12 18:59:53 INFO  ShutdownHookManager:54 - Shutdown hook called
2016-10-12 18:59:53 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-7a8b9c3b-8c3e-4698-9e98-7b6537dcb0cb
2016-10-12 19:00:36 WARN  HeartbeatReceiver:66 - Removing executor driver with no recent heartbeats: 3687450 ms exceeds timeout 120000 ms
2016-10-12 19:00:36 ERROR TaskSchedulerImpl:70 - Lost executor driver on localhost: Executor heartbeat timed out after 3687450 ms
2016-10-12 19:00:36 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2016-10-12 19:00:36 WARN  TaskSetManager:66 - Lost task 0.0 in stage 4.0 (TID 4, localhost): ExecutorLostFailure (executor driver exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 3687450 ms
2016-10-12 19:00:36 ERROR TaskSetManager:70 - Task 0 in stage 4.0 failed 1 times; aborting job
2016-10-12 19:00:36 INFO  TaskSchedulerImpl:54 - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2016-10-12 19:00:36 INFO  TaskSchedulerImpl:54 - Cancelling stage 4
2016-10-12 19:00:36 INFO  DAGScheduler:54 - ShuffleMapStage 4 (map at a1.scala:32) failed in 3678.286 s
2016-10-12 19:00:36 INFO  Executor:54 - Told to re-register on heartbeat
2016-10-12 19:00:36 INFO  BlockManager:54 - BlockManager BlockManagerId(driver, 150.212.30.95, 34563) re-registering with master
2016-10-12 19:00:36 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 150.212.30.95, 34563)
2016-10-12 19:00:36 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 150.212.30.95, 34563)
2016-10-12 19:00:36 INFO  BlockManager:54 - Reporting 4 blocks to the master.
2016-10-12 19:00:36 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 150.212.30.95:34563 (size: 22.8 KB, free: 366.3 MB)
2016-10-12 19:00:36 INFO  DAGScheduler:54 - Job 2 failed: collect at a1.scala:32, took 3678.313173 s
2016-10-12 19:00:36 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on 150.212.30.95:34563 (size: 2.4 KB, free: 366.3 MB)
2016-10-12 19:00:36 INFO  Executor:54 - Told to re-register on heartbeat
2016-10-12 19:00:36 INFO  BlockManager:54 - BlockManager BlockManagerId(driver, 150.212.30.95, 34563) re-registering with master
2016-10-12 19:00:36 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 150.212.30.95, 34563)
2016-10-12 19:00:36 WARN  SparkContext:66 - Killing executors is only supported in coarse-grained mode
2016-10-12 19:00:36 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 150.212.30.95, 34563)
2016-10-12 19:00:36 INFO  BlockManager:54 - Reporting 4 blocks to the master.
2016-10-12 19:00:36 INFO  DAGScheduler:54 - Executor lost: driver (epoch 2)
2016-10-12 19:00:36 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 150.212.30.95:34563 (size: 22.8 KB, free: 366.3 MB)
2016-10-12 19:00:36 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on 150.212.30.95:34563 (size: 2.4 KB, free: 366.3 MB)
2016-10-12 19:00:36 INFO  BlockManagerMasterEndpoint:54 - Trying to remove executor driver from BlockManagerMaster.
2016-10-12 19:00:36 INFO  BlockManagerMasterEndpoint:54 - Removing block manager BlockManagerId(driver, 150.212.30.95, 34563)
2016-10-12 19:00:36 INFO  Executor:54 - Told to re-register on heartbeat
2016-10-12 19:00:36 INFO  BlockManager:54 - BlockManager BlockManagerId(driver, 150.212.30.95, 34563) re-registering with master
2016-10-12 19:00:36 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 150.212.30.95, 34563)
2016-10-12 19:00:36 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 150.212.30.95:34563 with 366.3 MB RAM, BlockManagerId(driver, 150.212.30.95, 34563)
2016-10-12 19:00:36 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 150.212.30.95, 34563)
2016-10-12 19:00:36 INFO  BlockManager:54 - Reporting 4 blocks to the master.
2016-10-12 19:00:36 INFO  BlockManagerMaster:54 - Removed driver successfully in removeExecutor
2016-10-12 19:00:36 INFO  DAGScheduler:54 - Host added was in lost list earlier: localhost
2016-10-12 19:00:36 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 150.212.30.95:34563 (size: 22.8 KB, free: 366.3 MB)
2016-10-12 19:00:36 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on 150.212.30.95:34563 (size: 2.4 KB, free: 366.3 MB)
2016-10-12 19:00:36 INFO  Executor:54 - Told to re-register on heartbeat
2016-10-12 19:00:36 INFO  BlockManager:54 - BlockManager BlockManagerId(driver, 150.212.30.95, 34563) re-registering with master
2016-10-12 19:00:36 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 150.212.30.95, 34563)
2016-10-12 19:00:36 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 150.212.30.95, 34563)
2016-10-12 19:00:36 INFO  BlockManager:54 - Reporting 4 blocks to the master.
2016-10-12 19:00:36 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 150.212.30.95:34563 (size: 22.8 KB, free: 366.3 MB)
2016-10-12 19:00:36 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on 150.212.30.95:34563 (size: 2.4 KB, free: 366.3 MB)
2016-10-12 19:00:36 INFO  ServerConnector:306 - Stopped ServerConnector@64337702{HTTP/1.1}{0.0.0.0:4040}
2016-10-12 19:00:36 INFO  Executor:54 - Told to re-register on heartbeat
2016-10-12 19:00:36 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,UNAVAILABLE}
2016-10-12 19:00:36 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@62e70ea3{/api,null,UNAVAILABLE}
2016-10-12 19:00:36 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@28276e50{/,null,UNAVAILABLE}
2016-10-12 19:00:36 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a7471ce{/static,null,UNAVAILABLE}
2016-10-12 19:00:36 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,UNAVAILABLE}
2016-10-12 19:00:36 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,UNAVAILABLE}
2016-10-12 19:00:36 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,UNAVAILABLE}
2016-10-12 19:00:36 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@297ea53a{/executors,null,UNAVAILABLE}
2016-10-12 19:00:36 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,UNAVAILABLE}
2016-10-12 19:00:36 INFO  BlockManager:54 - BlockManager BlockManagerId(driver, 150.212.30.95, 34563) re-registering with master
2016-10-12 19:00:36 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4052274f{/environment,null,UNAVAILABLE}
2016-10-12 19:00:36 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 150.212.30.95, 34563)
2016-10-12 19:00:36 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,UNAVAILABLE}
2016-10-12 19:00:36 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 150.212.30.95, 34563)
2016-10-12 19:00:36 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,UNAVAILABLE}
2016-10-12 19:00:36 INFO  BlockManager:54 - Reporting 4 blocks to the master.
2016-10-12 19:00:36 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,UNAVAILABLE}
2016-10-12 19:00:36 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1643d68f{/storage,null,UNAVAILABLE}
2016-10-12 19:00:36 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 150.212.30.95:34563 (size: 22.8 KB, free: 366.3 MB)
2016-10-12 19:00:36 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on 150.212.30.95:34563 (size: 2.4 KB, free: 366.3 MB)
2016-10-12 19:00:36 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,UNAVAILABLE}
2016-10-12 19:00:36 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,UNAVAILABLE}
2016-10-12 19:00:36 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,UNAVAILABLE}
2016-10-12 19:00:36 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,UNAVAILABLE}
2016-10-12 19:00:36 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,UNAVAILABLE}
2016-10-12 19:00:36 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,UNAVAILABLE}
2016-10-12 19:00:36 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,UNAVAILABLE}
2016-10-12 19:00:36 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,UNAVAILABLE}
2016-10-12 19:00:36 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,UNAVAILABLE}
2016-10-12 19:00:36 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,UNAVAILABLE}
2016-10-12 19:00:36 INFO  Executor:54 - Told to re-register on heartbeat
2016-10-12 19:00:36 INFO  BlockManager:54 - BlockManager BlockManagerId(driver, 150.212.30.95, 34563) re-registering with master
2016-10-12 19:00:36 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 150.212.30.95, 34563)
2016-10-12 19:00:36 INFO  SparkUI:54 - Stopped Spark web UI at http://150.212.30.95:4040
2016-10-12 19:00:36 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 150.212.30.95, 34563)
2016-10-12 19:00:36 INFO  BlockManager:54 - Reporting 4 blocks to the master.
2016-10-12 19:00:36 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 150.212.30.95:34563 (size: 22.8 KB, free: 366.3 MB)
2016-10-12 19:00:36 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on 150.212.30.95:34563 (size: 2.4 KB, free: 366.3 MB)
2016-10-12 19:00:36 INFO  Executor:54 - Told to re-register on heartbeat
2016-10-12 19:00:36 INFO  BlockManager:54 - BlockManager BlockManagerId(driver, 150.212.30.95, 34563) re-registering with master
2016-10-12 19:00:36 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 150.212.30.95, 34563)
2016-10-12 19:00:36 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 150.212.30.95, 34563)
2016-10-12 19:00:36 INFO  BlockManager:54 - Reporting 4 blocks to the master.
2016-10-12 19:00:36 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 150.212.30.95:34563 (size: 22.8 KB, free: 366.3 MB)
2016-10-12 19:00:36 ERROR LiveListenerBus:70 - SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(driver, 150.212.30.95, 34563),broadcast_0_piece0,StorageLevel(memory, 1 replicas),23364,0))
2016-10-12 19:00:36 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on 150.212.30.95:34563 (size: 2.4 KB, free: 366.3 MB)
2016-10-12 19:00:36 ERROR LiveListenerBus:70 - SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(driver, 150.212.30.95, 34563),broadcast_5_piece0,StorageLevel(memory, 1 replicas),2475,0))
2016-10-12 19:00:36 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2016-10-12 19:00:36 INFO  MemoryStore:54 - MemoryStore cleared
2016-10-12 19:00:36 INFO  BlockManager:54 - BlockManager stopped
2016-10-12 19:00:36 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2016-10-12 19:00:36 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2016-10-12 19:00:36 INFO  SparkContext:54 - Successfully stopped SparkContext
2016-10-12 19:00:36 INFO  ShutdownHookManager:54 - Shutdown hook called
2016-10-12 19:00:36 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-cb8eaee3-2a40-419f-8390-200d9c3f9ae0
2016-10-12 19:00:45 WARN  HeartbeatReceiver:66 - Removing executor driver with no recent heartbeats: 1761702 ms exceeds timeout 120000 ms
2016-10-12 19:00:45 ERROR TaskSchedulerImpl:70 - Lost an executor driver (already removed): Executor heartbeat timed out after 1761702 ms
2016-10-12 19:00:45 WARN  SparkContext:66 - Killing executors is only supported in coarse-grained mode
2016-10-12 19:00:45 WARN  NettyRpcEndpointRef:87 - Error sending message [message = Heartbeat(driver,[Lscala.Tuple2;@2424811,BlockManagerId(driver, 150.212.30.95, 40741))] in 1 attempts
org.apache.spark.SparkException: Exception thrown in awaitResult
	at org.apache.spark.rpc.RpcTimeout$$anonfun$1.applyOrElse(RpcTimeout.scala:77)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$1.applyOrElse(RpcTimeout.scala:75)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:59)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:59)
	at scala.PartialFunction$OrElse.apply(PartialFunction.scala:167)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:83)
	at org.apache.spark.rpc.RpcEndpointRef.askWithRetry(RpcEndpointRef.scala:102)
	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:518)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply$mcV$sp(Executor.scala:547)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:547)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:547)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1857)
	at org.apache.spark.executor.Executor$$anon$1.run(Executor.scala:547)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.spark.SparkException: Could not find HeartbeatReceiver.
	at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:152)
	at org.apache.spark.rpc.netty.Dispatcher.postLocalMessage(Dispatcher.scala:127)
	at org.apache.spark.rpc.netty.NettyRpcEnv.ask(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEndpointRef.ask(NettyRpcEnv.scala:508)
	at org.apache.spark.rpc.RpcEndpointRef.askWithRetry(RpcEndpointRef.scala:101)
	... 13 more
2016-10-12 19:00:48 WARN  NettyRpcEnv:66 - Ignored failure: java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@16d37ac5 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@641bace[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
2016-10-12 19:00:48 WARN  NettyRpcEndpointRef:87 - Error sending message [message = Heartbeat(driver,[Lscala.Tuple2;@2424811,BlockManagerId(driver, 150.212.30.95, 40741))] in 2 attempts
org.apache.spark.SparkException: Exception thrown in awaitResult
	at org.apache.spark.rpc.RpcTimeout$$anonfun$1.applyOrElse(RpcTimeout.scala:77)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$1.applyOrElse(RpcTimeout.scala:75)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:59)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:59)
	at scala.PartialFunction$OrElse.apply(PartialFunction.scala:167)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:83)
	at org.apache.spark.rpc.RpcEndpointRef.askWithRetry(RpcEndpointRef.scala:102)
	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:518)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply$mcV$sp(Executor.scala:547)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:547)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:547)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1857)
	at org.apache.spark.executor.Executor$$anon$1.run(Executor.scala:547)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.spark.rpc.RpcEnvStoppedException: RpcEnv already stopped.
	at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:150)
	at org.apache.spark.rpc.netty.Dispatcher.postLocalMessage(Dispatcher.scala:127)
	at org.apache.spark.rpc.netty.NettyRpcEnv.ask(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEndpointRef.ask(NettyRpcEnv.scala:508)
	at org.apache.spark.rpc.RpcEndpointRef.askWithRetry(RpcEndpointRef.scala:101)
	... 13 more
2016-10-12 19:00:51 WARN  NettyRpcEnv:66 - Ignored failure: java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@21ea27af rejected from java.util.concurrent.ScheduledThreadPoolExecutor@641bace[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
2016-10-12 19:00:51 WARN  NettyRpcEndpointRef:87 - Error sending message [message = Heartbeat(driver,[Lscala.Tuple2;@2424811,BlockManagerId(driver, 150.212.30.95, 40741))] in 3 attempts
org.apache.spark.SparkException: Exception thrown in awaitResult
	at org.apache.spark.rpc.RpcTimeout$$anonfun$1.applyOrElse(RpcTimeout.scala:77)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$1.applyOrElse(RpcTimeout.scala:75)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:59)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:59)
	at scala.PartialFunction$OrElse.apply(PartialFunction.scala:167)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:83)
	at org.apache.spark.rpc.RpcEndpointRef.askWithRetry(RpcEndpointRef.scala:102)
	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:518)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply$mcV$sp(Executor.scala:547)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:547)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:547)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1857)
	at org.apache.spark.executor.Executor$$anon$1.run(Executor.scala:547)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.spark.rpc.RpcEnvStoppedException: RpcEnv already stopped.
	at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:150)
	at org.apache.spark.rpc.netty.Dispatcher.postLocalMessage(Dispatcher.scala:127)
	at org.apache.spark.rpc.netty.NettyRpcEnv.ask(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEndpointRef.ask(NettyRpcEnv.scala:508)
	at org.apache.spark.rpc.RpcEndpointRef.askWithRetry(RpcEndpointRef.scala:101)
	... 13 more
2016-10-12 19:00:51 WARN  Executor:87 - Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Error sending message [message = Heartbeat(driver,[Lscala.Tuple2;@2424811,BlockManagerId(driver, 150.212.30.95, 40741))]
	at org.apache.spark.rpc.RpcEndpointRef.askWithRetry(RpcEndpointRef.scala:119)
	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:518)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply$mcV$sp(Executor.scala:547)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:547)
	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:547)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1857)
	at org.apache.spark.executor.Executor$$anon$1.run(Executor.scala:547)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult
	at org.apache.spark.rpc.RpcTimeout$$anonfun$1.applyOrElse(RpcTimeout.scala:77)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$1.applyOrElse(RpcTimeout.scala:75)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:59)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:59)
	at scala.PartialFunction$OrElse.apply(PartialFunction.scala:167)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:83)
	at org.apache.spark.rpc.RpcEndpointRef.askWithRetry(RpcEndpointRef.scala:102)
	... 13 more
Caused by: org.apache.spark.rpc.RpcEnvStoppedException: RpcEnv already stopped.
	at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:150)
	at org.apache.spark.rpc.netty.Dispatcher.postLocalMessage(Dispatcher.scala:127)
	at org.apache.spark.rpc.netty.NettyRpcEnv.ask(NettyRpcEnv.scala:225)
	at org.apache.spark.rpc.netty.NettyRpcEndpointRef.ask(NettyRpcEnv.scala:508)
	at org.apache.spark.rpc.RpcEndpointRef.askWithRetry(RpcEndpointRef.scala:101)
	... 13 more
2016-10-12 19:03:07 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-12 19:03:07 WARN  Utils:66 - Your hostname, aadu-XPS-13-9350 resolves to a loopback address: 127.0.1.1; using 150.212.30.95 instead (on interface wlp58s0)
2016-10-12 19:03:07 WARN  Utils:66 - Set SPARK_LOCAL_IP if you need to bind to another address
2016-10-12 19:03:08 WARN  SparkContext:66 - Use an existing SparkContext, some configuration may not take effect.
2016-10-12 19:05:13 INFO  SparkContext:54 - Running Spark version 2.0.0
2016-10-12 19:05:13 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-12 19:05:13 WARN  Utils:66 - Your hostname, aadu-XPS-13-9350 resolves to a loopback address: 127.0.1.1; using 150.212.30.95 instead (on interface wlp58s0)
2016-10-12 19:05:13 WARN  Utils:66 - Set SPARK_LOCAL_IP if you need to bind to another address
2016-10-12 19:05:13 INFO  SecurityManager:54 - Changing view acls to: aadu
2016-10-12 19:05:13 INFO  SecurityManager:54 - Changing modify acls to: aadu
2016-10-12 19:05:13 INFO  SecurityManager:54 - Changing view acls groups to: 
2016-10-12 19:05:13 INFO  SecurityManager:54 - Changing modify acls groups to: 
2016-10-12 19:05:13 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(aadu); groups with view permissions: Set(); users  with modify permissions: Set(aadu); groups with modify permissions: Set()
2016-10-12 19:05:14 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 36469.
2016-10-12 19:05:14 INFO  SparkEnv:54 - Registering MapOutputTracker
2016-10-12 19:05:14 INFO  SparkEnv:54 - Registering BlockManagerMaster
2016-10-12 19:05:14 INFO  DiskBlockManager:54 - Created local directory at /tmp/blockmgr-bf884325-b674-479b-8129-a35bb798f884
2016-10-12 19:05:14 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2016-10-12 19:05:14 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2016-10-12 19:05:14 INFO  log:186 - Logging initialized @1435ms
2016-10-12 19:05:14 INFO  Server:327 - jetty-9.2.z-SNAPSHOT
2016-10-12 19:05:14 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,AVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,AVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,AVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,AVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,AVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,AVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,AVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,AVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,AVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,AVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1643d68f{/storage,null,AVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,AVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,AVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,AVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4052274f{/environment,null,AVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,AVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@297ea53a{/executors,null,AVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,AVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,AVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,AVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a7471ce{/static,null,AVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@28276e50{/,null,AVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@62e70ea3{/api,null,AVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,AVAILABLE}
2016-10-12 19:05:14 WARN  AbstractLifeCycle:212 - FAILED ServerConnector@4fe89c24{HTTP/1.1}{0.0.0.0:4040}: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2071)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2062)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:139)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:451)
	at Assign1$.main(a1.scala:19)
	at Assign1.main(a1.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2016-10-12 19:05:14 WARN  AbstractLifeCycle:212 - FAILED org.spark_project.jetty.server.Server@6175619b: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2071)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2062)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:139)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:451)
	at Assign1$.main(a1.scala:19)
	at Assign1.main(a1.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2016-10-12 19:05:14 INFO  ServerConnector:306 - Stopped ServerConnector@4fe89c24{HTTP/1.1}{0.0.0.0:4040}
2016-10-12 19:05:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,UNAVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@62e70ea3{/api,null,UNAVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@28276e50{/,null,UNAVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a7471ce{/static,null,UNAVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,UNAVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,UNAVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,UNAVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@297ea53a{/executors,null,UNAVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,UNAVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4052274f{/environment,null,UNAVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,UNAVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,UNAVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,UNAVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1643d68f{/storage,null,UNAVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,UNAVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,UNAVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,UNAVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,UNAVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,UNAVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,UNAVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,UNAVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,UNAVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,UNAVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,UNAVAILABLE}
2016-10-12 19:05:14 WARN  Utils:66 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2016-10-12 19:05:14 INFO  Server:327 - jetty-9.2.z-SNAPSHOT
2016-10-12 19:05:14 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,AVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,AVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,AVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,AVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,AVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,AVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,AVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,AVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,AVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,AVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1643d68f{/storage,null,AVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,AVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,AVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,AVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4052274f{/environment,null,AVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,AVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@297ea53a{/executors,null,AVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,AVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,AVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,AVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a7471ce{/static,null,AVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@28276e50{/,null,AVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@62e70ea3{/api,null,AVAILABLE}
2016-10-12 19:05:14 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,AVAILABLE}
2016-10-12 19:05:14 INFO  ServerConnector:266 - Started ServerConnector@6c67e137{HTTP/1.1}{0.0.0.0:4041}
2016-10-12 19:05:14 INFO  Server:379 - Started @1591ms
2016-10-12 19:05:14 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4041.
2016-10-12 19:05:14 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://150.212.30.95:4041
2016-10-12 19:05:14 INFO  SparkContext:54 - Added JAR file:/home/aadu/Repos/adam/adam-assembly/target/adam_2.11-0.19.1-SNAPSHOT.jar at spark://150.212.30.95:36469/jars/adam_2.11-0.19.1-SNAPSHOT.jar with timestamp 1476313514639
2016-10-12 19:05:14 INFO  SparkContext:54 - Added JAR file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/a1.jar at spark://150.212.30.95:36469/jars/a1.jar with timestamp 1476313514641
2016-10-12 19:05:14 INFO  Executor:54 - Starting executor ID driver on host localhost
2016-10-12 19:05:14 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44347.
2016-10-12 19:05:14 INFO  NettyBlockTransferService:54 - Server created on 150.212.30.95:44347
2016-10-12 19:05:14 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 150.212.30.95, 44347)
2016-10-12 19:05:14 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 150.212.30.95:44347 with 366.3 MB RAM, BlockManagerId(driver, 150.212.30.95, 44347)
2016-10-12 19:05:14 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 150.212.30.95, 44347)
2016-10-12 19:05:14 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2472c7d8{/metrics/json,null,AVAILABLE}
2016-10-12 19:05:14 INFO  ADAMContext:1336 - Loading small.adam as Parquet containing Genotypes. Sequence dictionary for translation is ignored.
2016-10-12 19:05:14 INFO  ADAMContext:257 - Reading the ADAM file at small.adam to create RDD
2016-10-12 19:05:15 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 268.7 KB, free 366.0 MB)
2016-10-12 19:05:16 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 22.8 KB, free 366.0 MB)
2016-10-12 19:05:16 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 150.212.30.95:44347 (size: 22.8 KB, free: 366.3 MB)
2016-10-12 19:05:16 INFO  SparkContext:54 - Created broadcast 0 from newAPIHadoopFile at ADAMContext.scala:271
2016-10-12 19:05:16 INFO  FileInputFormat:283 - Total input paths to process : 1
2016-10-12 19:05:16 INFO  SparkContext:54 - Starting job: count at a1.scala:32
2016-10-12 19:05:16 INFO  DAGScheduler:54 - Registering RDD 3 (distinct at a1.scala:32)
2016-10-12 19:05:16 INFO  DAGScheduler:54 - Got job 0 (count at a1.scala:32) with 1 output partitions
2016-10-12 19:05:16 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (count at a1.scala:32)
2016-10-12 19:05:16 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 0)
2016-10-12 19:05:16 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 0)
2016-10-12 19:05:16 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at distinct at a1.scala:32), which has no missing parents
2016-10-12 19:05:16 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 4.2 KB, free 366.0 MB)
2016-10-12 19:05:16 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.5 KB, free 366.0 MB)
2016-10-12 19:05:16 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 150.212.30.95:44347 (size: 2.5 KB, free: 366.3 MB)
2016-10-12 19:05:16 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1012
2016-10-12 19:05:16 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at distinct at a1.scala:32)
2016-10-12 19:05:16 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2016-10-12 19:05:16 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5507 bytes)
2016-10-12 19:05:16 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2016-10-12 19:05:16 INFO  Executor:54 - Fetching spark://150.212.30.95:36469/jars/adam_2.11-0.19.1-SNAPSHOT.jar with timestamp 1476313514639
2016-10-12 19:05:16 INFO  TransportClientFactory:250 - Successfully created connection to /150.212.30.95:36469 after 37 ms (0 ms spent in bootstraps)
2016-10-12 19:05:16 INFO  Utils:54 - Fetching spark://150.212.30.95:36469/jars/adam_2.11-0.19.1-SNAPSHOT.jar to /tmp/spark-a9e4c00a-e651-4e9b-8985-e935ad7239aa/userFiles-2b7ed647-8209-4cc8-bd77-9747099bd0f3/fetchFileTemp206457883743053460.tmp
2016-10-12 19:05:16 INFO  Executor:54 - Adding file:/tmp/spark-a9e4c00a-e651-4e9b-8985-e935ad7239aa/userFiles-2b7ed647-8209-4cc8-bd77-9747099bd0f3/adam_2.11-0.19.1-SNAPSHOT.jar to class loader
2016-10-12 19:05:16 INFO  Executor:54 - Fetching spark://150.212.30.95:36469/jars/a1.jar with timestamp 1476313514641
2016-10-12 19:05:16 INFO  Utils:54 - Fetching spark://150.212.30.95:36469/jars/a1.jar to /tmp/spark-a9e4c00a-e651-4e9b-8985-e935ad7239aa/userFiles-2b7ed647-8209-4cc8-bd77-9747099bd0f3/fetchFileTemp6479540820354109222.tmp
2016-10-12 19:05:16 INFO  Executor:54 - Adding file:/tmp/spark-a9e4c00a-e651-4e9b-8985-e935ad7239aa/userFiles-2b7ed647-8209-4cc8-bd77-9747099bd0f3/a1.jar to class loader
2016-10-12 19:05:16 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 19:05:16 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 19:05:20 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1490 bytes result sent to driver
2016-10-12 19:05:20 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 4131 ms on localhost (1/1)
2016-10-12 19:05:20 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2016-10-12 19:05:20 INFO  DAGScheduler:54 - ShuffleMapStage 0 (distinct at a1.scala:32) finished in 4.148 s
2016-10-12 19:05:20 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 19:05:20 INFO  DAGScheduler:54 - running: Set()
2016-10-12 19:05:20 INFO  DAGScheduler:54 - waiting: Set(ResultStage 1)
2016-10-12 19:05:20 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 19:05:20 INFO  DAGScheduler:54 - Submitting ResultStage 1 (MapPartitionsRDD[5] at distinct at a1.scala:32), which has no missing parents
2016-10-12 19:05:20 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 3.7 KB, free 366.0 MB)
2016-10-12 19:05:20 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.2 KB, free 366.0 MB)
2016-10-12 19:05:20 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on 150.212.30.95:44347 (size: 2.2 KB, free: 366.3 MB)
2016-10-12 19:05:20 INFO  SparkContext:54 - Created broadcast 2 from broadcast at DAGScheduler.scala:1012
2016-10-12 19:05:20 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at distinct at a1.scala:32)
2016-10-12 19:05:20 INFO  TaskSchedulerImpl:54 - Adding task set 1.0 with 1 tasks
2016-10-12 19:05:20 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, ANY, 5177 bytes)
2016-10-12 19:05:20 INFO  Executor:54 - Running task 0.0 in stage 1.0 (TID 1)
2016-10-12 19:05:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 19:05:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 4 ms
2016-10-12 19:05:20 INFO  Executor:54 - Finished task 0.0 in stage 1.0 (TID 1). 1512 bytes result sent to driver
2016-10-12 19:05:20 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 1) in 100 ms on localhost (1/1)
2016-10-12 19:05:20 INFO  DAGScheduler:54 - ResultStage 1 (count at a1.scala:32) finished in 0.101 s
2016-10-12 19:05:20 INFO  TaskSchedulerImpl:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2016-10-12 19:05:20 INFO  DAGScheduler:54 - Job 0 finished: count at a1.scala:32, took 4.444340 s
2016-10-12 19:05:20 INFO  SparkContext:54 - Starting job: count at a1.scala:33
2016-10-12 19:05:20 INFO  DAGScheduler:54 - Registering RDD 7 (distinct at a1.scala:33)
2016-10-12 19:05:20 INFO  DAGScheduler:54 - Got job 1 (count at a1.scala:33) with 1 output partitions
2016-10-12 19:05:20 INFO  DAGScheduler:54 - Final stage: ResultStage 3 (count at a1.scala:33)
2016-10-12 19:05:20 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 2)
2016-10-12 19:05:20 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 2)
2016-10-12 19:05:20 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 2 (MapPartitionsRDD[7] at distinct at a1.scala:33), which has no missing parents
2016-10-12 19:05:20 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 4.2 KB, free 366.0 MB)
2016-10-12 19:05:20 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.5 KB, free 366.0 MB)
2016-10-12 19:05:20 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on 150.212.30.95:44347 (size: 2.5 KB, free: 366.3 MB)
2016-10-12 19:05:20 INFO  SparkContext:54 - Created broadcast 3 from broadcast at DAGScheduler.scala:1012
2016-10-12 19:05:20 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[7] at distinct at a1.scala:33)
2016-10-12 19:05:20 INFO  TaskSchedulerImpl:54 - Adding task set 2.0 with 1 tasks
2016-10-12 19:05:20 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5507 bytes)
2016-10-12 19:05:20 INFO  Executor:54 - Running task 0.0 in stage 2.0 (TID 2)
2016-10-12 19:05:20 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 19:05:20 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 19:05:21 INFO  BlockManagerInfo:54 - Removed broadcast_2_piece0 on 150.212.30.95:44347 in memory (size: 2.2 KB, free: 366.3 MB)
2016-10-12 19:05:21 INFO  BlockManagerInfo:54 - Removed broadcast_1_piece0 on 150.212.30.95:44347 in memory (size: 2.5 KB, free: 366.3 MB)
2016-10-12 19:05:21 INFO  ContextCleaner:54 - Cleaned shuffle 0
2016-10-12 19:05:23 INFO  Executor:54 - Finished task 0.0 in stage 2.0 (TID 2). 1490 bytes result sent to driver
2016-10-12 19:05:23 INFO  TaskSetManager:54 - Finished task 0.0 in stage 2.0 (TID 2) in 3215 ms on localhost (1/1)
2016-10-12 19:05:23 INFO  DAGScheduler:54 - ShuffleMapStage 2 (distinct at a1.scala:33) finished in 3.216 s
2016-10-12 19:05:23 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 19:05:23 INFO  DAGScheduler:54 - running: Set()
2016-10-12 19:05:23 INFO  DAGScheduler:54 - waiting: Set(ResultStage 3)
2016-10-12 19:05:23 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 19:05:23 INFO  TaskSchedulerImpl:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2016-10-12 19:05:23 INFO  DAGScheduler:54 - Submitting ResultStage 3 (MapPartitionsRDD[9] at distinct at a1.scala:33), which has no missing parents
2016-10-12 19:05:23 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 3.8 KB, free 366.0 MB)
2016-10-12 19:05:23 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.2 KB, free 366.0 MB)
2016-10-12 19:05:23 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on 150.212.30.95:44347 (size: 2.2 KB, free: 366.3 MB)
2016-10-12 19:05:23 INFO  SparkContext:54 - Created broadcast 4 from broadcast at DAGScheduler.scala:1012
2016-10-12 19:05:23 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[9] at distinct at a1.scala:33)
2016-10-12 19:05:23 INFO  TaskSchedulerImpl:54 - Adding task set 3.0 with 1 tasks
2016-10-12 19:05:23 INFO  TaskSetManager:54 - Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, ANY, 5177 bytes)
2016-10-12 19:05:23 INFO  Executor:54 - Running task 0.0 in stage 3.0 (TID 3)
2016-10-12 19:05:23 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 19:05:23 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2016-10-12 19:05:24 INFO  Executor:54 - Finished task 0.0 in stage 3.0 (TID 3). 1512 bytes result sent to driver
2016-10-12 19:05:24 INFO  DAGScheduler:54 - ResultStage 3 (count at a1.scala:33) finished in 0.040 s
2016-10-12 19:05:24 INFO  TaskSetManager:54 - Finished task 0.0 in stage 3.0 (TID 3) in 47 ms on localhost (1/1)
2016-10-12 19:05:24 INFO  DAGScheduler:54 - Job 1 finished: count at a1.scala:33, took 3.329949 s
2016-10-12 19:05:24 INFO  TaskSchedulerImpl:54 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2016-10-12 19:05:24 INFO  SparkContext:54 - Starting job: collect at a1.scala:34
2016-10-12 19:05:24 INFO  DAGScheduler:54 - Registering RDD 10 (map at a1.scala:34)
2016-10-12 19:05:24 INFO  DAGScheduler:54 - Got job 2 (collect at a1.scala:34) with 1 output partitions
2016-10-12 19:05:24 INFO  DAGScheduler:54 - Final stage: ResultStage 5 (collect at a1.scala:34)
2016-10-12 19:05:24 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 4)
2016-10-12 19:05:24 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 4)
2016-10-12 19:05:24 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 4 (MapPartitionsRDD[10] at map at a1.scala:34), which has no missing parents
2016-10-12 19:05:24 INFO  MemoryStore:54 - Block broadcast_5 stored as values in memory (estimated size 4.0 KB, free 366.0 MB)
2016-10-12 19:05:24 INFO  MemoryStore:54 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.4 KB, free 366.0 MB)
2016-10-12 19:05:24 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on 150.212.30.95:44347 (size: 2.4 KB, free: 366.3 MB)
2016-10-12 19:05:24 INFO  SparkContext:54 - Created broadcast 5 from broadcast at DAGScheduler.scala:1012
2016-10-12 19:05:24 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[10] at map at a1.scala:34)
2016-10-12 19:05:24 INFO  TaskSchedulerImpl:54 - Adding task set 4.0 with 1 tasks
2016-10-12 19:05:24 INFO  TaskSetManager:54 - Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5592 bytes)
2016-10-12 19:05:24 INFO  Executor:54 - Running task 0.0 in stage 4.0 (TID 4)
2016-10-12 19:05:24 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 19:05:24 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 19:05:24 INFO  BlockManagerInfo:54 - Removed broadcast_3_piece0 on 150.212.30.95:44347 in memory (size: 2.5 KB, free: 366.3 MB)
2016-10-12 19:05:24 INFO  BlockManagerInfo:54 - Removed broadcast_4_piece0 on 150.212.30.95:44347 in memory (size: 2.2 KB, free: 366.3 MB)
2016-10-12 19:05:24 INFO  ContextCleaner:54 - Cleaned shuffle 1
2016-10-12 19:05:27 INFO  Executor:54 - Finished task 0.0 in stage 4.0 (TID 4). 1490 bytes result sent to driver
2016-10-12 19:05:27 INFO  TaskSetManager:54 - Finished task 0.0 in stage 4.0 (TID 4) in 3216 ms on localhost (1/1)
2016-10-12 19:05:27 INFO  DAGScheduler:54 - ShuffleMapStage 4 (map at a1.scala:34) finished in 3.216 s
2016-10-12 19:05:27 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 19:05:27 INFO  DAGScheduler:54 - running: Set()
2016-10-12 19:05:27 INFO  DAGScheduler:54 - waiting: Set(ResultStage 5)
2016-10-12 19:05:27 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 19:05:27 INFO  DAGScheduler:54 - Submitting ResultStage 5 (MapPartitionsRDD[13] at map at a1.scala:34), which has no missing parents
2016-10-12 19:05:27 INFO  TaskSchedulerImpl:54 - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2016-10-12 19:05:27 INFO  MemoryStore:54 - Block broadcast_6 stored as values in memory (estimated size 3.8 KB, free 366.0 MB)
2016-10-12 19:05:27 INFO  MemoryStore:54 - Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.2 KB, free 366.0 MB)
2016-10-12 19:05:27 INFO  BlockManagerInfo:54 - Added broadcast_6_piece0 in memory on 150.212.30.95:44347 (size: 2.2 KB, free: 366.3 MB)
2016-10-12 19:05:27 INFO  SparkContext:54 - Created broadcast 6 from broadcast at DAGScheduler.scala:1012
2016-10-12 19:05:27 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[13] at map at a1.scala:34)
2016-10-12 19:05:27 INFO  TaskSchedulerImpl:54 - Adding task set 5.0 with 1 tasks
2016-10-12 19:05:27 INFO  TaskSetManager:54 - Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, ANY, 5262 bytes)
2016-10-12 19:05:27 INFO  Executor:54 - Running task 0.0 in stage 5.0 (TID 5)
2016-10-12 19:05:27 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 19:05:27 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 2 ms
2016-10-12 19:05:27 INFO  Executor:54 - Finished task 0.0 in stage 5.0 (TID 5). 9861 bytes result sent to driver
2016-10-12 19:05:27 INFO  DAGScheduler:54 - ResultStage 5 (collect at a1.scala:34) finished in 0.050 s
2016-10-12 19:05:27 INFO  DAGScheduler:54 - Job 2 finished: collect at a1.scala:34, took 3.314774 s
2016-10-12 19:05:27 INFO  TaskSetManager:54 - Finished task 0.0 in stage 5.0 (TID 5) in 48 ms on localhost (1/1)
2016-10-12 19:05:27 INFO  TaskSchedulerImpl:54 - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2016-10-12 19:05:27 INFO  SparkContext:54 - Starting job: take at a1.scala:43
2016-10-12 19:05:27 INFO  DAGScheduler:54 - Registering RDD 16 (map at a1.scala:41)
2016-10-12 19:05:27 INFO  DAGScheduler:54 - Got job 3 (take at a1.scala:43) with 1 output partitions
2016-10-12 19:05:27 INFO  DAGScheduler:54 - Final stage: ResultStage 7 (take at a1.scala:43)
2016-10-12 19:05:27 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 6)
2016-10-12 19:05:27 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 6)
2016-10-12 19:05:27 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 6 (MapPartitionsRDD[16] at map at a1.scala:41), which has no missing parents
2016-10-12 19:05:27 INFO  MemoryStore:54 - Block broadcast_7 stored as values in memory (estimated size 45.6 KB, free 366.0 MB)
2016-10-12 19:05:27 INFO  MemoryStore:54 - Block broadcast_7_piece0 stored as bytes in memory (estimated size 21.5 KB, free 365.9 MB)
2016-10-12 19:05:27 INFO  BlockManagerInfo:54 - Added broadcast_7_piece0 in memory on 150.212.30.95:44347 (size: 21.5 KB, free: 366.3 MB)
2016-10-12 19:05:27 INFO  SparkContext:54 - Created broadcast 7 from broadcast at DAGScheduler.scala:1012
2016-10-12 19:05:27 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[16] at map at a1.scala:41)
2016-10-12 19:05:27 INFO  TaskSchedulerImpl:54 - Adding task set 6.0 with 1 tasks
2016-10-12 19:05:27 INFO  TaskSetManager:54 - Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, PROCESS_LOCAL, 5589 bytes)
2016-10-12 19:05:27 INFO  Executor:54 - Running task 0.0 in stage 6.0 (TID 6)
2016-10-12 19:05:27 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 19:05:27 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 19:05:28 INFO  BlockManagerInfo:54 - Removed broadcast_5_piece0 on 150.212.30.95:44347 in memory (size: 2.4 KB, free: 366.3 MB)
2016-10-12 19:05:28 INFO  BlockManagerInfo:54 - Removed broadcast_6_piece0 on 150.212.30.95:44347 in memory (size: 2.2 KB, free: 366.3 MB)
2016-10-12 19:05:28 INFO  ContextCleaner:54 - Cleaned shuffle 2
2016-10-12 19:05:31 INFO  Executor:54 - Finished task 0.0 in stage 6.0 (TID 6). 1490 bytes result sent to driver
2016-10-12 19:05:31 INFO  TaskSetManager:54 - Finished task 0.0 in stage 6.0 (TID 6) in 4383 ms on localhost (1/1)
2016-10-12 19:05:31 INFO  TaskSchedulerImpl:54 - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2016-10-12 19:05:31 INFO  DAGScheduler:54 - ShuffleMapStage 6 (map at a1.scala:41) finished in 4.383 s
2016-10-12 19:05:31 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 19:05:31 INFO  DAGScheduler:54 - running: Set()
2016-10-12 19:05:31 INFO  DAGScheduler:54 - waiting: Set(ResultStage 7)
2016-10-12 19:05:31 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 19:05:31 INFO  DAGScheduler:54 - Submitting ResultStage 7 (ShuffledRDD[17] at reduceByKey at a1.scala:41), which has no missing parents
2016-10-12 19:05:31 INFO  MemoryStore:54 - Block broadcast_8 stored as values in memory (estimated size 3.1 KB, free 365.9 MB)
2016-10-12 19:05:31 INFO  MemoryStore:54 - Block broadcast_8_piece0 stored as bytes in memory (estimated size 1923.0 B, free 365.9 MB)
2016-10-12 19:05:31 INFO  BlockManagerInfo:54 - Added broadcast_8_piece0 in memory on 150.212.30.95:44347 (size: 1923.0 B, free: 366.3 MB)
2016-10-12 19:05:31 INFO  SparkContext:54 - Created broadcast 8 from broadcast at DAGScheduler.scala:1012
2016-10-12 19:05:31 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 7 (ShuffledRDD[17] at reduceByKey at a1.scala:41)
2016-10-12 19:05:31 INFO  TaskSchedulerImpl:54 - Adding task set 7.0 with 1 tasks
2016-10-12 19:05:31 INFO  TaskSetManager:54 - Starting task 0.0 in stage 7.0 (TID 7, localhost, partition 0, ANY, 5259 bytes)
2016-10-12 19:05:31 INFO  Executor:54 - Running task 0.0 in stage 7.0 (TID 7)
2016-10-12 19:05:31 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 19:05:31 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 2 ms
2016-10-12 19:05:31 INFO  Executor:54 - Finished task 0.0 in stage 7.0 (TID 7). 2081 bytes result sent to driver
2016-10-12 19:05:31 INFO  DAGScheduler:54 - ResultStage 7 (take at a1.scala:43) finished in 0.081 s
2016-10-12 19:05:31 INFO  DAGScheduler:54 - Job 3 finished: take at a1.scala:43, took 4.507926 s
2016-10-12 19:05:31 INFO  TaskSetManager:54 - Finished task 0.0 in stage 7.0 (TID 7) in 80 ms on localhost (1/1)
2016-10-12 19:05:31 INFO  TaskSchedulerImpl:54 - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2016-10-12 19:05:31 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2016-10-12 19:05:31 INFO  ServerConnector:306 - Stopped ServerConnector@6c67e137{HTTP/1.1}{0.0.0.0:4041}
2016-10-12 19:05:31 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,UNAVAILABLE}
2016-10-12 19:05:31 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@62e70ea3{/api,null,UNAVAILABLE}
2016-10-12 19:05:31 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@28276e50{/,null,UNAVAILABLE}
2016-10-12 19:05:31 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a7471ce{/static,null,UNAVAILABLE}
2016-10-12 19:05:31 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,UNAVAILABLE}
2016-10-12 19:05:31 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,UNAVAILABLE}
2016-10-12 19:05:31 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,UNAVAILABLE}
2016-10-12 19:05:31 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@297ea53a{/executors,null,UNAVAILABLE}
2016-10-12 19:05:31 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,UNAVAILABLE}
2016-10-12 19:05:31 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4052274f{/environment,null,UNAVAILABLE}
2016-10-12 19:05:31 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,UNAVAILABLE}
2016-10-12 19:05:31 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,UNAVAILABLE}
2016-10-12 19:05:31 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,UNAVAILABLE}
2016-10-12 19:05:31 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1643d68f{/storage,null,UNAVAILABLE}
2016-10-12 19:05:31 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,UNAVAILABLE}
2016-10-12 19:05:31 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,UNAVAILABLE}
2016-10-12 19:05:31 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,UNAVAILABLE}
2016-10-12 19:05:31 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,UNAVAILABLE}
2016-10-12 19:05:31 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,UNAVAILABLE}
2016-10-12 19:05:31 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,UNAVAILABLE}
2016-10-12 19:05:31 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,UNAVAILABLE}
2016-10-12 19:05:31 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,UNAVAILABLE}
2016-10-12 19:05:31 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,UNAVAILABLE}
2016-10-12 19:05:31 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,UNAVAILABLE}
2016-10-12 19:05:31 INFO  SparkUI:54 - Stopped Spark web UI at http://150.212.30.95:4041
2016-10-12 19:05:32 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2016-10-12 19:05:32 INFO  MemoryStore:54 - MemoryStore cleared
2016-10-12 19:05:32 INFO  BlockManager:54 - BlockManager stopped
2016-10-12 19:05:32 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2016-10-12 19:05:32 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2016-10-12 19:05:32 INFO  SparkContext:54 - Successfully stopped SparkContext
2016-10-12 19:05:32 INFO  ShutdownHookManager:54 - Shutdown hook called
2016-10-12 19:05:32 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-a9e4c00a-e651-4e9b-8985-e935ad7239aa
2016-10-12 19:06:25 INFO  SparkContext:54 - Running Spark version 2.0.0
2016-10-12 19:06:26 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-12 19:06:26 WARN  Utils:66 - Your hostname, aadu-XPS-13-9350 resolves to a loopback address: 127.0.1.1; using 150.212.30.95 instead (on interface wlp58s0)
2016-10-12 19:06:26 WARN  Utils:66 - Set SPARK_LOCAL_IP if you need to bind to another address
2016-10-12 19:06:26 INFO  SecurityManager:54 - Changing view acls to: aadu
2016-10-12 19:06:26 INFO  SecurityManager:54 - Changing modify acls to: aadu
2016-10-12 19:06:26 INFO  SecurityManager:54 - Changing view acls groups to: 
2016-10-12 19:06:26 INFO  SecurityManager:54 - Changing modify acls groups to: 
2016-10-12 19:06:26 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(aadu); groups with view permissions: Set(); users  with modify permissions: Set(aadu); groups with modify permissions: Set()
2016-10-12 19:06:26 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 42560.
2016-10-12 19:06:26 INFO  SparkEnv:54 - Registering MapOutputTracker
2016-10-12 19:06:26 INFO  SparkEnv:54 - Registering BlockManagerMaster
2016-10-12 19:06:26 INFO  DiskBlockManager:54 - Created local directory at /tmp/blockmgr-06067319-26f1-4ab6-af6b-ac9ad2243bf7
2016-10-12 19:06:26 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2016-10-12 19:06:26 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2016-10-12 19:06:26 INFO  log:186 - Logging initialized @1469ms
2016-10-12 19:06:26 INFO  Server:327 - jetty-9.2.z-SNAPSHOT
2016-10-12 19:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,AVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,AVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,AVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,AVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,AVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,AVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,AVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,AVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,AVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,AVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1643d68f{/storage,null,AVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,AVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,AVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,AVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4052274f{/environment,null,AVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,AVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@297ea53a{/executors,null,AVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,AVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,AVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,AVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a7471ce{/static,null,AVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@28276e50{/,null,AVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@62e70ea3{/api,null,AVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,AVAILABLE}
2016-10-12 19:06:26 WARN  AbstractLifeCycle:212 - FAILED ServerConnector@4fe89c24{HTTP/1.1}{0.0.0.0:4040}: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2071)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2062)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:139)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:451)
	at Assign1$.main(a1.scala:19)
	at Assign1.main(a1.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2016-10-12 19:06:26 WARN  AbstractLifeCycle:212 - FAILED org.spark_project.jetty.server.Server@6175619b: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2071)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2062)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:139)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:451)
	at Assign1$.main(a1.scala:19)
	at Assign1.main(a1.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2016-10-12 19:06:26 INFO  ServerConnector:306 - Stopped ServerConnector@4fe89c24{HTTP/1.1}{0.0.0.0:4040}
2016-10-12 19:06:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,UNAVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@62e70ea3{/api,null,UNAVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@28276e50{/,null,UNAVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a7471ce{/static,null,UNAVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,UNAVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,UNAVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,UNAVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@297ea53a{/executors,null,UNAVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,UNAVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4052274f{/environment,null,UNAVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,UNAVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,UNAVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,UNAVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1643d68f{/storage,null,UNAVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,UNAVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,UNAVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,UNAVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,UNAVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,UNAVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,UNAVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,UNAVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,UNAVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,UNAVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,UNAVAILABLE}
2016-10-12 19:06:26 WARN  Utils:66 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2016-10-12 19:06:26 INFO  Server:327 - jetty-9.2.z-SNAPSHOT
2016-10-12 19:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,AVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,AVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,AVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,AVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,AVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,AVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,AVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,AVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,AVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,AVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1643d68f{/storage,null,AVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,AVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,AVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,AVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4052274f{/environment,null,AVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,AVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@297ea53a{/executors,null,AVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,AVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,AVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,AVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a7471ce{/static,null,AVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@28276e50{/,null,AVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@62e70ea3{/api,null,AVAILABLE}
2016-10-12 19:06:26 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,AVAILABLE}
2016-10-12 19:06:26 INFO  ServerConnector:266 - Started ServerConnector@6c67e137{HTTP/1.1}{0.0.0.0:4041}
2016-10-12 19:06:26 INFO  Server:379 - Started @1636ms
2016-10-12 19:06:26 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4041.
2016-10-12 19:06:26 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://150.212.30.95:4041
2016-10-12 19:06:26 INFO  SparkContext:54 - Added JAR file:/home/aadu/Repos/adam/adam-assembly/target/adam_2.11-0.19.1-SNAPSHOT.jar at spark://150.212.30.95:42560/jars/adam_2.11-0.19.1-SNAPSHOT.jar with timestamp 1476313586873
2016-10-12 19:06:26 INFO  SparkContext:54 - Added JAR file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/a1.jar at spark://150.212.30.95:42560/jars/a1.jar with timestamp 1476313586874
2016-10-12 19:06:26 INFO  Executor:54 - Starting executor ID driver on host localhost
2016-10-12 19:06:26 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40276.
2016-10-12 19:06:26 INFO  NettyBlockTransferService:54 - Server created on 150.212.30.95:40276
2016-10-12 19:06:26 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 150.212.30.95, 40276)
2016-10-12 19:06:26 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 150.212.30.95:40276 with 366.3 MB RAM, BlockManagerId(driver, 150.212.30.95, 40276)
2016-10-12 19:06:26 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 150.212.30.95, 40276)
2016-10-12 19:06:27 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2472c7d8{/metrics/json,null,AVAILABLE}
2016-10-12 19:06:27 INFO  ADAMContext:1336 - Loading small.adam as Parquet containing Genotypes. Sequence dictionary for translation is ignored.
2016-10-12 19:06:27 INFO  ADAMContext:257 - Reading the ADAM file at small.adam to create RDD
2016-10-12 19:06:27 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 268.7 KB, free 366.0 MB)
2016-10-12 19:06:28 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 22.8 KB, free 366.0 MB)
2016-10-12 19:06:28 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 150.212.30.95:40276 (size: 22.8 KB, free: 366.3 MB)
2016-10-12 19:06:28 INFO  SparkContext:54 - Created broadcast 0 from newAPIHadoopFile at ADAMContext.scala:271
2016-10-12 19:06:28 INFO  FileInputFormat:283 - Total input paths to process : 1
2016-10-12 19:06:28 INFO  SparkContext:54 - Starting job: count at a1.scala:32
2016-10-12 19:06:28 INFO  DAGScheduler:54 - Registering RDD 3 (distinct at a1.scala:32)
2016-10-12 19:06:28 INFO  DAGScheduler:54 - Got job 0 (count at a1.scala:32) with 1 output partitions
2016-10-12 19:06:28 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (count at a1.scala:32)
2016-10-12 19:06:28 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 0)
2016-10-12 19:06:28 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 0)
2016-10-12 19:06:28 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at distinct at a1.scala:32), which has no missing parents
2016-10-12 19:06:28 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 4.2 KB, free 366.0 MB)
2016-10-12 19:06:28 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.5 KB, free 366.0 MB)
2016-10-12 19:06:28 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 150.212.30.95:40276 (size: 2.5 KB, free: 366.3 MB)
2016-10-12 19:06:28 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1012
2016-10-12 19:06:28 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at distinct at a1.scala:32)
2016-10-12 19:06:28 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2016-10-12 19:06:28 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5507 bytes)
2016-10-12 19:06:28 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2016-10-12 19:06:28 INFO  Executor:54 - Fetching spark://150.212.30.95:42560/jars/adam_2.11-0.19.1-SNAPSHOT.jar with timestamp 1476313586873
2016-10-12 19:06:28 INFO  TransportClientFactory:250 - Successfully created connection to /150.212.30.95:42560 after 35 ms (0 ms spent in bootstraps)
2016-10-12 19:06:28 INFO  Utils:54 - Fetching spark://150.212.30.95:42560/jars/adam_2.11-0.19.1-SNAPSHOT.jar to /tmp/spark-7a9a3a90-976f-4ca7-ae16-d20ef9178255/userFiles-54feb42a-886f-495c-80e0-8ca620f954c7/fetchFileTemp8212298422068983054.tmp
2016-10-12 19:06:28 INFO  Executor:54 - Adding file:/tmp/spark-7a9a3a90-976f-4ca7-ae16-d20ef9178255/userFiles-54feb42a-886f-495c-80e0-8ca620f954c7/adam_2.11-0.19.1-SNAPSHOT.jar to class loader
2016-10-12 19:06:28 INFO  Executor:54 - Fetching spark://150.212.30.95:42560/jars/a1.jar with timestamp 1476313586874
2016-10-12 19:06:28 INFO  Utils:54 - Fetching spark://150.212.30.95:42560/jars/a1.jar to /tmp/spark-7a9a3a90-976f-4ca7-ae16-d20ef9178255/userFiles-54feb42a-886f-495c-80e0-8ca620f954c7/fetchFileTemp4073969481676398051.tmp
2016-10-12 19:06:28 INFO  Executor:54 - Adding file:/tmp/spark-7a9a3a90-976f-4ca7-ae16-d20ef9178255/userFiles-54feb42a-886f-495c-80e0-8ca620f954c7/a1.jar to class loader
2016-10-12 19:06:29 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 19:06:29 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 19:06:33 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1490 bytes result sent to driver
2016-10-12 19:06:33 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 4554 ms on localhost (1/1)
2016-10-12 19:06:33 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2016-10-12 19:06:33 INFO  DAGScheduler:54 - ShuffleMapStage 0 (distinct at a1.scala:32) finished in 4.568 s
2016-10-12 19:06:33 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 19:06:33 INFO  DAGScheduler:54 - running: Set()
2016-10-12 19:06:33 INFO  DAGScheduler:54 - waiting: Set(ResultStage 1)
2016-10-12 19:06:33 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 19:06:33 INFO  DAGScheduler:54 - Submitting ResultStage 1 (MapPartitionsRDD[5] at distinct at a1.scala:32), which has no missing parents
2016-10-12 19:06:33 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 3.7 KB, free 366.0 MB)
2016-10-12 19:06:33 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.2 KB, free 366.0 MB)
2016-10-12 19:06:33 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on 150.212.30.95:40276 (size: 2.2 KB, free: 366.3 MB)
2016-10-12 19:06:33 INFO  SparkContext:54 - Created broadcast 2 from broadcast at DAGScheduler.scala:1012
2016-10-12 19:06:33 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at distinct at a1.scala:32)
2016-10-12 19:06:33 INFO  TaskSchedulerImpl:54 - Adding task set 1.0 with 1 tasks
2016-10-12 19:06:33 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, ANY, 5177 bytes)
2016-10-12 19:06:33 INFO  Executor:54 - Running task 0.0 in stage 1.0 (TID 1)
2016-10-12 19:06:33 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 19:06:33 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 3 ms
2016-10-12 19:06:33 INFO  Executor:54 - Finished task 0.0 in stage 1.0 (TID 1). 1512 bytes result sent to driver
2016-10-12 19:06:33 INFO  DAGScheduler:54 - ResultStage 1 (count at a1.scala:32) finished in 0.095 s
2016-10-12 19:06:33 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 1) in 95 ms on localhost (1/1)
2016-10-12 19:06:33 INFO  TaskSchedulerImpl:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2016-10-12 19:06:33 INFO  DAGScheduler:54 - Job 0 finished: count at a1.scala:32, took 4.861454 s
2016-10-12 19:06:33 INFO  SparkContext:54 - Starting job: count at a1.scala:33
2016-10-12 19:06:33 INFO  DAGScheduler:54 - Registering RDD 7 (distinct at a1.scala:33)
2016-10-12 19:06:33 INFO  DAGScheduler:54 - Got job 1 (count at a1.scala:33) with 1 output partitions
2016-10-12 19:06:33 INFO  DAGScheduler:54 - Final stage: ResultStage 3 (count at a1.scala:33)
2016-10-12 19:06:33 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 2)
2016-10-12 19:06:33 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 2)
2016-10-12 19:06:33 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 2 (MapPartitionsRDD[7] at distinct at a1.scala:33), which has no missing parents
2016-10-12 19:06:33 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 4.2 KB, free 366.0 MB)
2016-10-12 19:06:33 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.5 KB, free 366.0 MB)
2016-10-12 19:06:33 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on 150.212.30.95:40276 (size: 2.5 KB, free: 366.3 MB)
2016-10-12 19:06:33 INFO  SparkContext:54 - Created broadcast 3 from broadcast at DAGScheduler.scala:1012
2016-10-12 19:06:33 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[7] at distinct at a1.scala:33)
2016-10-12 19:06:33 INFO  TaskSchedulerImpl:54 - Adding task set 2.0 with 1 tasks
2016-10-12 19:06:33 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5507 bytes)
2016-10-12 19:06:33 INFO  Executor:54 - Running task 0.0 in stage 2.0 (TID 2)
2016-10-12 19:06:33 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 19:06:33 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 19:06:33 INFO  ContextCleaner:54 - Cleaned shuffle 0
2016-10-12 19:06:33 INFO  BlockManagerInfo:54 - Removed broadcast_1_piece0 on 150.212.30.95:40276 in memory (size: 2.5 KB, free: 366.3 MB)
2016-10-12 19:06:33 INFO  BlockManagerInfo:54 - Removed broadcast_2_piece0 on 150.212.30.95:40276 in memory (size: 2.2 KB, free: 366.3 MB)
2016-10-12 19:06:37 INFO  Executor:54 - Finished task 0.0 in stage 2.0 (TID 2). 1490 bytes result sent to driver
2016-10-12 19:06:37 INFO  DAGScheduler:54 - ShuffleMapStage 2 (distinct at a1.scala:33) finished in 3.860 s
2016-10-12 19:06:37 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 19:06:37 INFO  DAGScheduler:54 - running: Set()
2016-10-12 19:06:37 INFO  DAGScheduler:54 - waiting: Set(ResultStage 3)
2016-10-12 19:06:37 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 19:06:37 INFO  DAGScheduler:54 - Submitting ResultStage 3 (MapPartitionsRDD[9] at distinct at a1.scala:33), which has no missing parents
2016-10-12 19:06:37 INFO  TaskSetManager:54 - Finished task 0.0 in stage 2.0 (TID 2) in 3860 ms on localhost (1/1)
2016-10-12 19:06:37 INFO  TaskSchedulerImpl:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2016-10-12 19:06:37 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 3.8 KB, free 366.0 MB)
2016-10-12 19:06:37 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.2 KB, free 366.0 MB)
2016-10-12 19:06:37 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on 150.212.30.95:40276 (size: 2.2 KB, free: 366.3 MB)
2016-10-12 19:06:37 INFO  SparkContext:54 - Created broadcast 4 from broadcast at DAGScheduler.scala:1012
2016-10-12 19:06:37 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[9] at distinct at a1.scala:33)
2016-10-12 19:06:37 INFO  TaskSchedulerImpl:54 - Adding task set 3.0 with 1 tasks
2016-10-12 19:06:37 INFO  TaskSetManager:54 - Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, ANY, 5177 bytes)
2016-10-12 19:06:37 INFO  Executor:54 - Running task 0.0 in stage 3.0 (TID 3)
2016-10-12 19:06:37 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 19:06:37 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 2 ms
2016-10-12 19:06:37 INFO  Executor:54 - Finished task 0.0 in stage 3.0 (TID 3). 1512 bytes result sent to driver
2016-10-12 19:06:37 INFO  DAGScheduler:54 - ResultStage 3 (count at a1.scala:33) finished in 0.049 s
2016-10-12 19:06:37 INFO  DAGScheduler:54 - Job 1 finished: count at a1.scala:33, took 3.969617 s
2016-10-12 19:06:37 INFO  TaskSetManager:54 - Finished task 0.0 in stage 3.0 (TID 3) in 47 ms on localhost (1/1)
2016-10-12 19:06:37 INFO  TaskSchedulerImpl:54 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2016-10-12 19:06:37 INFO  SparkContext:54 - Starting job: collect at a1.scala:34
2016-10-12 19:06:37 INFO  DAGScheduler:54 - Registering RDD 10 (map at a1.scala:34)
2016-10-12 19:06:37 INFO  DAGScheduler:54 - Got job 2 (collect at a1.scala:34) with 1 output partitions
2016-10-12 19:06:37 INFO  DAGScheduler:54 - Final stage: ResultStage 5 (collect at a1.scala:34)
2016-10-12 19:06:37 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 4)
2016-10-12 19:06:37 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 4)
2016-10-12 19:06:37 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 4 (MapPartitionsRDD[10] at map at a1.scala:34), which has no missing parents
2016-10-12 19:06:37 INFO  MemoryStore:54 - Block broadcast_5 stored as values in memory (estimated size 4.0 KB, free 366.0 MB)
2016-10-12 19:06:37 INFO  MemoryStore:54 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.4 KB, free 366.0 MB)
2016-10-12 19:06:37 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on 150.212.30.95:40276 (size: 2.4 KB, free: 366.3 MB)
2016-10-12 19:06:37 INFO  SparkContext:54 - Created broadcast 5 from broadcast at DAGScheduler.scala:1012
2016-10-12 19:06:37 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[10] at map at a1.scala:34)
2016-10-12 19:06:37 INFO  TaskSchedulerImpl:54 - Adding task set 4.0 with 1 tasks
2016-10-12 19:06:37 INFO  TaskSetManager:54 - Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5592 bytes)
2016-10-12 19:06:37 INFO  Executor:54 - Running task 0.0 in stage 4.0 (TID 4)
2016-10-12 19:06:37 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 19:06:37 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 19:06:37 INFO  ContextCleaner:54 - Cleaned shuffle 1
2016-10-12 19:06:37 INFO  BlockManagerInfo:54 - Removed broadcast_3_piece0 on 150.212.30.95:40276 in memory (size: 2.5 KB, free: 366.3 MB)
2016-10-12 19:06:37 INFO  BlockManagerInfo:54 - Removed broadcast_4_piece0 on 150.212.30.95:40276 in memory (size: 2.2 KB, free: 366.3 MB)
2016-10-12 19:06:40 INFO  Executor:54 - Finished task 0.0 in stage 4.0 (TID 4). 1490 bytes result sent to driver
2016-10-12 19:06:40 INFO  TaskSetManager:54 - Finished task 0.0 in stage 4.0 (TID 4) in 3394 ms on localhost (1/1)
2016-10-12 19:06:40 INFO  DAGScheduler:54 - ShuffleMapStage 4 (map at a1.scala:34) finished in 3.393 s
2016-10-12 19:06:40 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 19:06:40 INFO  DAGScheduler:54 - running: Set()
2016-10-12 19:06:40 INFO  DAGScheduler:54 - waiting: Set(ResultStage 5)
2016-10-12 19:06:40 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 19:06:40 INFO  TaskSchedulerImpl:54 - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2016-10-12 19:06:40 INFO  DAGScheduler:54 - Submitting ResultStage 5 (MapPartitionsRDD[13] at map at a1.scala:34), which has no missing parents
2016-10-12 19:06:40 INFO  MemoryStore:54 - Block broadcast_6 stored as values in memory (estimated size 3.8 KB, free 366.0 MB)
2016-10-12 19:06:40 INFO  MemoryStore:54 - Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.2 KB, free 366.0 MB)
2016-10-12 19:06:40 INFO  BlockManagerInfo:54 - Added broadcast_6_piece0 in memory on 150.212.30.95:40276 (size: 2.2 KB, free: 366.3 MB)
2016-10-12 19:06:40 INFO  SparkContext:54 - Created broadcast 6 from broadcast at DAGScheduler.scala:1012
2016-10-12 19:06:40 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[13] at map at a1.scala:34)
2016-10-12 19:06:40 INFO  TaskSchedulerImpl:54 - Adding task set 5.0 with 1 tasks
2016-10-12 19:06:40 INFO  TaskSetManager:54 - Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, ANY, 5262 bytes)
2016-10-12 19:06:40 INFO  Executor:54 - Running task 0.0 in stage 5.0 (TID 5)
2016-10-12 19:06:40 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 19:06:40 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2016-10-12 19:06:40 INFO  Executor:54 - Finished task 0.0 in stage 5.0 (TID 5). 9861 bytes result sent to driver
2016-10-12 19:06:40 INFO  TaskSetManager:54 - Finished task 0.0 in stage 5.0 (TID 5) in 60 ms on localhost (1/1)
2016-10-12 19:06:40 INFO  DAGScheduler:54 - ResultStage 5 (collect at a1.scala:34) finished in 0.059 s
2016-10-12 19:06:40 INFO  DAGScheduler:54 - Job 2 finished: collect at a1.scala:34, took 3.499415 s
2016-10-12 19:06:40 INFO  TaskSchedulerImpl:54 - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2016-10-12 19:06:40 INFO  SparkContext:54 - Starting job: take at a1.scala:43
2016-10-12 19:06:40 INFO  DAGScheduler:54 - Registering RDD 16 (map at a1.scala:41)
2016-10-12 19:06:40 INFO  DAGScheduler:54 - Got job 3 (take at a1.scala:43) with 1 output partitions
2016-10-12 19:06:40 INFO  DAGScheduler:54 - Final stage: ResultStage 7 (take at a1.scala:43)
2016-10-12 19:06:40 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 6)
2016-10-12 19:06:40 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 6)
2016-10-12 19:06:40 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 6 (MapPartitionsRDD[16] at map at a1.scala:41), which has no missing parents
2016-10-12 19:06:40 INFO  MemoryStore:54 - Block broadcast_7 stored as values in memory (estimated size 45.6 KB, free 366.0 MB)
2016-10-12 19:06:40 INFO  MemoryStore:54 - Block broadcast_7_piece0 stored as bytes in memory (estimated size 21.5 KB, free 365.9 MB)
2016-10-12 19:06:40 INFO  BlockManagerInfo:54 - Added broadcast_7_piece0 in memory on 150.212.30.95:40276 (size: 21.5 KB, free: 366.3 MB)
2016-10-12 19:06:40 INFO  SparkContext:54 - Created broadcast 7 from broadcast at DAGScheduler.scala:1012
2016-10-12 19:06:40 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[16] at map at a1.scala:41)
2016-10-12 19:06:40 INFO  TaskSchedulerImpl:54 - Adding task set 6.0 with 1 tasks
2016-10-12 19:06:40 INFO  TaskSetManager:54 - Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, PROCESS_LOCAL, 5589 bytes)
2016-10-12 19:06:40 INFO  Executor:54 - Running task 0.0 in stage 6.0 (TID 6)
2016-10-12 19:06:40 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 19:06:40 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 19:06:41 INFO  BlockManagerInfo:54 - Removed broadcast_5_piece0 on 150.212.30.95:40276 in memory (size: 2.4 KB, free: 366.3 MB)
2016-10-12 19:06:41 INFO  BlockManagerInfo:54 - Removed broadcast_6_piece0 on 150.212.30.95:40276 in memory (size: 2.2 KB, free: 366.3 MB)
2016-10-12 19:06:41 INFO  ContextCleaner:54 - Cleaned shuffle 2
2016-10-12 19:06:45 INFO  Executor:54 - Finished task 0.0 in stage 6.0 (TID 6). 1490 bytes result sent to driver
2016-10-12 19:06:45 INFO  TaskSetManager:54 - Finished task 0.0 in stage 6.0 (TID 6) in 4710 ms on localhost (1/1)
2016-10-12 19:06:45 INFO  DAGScheduler:54 - ShuffleMapStage 6 (map at a1.scala:41) finished in 4.709 s
2016-10-12 19:06:45 INFO  TaskSchedulerImpl:54 - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2016-10-12 19:06:45 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 19:06:45 INFO  DAGScheduler:54 - running: Set()
2016-10-12 19:06:45 INFO  DAGScheduler:54 - waiting: Set(ResultStage 7)
2016-10-12 19:06:45 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 19:06:45 INFO  DAGScheduler:54 - Submitting ResultStage 7 (ShuffledRDD[17] at reduceByKey at a1.scala:41), which has no missing parents
2016-10-12 19:06:45 INFO  MemoryStore:54 - Block broadcast_8 stored as values in memory (estimated size 3.1 KB, free 365.9 MB)
2016-10-12 19:06:45 INFO  MemoryStore:54 - Block broadcast_8_piece0 stored as bytes in memory (estimated size 1923.0 B, free 365.9 MB)
2016-10-12 19:06:45 INFO  BlockManagerInfo:54 - Added broadcast_8_piece0 in memory on 150.212.30.95:40276 (size: 1923.0 B, free: 366.3 MB)
2016-10-12 19:06:45 INFO  SparkContext:54 - Created broadcast 8 from broadcast at DAGScheduler.scala:1012
2016-10-12 19:06:45 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 7 (ShuffledRDD[17] at reduceByKey at a1.scala:41)
2016-10-12 19:06:45 INFO  TaskSchedulerImpl:54 - Adding task set 7.0 with 1 tasks
2016-10-12 19:06:45 INFO  TaskSetManager:54 - Starting task 0.0 in stage 7.0 (TID 7, localhost, partition 0, ANY, 5259 bytes)
2016-10-12 19:06:45 INFO  Executor:54 - Running task 0.0 in stage 7.0 (TID 7)
2016-10-12 19:06:45 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 19:06:45 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2016-10-12 19:06:45 INFO  Executor:54 - Finished task 0.0 in stage 7.0 (TID 7). 2081 bytes result sent to driver
2016-10-12 19:06:45 INFO  TaskSetManager:54 - Finished task 0.0 in stage 7.0 (TID 7) in 79 ms on localhost (1/1)
2016-10-12 19:06:45 INFO  TaskSchedulerImpl:54 - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2016-10-12 19:06:45 INFO  DAGScheduler:54 - ResultStage 7 (take at a1.scala:43) finished in 0.079 s
2016-10-12 19:06:45 INFO  DAGScheduler:54 - Job 3 finished: take at a1.scala:43, took 4.846263 s
2016-10-12 19:06:45 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2016-10-12 19:06:45 INFO  ServerConnector:306 - Stopped ServerConnector@6c67e137{HTTP/1.1}{0.0.0.0:4041}
2016-10-12 19:06:45 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,UNAVAILABLE}
2016-10-12 19:06:45 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@62e70ea3{/api,null,UNAVAILABLE}
2016-10-12 19:06:45 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@28276e50{/,null,UNAVAILABLE}
2016-10-12 19:06:45 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a7471ce{/static,null,UNAVAILABLE}
2016-10-12 19:06:45 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,UNAVAILABLE}
2016-10-12 19:06:45 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,UNAVAILABLE}
2016-10-12 19:06:45 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,UNAVAILABLE}
2016-10-12 19:06:45 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@297ea53a{/executors,null,UNAVAILABLE}
2016-10-12 19:06:45 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,UNAVAILABLE}
2016-10-12 19:06:45 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4052274f{/environment,null,UNAVAILABLE}
2016-10-12 19:06:45 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,UNAVAILABLE}
2016-10-12 19:06:45 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,UNAVAILABLE}
2016-10-12 19:06:45 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,UNAVAILABLE}
2016-10-12 19:06:45 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1643d68f{/storage,null,UNAVAILABLE}
2016-10-12 19:06:45 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,UNAVAILABLE}
2016-10-12 19:06:45 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,UNAVAILABLE}
2016-10-12 19:06:45 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,UNAVAILABLE}
2016-10-12 19:06:45 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,UNAVAILABLE}
2016-10-12 19:06:45 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,UNAVAILABLE}
2016-10-12 19:06:45 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,UNAVAILABLE}
2016-10-12 19:06:45 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,UNAVAILABLE}
2016-10-12 19:06:45 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,UNAVAILABLE}
2016-10-12 19:06:45 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,UNAVAILABLE}
2016-10-12 19:06:45 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,UNAVAILABLE}
2016-10-12 19:06:45 INFO  SparkUI:54 - Stopped Spark web UI at http://150.212.30.95:4041
2016-10-12 19:06:45 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2016-10-12 19:06:45 INFO  MemoryStore:54 - MemoryStore cleared
2016-10-12 19:06:45 INFO  BlockManager:54 - BlockManager stopped
2016-10-12 19:06:45 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2016-10-12 19:06:45 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2016-10-12 19:06:45 INFO  SparkContext:54 - Successfully stopped SparkContext
2016-10-12 19:06:45 INFO  ShutdownHookManager:54 - Shutdown hook called
2016-10-12 19:06:45 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-7a9a3a90-976f-4ca7-ae16-d20ef9178255
2016-10-12 21:22:22 INFO  SparkContext:54 - Running Spark version 2.0.0
2016-10-12 21:22:22 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-12 21:22:22 WARN  Utils:66 - Your hostname, aadu-XPS-13-9350 resolves to a loopback address: 127.0.1.1; using 150.212.30.95 instead (on interface wlp58s0)
2016-10-12 21:22:22 WARN  Utils:66 - Set SPARK_LOCAL_IP if you need to bind to another address
2016-10-12 21:22:22 INFO  SecurityManager:54 - Changing view acls to: aadu
2016-10-12 21:22:22 INFO  SecurityManager:54 - Changing modify acls to: aadu
2016-10-12 21:22:22 INFO  SecurityManager:54 - Changing view acls groups to: 
2016-10-12 21:22:22 INFO  SecurityManager:54 - Changing modify acls groups to: 
2016-10-12 21:22:22 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(aadu); groups with view permissions: Set(); users  with modify permissions: Set(aadu); groups with modify permissions: Set()
2016-10-12 21:22:23 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 42520.
2016-10-12 21:22:23 INFO  SparkEnv:54 - Registering MapOutputTracker
2016-10-12 21:22:23 INFO  SparkEnv:54 - Registering BlockManagerMaster
2016-10-12 21:22:23 INFO  DiskBlockManager:54 - Created local directory at /tmp/blockmgr-dc5983a5-cb12-4e01-9b38-4a91b6e456f9
2016-10-12 21:22:23 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2016-10-12 21:22:23 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2016-10-12 21:22:23 INFO  log:186 - Logging initialized @1413ms
2016-10-12 21:22:23 INFO  Server:327 - jetty-9.2.z-SNAPSHOT
2016-10-12 21:22:23 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,AVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,AVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,AVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,AVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,AVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,AVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,AVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,AVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,AVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,AVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1643d68f{/storage,null,AVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,AVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,AVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,AVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4052274f{/environment,null,AVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,AVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@297ea53a{/executors,null,AVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,AVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,AVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,AVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a7471ce{/static,null,AVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@28276e50{/,null,AVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@62e70ea3{/api,null,AVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,AVAILABLE}
2016-10-12 21:22:23 WARN  AbstractLifeCycle:212 - FAILED ServerConnector@4fe89c24{HTTP/1.1}{0.0.0.0:4040}: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2071)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2062)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:139)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:451)
	at Assign1$.main(a1.scala:20)
	at Assign1.main(a1.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2016-10-12 21:22:23 WARN  AbstractLifeCycle:212 - FAILED org.spark_project.jetty.server.Server@6175619b: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2071)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2062)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:139)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:451)
	at Assign1$.main(a1.scala:20)
	at Assign1.main(a1.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2016-10-12 21:22:23 INFO  ServerConnector:306 - Stopped ServerConnector@4fe89c24{HTTP/1.1}{0.0.0.0:4040}
2016-10-12 21:22:23 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,UNAVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@62e70ea3{/api,null,UNAVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@28276e50{/,null,UNAVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a7471ce{/static,null,UNAVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,UNAVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,UNAVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,UNAVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@297ea53a{/executors,null,UNAVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,UNAVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4052274f{/environment,null,UNAVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,UNAVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,UNAVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,UNAVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1643d68f{/storage,null,UNAVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,UNAVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,UNAVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,UNAVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,UNAVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,UNAVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,UNAVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,UNAVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,UNAVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,UNAVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,UNAVAILABLE}
2016-10-12 21:22:23 WARN  Utils:66 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2016-10-12 21:22:23 INFO  Server:327 - jetty-9.2.z-SNAPSHOT
2016-10-12 21:22:23 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,AVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,AVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,AVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,AVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,AVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,AVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,AVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,AVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,AVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,AVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1643d68f{/storage,null,AVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,AVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,AVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,AVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4052274f{/environment,null,AVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,AVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@297ea53a{/executors,null,AVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,AVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,AVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,AVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a7471ce{/static,null,AVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@28276e50{/,null,AVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@62e70ea3{/api,null,AVAILABLE}
2016-10-12 21:22:23 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,AVAILABLE}
2016-10-12 21:22:23 INFO  ServerConnector:266 - Started ServerConnector@6c67e137{HTTP/1.1}{0.0.0.0:4041}
2016-10-12 21:22:23 INFO  Server:379 - Started @1564ms
2016-10-12 21:22:23 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4041.
2016-10-12 21:22:23 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://150.212.30.95:4041
2016-10-12 21:22:23 INFO  SparkContext:54 - Added JAR file:/home/aadu/Repos/adam/adam-assembly/target/adam_2.11-0.19.1-SNAPSHOT.jar at spark://150.212.30.95:42520/jars/adam_2.11-0.19.1-SNAPSHOT.jar with timestamp 1476321743384
2016-10-12 21:22:23 INFO  SparkContext:54 - Added JAR file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/a1.jar at spark://150.212.30.95:42520/jars/a1.jar with timestamp 1476321743386
2016-10-12 21:22:23 INFO  Executor:54 - Starting executor ID driver on host localhost
2016-10-12 21:22:23 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37346.
2016-10-12 21:22:23 INFO  NettyBlockTransferService:54 - Server created on 150.212.30.95:37346
2016-10-12 21:22:23 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 150.212.30.95, 37346)
2016-10-12 21:22:23 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 150.212.30.95:37346 with 366.3 MB RAM, BlockManagerId(driver, 150.212.30.95, 37346)
2016-10-12 21:22:23 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 150.212.30.95, 37346)
2016-10-12 21:22:23 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2472c7d8{/metrics/json,null,AVAILABLE}
2016-10-12 21:22:23 INFO  ADAMContext:1336 - Loading small.adam as Parquet containing Genotypes. Sequence dictionary for translation is ignored.
2016-10-12 21:22:23 INFO  ADAMContext:257 - Reading the ADAM file at small.adam to create RDD
2016-10-12 21:22:24 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 268.7 KB, free 366.0 MB)
2016-10-12 21:22:24 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 22.8 KB, free 366.0 MB)
2016-10-12 21:22:24 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 150.212.30.95:37346 (size: 22.8 KB, free: 366.3 MB)
2016-10-12 21:22:24 INFO  SparkContext:54 - Created broadcast 0 from newAPIHadoopFile at ADAMContext.scala:271
2016-10-12 21:22:24 INFO  FileInputFormat:283 - Total input paths to process : 1
2016-10-12 21:22:25 INFO  SparkContext:54 - Starting job: count at a1.scala:33
2016-10-12 21:22:25 INFO  DAGScheduler:54 - Registering RDD 3 (distinct at a1.scala:33)
2016-10-12 21:22:25 INFO  DAGScheduler:54 - Got job 0 (count at a1.scala:33) with 1 output partitions
2016-10-12 21:22:25 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (count at a1.scala:33)
2016-10-12 21:22:25 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 0)
2016-10-12 21:22:25 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 0)
2016-10-12 21:22:25 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at distinct at a1.scala:33), which has no missing parents
2016-10-12 21:22:25 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 4.2 KB, free 366.0 MB)
2016-10-12 21:22:25 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.5 KB, free 366.0 MB)
2016-10-12 21:22:25 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 150.212.30.95:37346 (size: 2.5 KB, free: 366.3 MB)
2016-10-12 21:22:25 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:22:25 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at distinct at a1.scala:33)
2016-10-12 21:22:25 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2016-10-12 21:22:25 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5507 bytes)
2016-10-12 21:22:25 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2016-10-12 21:22:25 INFO  Executor:54 - Fetching spark://150.212.30.95:42520/jars/a1.jar with timestamp 1476321743386
2016-10-12 21:22:25 INFO  TransportClientFactory:250 - Successfully created connection to /150.212.30.95:42520 after 28 ms (0 ms spent in bootstraps)
2016-10-12 21:22:25 INFO  Utils:54 - Fetching spark://150.212.30.95:42520/jars/a1.jar to /tmp/spark-8f91a2d5-915d-4ad4-8454-78198ef8acf9/userFiles-0382010a-3949-483b-9cde-a4c8473a9af3/fetchFileTemp7570613356063290179.tmp
2016-10-12 21:22:25 INFO  Executor:54 - Adding file:/tmp/spark-8f91a2d5-915d-4ad4-8454-78198ef8acf9/userFiles-0382010a-3949-483b-9cde-a4c8473a9af3/a1.jar to class loader
2016-10-12 21:22:25 INFO  Executor:54 - Fetching spark://150.212.30.95:42520/jars/adam_2.11-0.19.1-SNAPSHOT.jar with timestamp 1476321743384
2016-10-12 21:22:25 INFO  Utils:54 - Fetching spark://150.212.30.95:42520/jars/adam_2.11-0.19.1-SNAPSHOT.jar to /tmp/spark-8f91a2d5-915d-4ad4-8454-78198ef8acf9/userFiles-0382010a-3949-483b-9cde-a4c8473a9af3/fetchFileTemp1794113379040544033.tmp
2016-10-12 21:22:25 INFO  Executor:54 - Adding file:/tmp/spark-8f91a2d5-915d-4ad4-8454-78198ef8acf9/userFiles-0382010a-3949-483b-9cde-a4c8473a9af3/adam_2.11-0.19.1-SNAPSHOT.jar to class loader
2016-10-12 21:22:25 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 21:22:25 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 21:22:29 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1490 bytes result sent to driver
2016-10-12 21:22:29 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 4091 ms on localhost (1/1)
2016-10-12 21:22:29 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2016-10-12 21:22:29 INFO  DAGScheduler:54 - ShuffleMapStage 0 (distinct at a1.scala:33) finished in 4.106 s
2016-10-12 21:22:29 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 21:22:29 INFO  DAGScheduler:54 - running: Set()
2016-10-12 21:22:29 INFO  DAGScheduler:54 - waiting: Set(ResultStage 1)
2016-10-12 21:22:29 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 21:22:29 INFO  DAGScheduler:54 - Submitting ResultStage 1 (MapPartitionsRDD[5] at distinct at a1.scala:33), which has no missing parents
2016-10-12 21:22:29 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 3.7 KB, free 366.0 MB)
2016-10-12 21:22:29 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.2 KB, free 366.0 MB)
2016-10-12 21:22:29 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on 150.212.30.95:37346 (size: 2.2 KB, free: 366.3 MB)
2016-10-12 21:22:29 INFO  SparkContext:54 - Created broadcast 2 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:22:29 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at distinct at a1.scala:33)
2016-10-12 21:22:29 INFO  TaskSchedulerImpl:54 - Adding task set 1.0 with 1 tasks
2016-10-12 21:22:29 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, ANY, 5177 bytes)
2016-10-12 21:22:29 INFO  Executor:54 - Running task 0.0 in stage 1.0 (TID 1)
2016-10-12 21:22:29 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 21:22:29 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 5 ms
2016-10-12 21:22:29 INFO  Executor:54 - Finished task 0.0 in stage 1.0 (TID 1). 1512 bytes result sent to driver
2016-10-12 21:22:29 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 1) in 101 ms on localhost (1/1)
2016-10-12 21:22:29 INFO  DAGScheduler:54 - ResultStage 1 (count at a1.scala:33) finished in 0.101 s
2016-10-12 21:22:29 INFO  TaskSchedulerImpl:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2016-10-12 21:22:29 INFO  DAGScheduler:54 - Job 0 finished: count at a1.scala:33, took 4.376823 s
2016-10-12 21:22:29 INFO  SparkContext:54 - Starting job: count at a1.scala:34
2016-10-12 21:22:29 INFO  DAGScheduler:54 - Registering RDD 7 (distinct at a1.scala:34)
2016-10-12 21:22:29 INFO  DAGScheduler:54 - Got job 1 (count at a1.scala:34) with 1 output partitions
2016-10-12 21:22:29 INFO  DAGScheduler:54 - Final stage: ResultStage 3 (count at a1.scala:34)
2016-10-12 21:22:29 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 2)
2016-10-12 21:22:29 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 2)
2016-10-12 21:22:29 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 2 (MapPartitionsRDD[7] at distinct at a1.scala:34), which has no missing parents
2016-10-12 21:22:29 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 4.2 KB, free 366.0 MB)
2016-10-12 21:22:29 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.5 KB, free 366.0 MB)
2016-10-12 21:22:29 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on 150.212.30.95:37346 (size: 2.5 KB, free: 366.3 MB)
2016-10-12 21:22:29 INFO  SparkContext:54 - Created broadcast 3 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:22:29 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[7] at distinct at a1.scala:34)
2016-10-12 21:22:29 INFO  TaskSchedulerImpl:54 - Adding task set 2.0 with 1 tasks
2016-10-12 21:22:29 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5507 bytes)
2016-10-12 21:22:29 INFO  Executor:54 - Running task 0.0 in stage 2.0 (TID 2)
2016-10-12 21:22:29 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 21:22:29 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 21:22:29 INFO  BlockManagerInfo:54 - Removed broadcast_2_piece0 on 150.212.30.95:37346 in memory (size: 2.2 KB, free: 366.3 MB)
2016-10-12 21:22:29 INFO  ContextCleaner:54 - Cleaned shuffle 0
2016-10-12 21:22:29 INFO  BlockManagerInfo:54 - Removed broadcast_1_piece0 on 150.212.30.95:37346 in memory (size: 2.5 KB, free: 366.3 MB)
2016-10-12 21:22:32 INFO  Executor:54 - Finished task 0.0 in stage 2.0 (TID 2). 1490 bytes result sent to driver
2016-10-12 21:22:32 INFO  TaskSetManager:54 - Finished task 0.0 in stage 2.0 (TID 2) in 3550 ms on localhost (1/1)
2016-10-12 21:22:32 INFO  DAGScheduler:54 - ShuffleMapStage 2 (distinct at a1.scala:34) finished in 3.551 s
2016-10-12 21:22:32 INFO  TaskSchedulerImpl:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2016-10-12 21:22:32 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 21:22:32 INFO  DAGScheduler:54 - running: Set()
2016-10-12 21:22:32 INFO  DAGScheduler:54 - waiting: Set(ResultStage 3)
2016-10-12 21:22:32 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 21:22:32 INFO  DAGScheduler:54 - Submitting ResultStage 3 (MapPartitionsRDD[9] at distinct at a1.scala:34), which has no missing parents
2016-10-12 21:22:32 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 3.8 KB, free 366.0 MB)
2016-10-12 21:22:33 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.2 KB, free 366.0 MB)
2016-10-12 21:22:33 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on 150.212.30.95:37346 (size: 2.2 KB, free: 366.3 MB)
2016-10-12 21:22:33 INFO  SparkContext:54 - Created broadcast 4 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:22:33 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[9] at distinct at a1.scala:34)
2016-10-12 21:22:33 INFO  TaskSchedulerImpl:54 - Adding task set 3.0 with 1 tasks
2016-10-12 21:22:33 INFO  TaskSetManager:54 - Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, ANY, 5177 bytes)
2016-10-12 21:22:33 INFO  Executor:54 - Running task 0.0 in stage 3.0 (TID 3)
2016-10-12 21:22:33 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 21:22:33 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2016-10-12 21:22:33 INFO  Executor:54 - Finished task 0.0 in stage 3.0 (TID 3). 1512 bytes result sent to driver
2016-10-12 21:22:33 INFO  DAGScheduler:54 - ResultStage 3 (count at a1.scala:34) finished in 0.042 s
2016-10-12 21:22:33 INFO  TaskSetManager:54 - Finished task 0.0 in stage 3.0 (TID 3) in 44 ms on localhost (1/1)
2016-10-12 21:22:33 INFO  DAGScheduler:54 - Job 1 finished: count at a1.scala:34, took 3.648755 s
2016-10-12 21:22:33 INFO  TaskSchedulerImpl:54 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2016-10-12 21:22:33 INFO  SparkContext:54 - Starting job: collect at a1.scala:35
2016-10-12 21:22:33 INFO  DAGScheduler:54 - Registering RDD 10 (map at a1.scala:35)
2016-10-12 21:22:33 INFO  DAGScheduler:54 - Got job 2 (collect at a1.scala:35) with 1 output partitions
2016-10-12 21:22:33 INFO  DAGScheduler:54 - Final stage: ResultStage 5 (collect at a1.scala:35)
2016-10-12 21:22:33 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 4)
2016-10-12 21:22:33 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 4)
2016-10-12 21:22:33 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 4 (MapPartitionsRDD[10] at map at a1.scala:35), which has no missing parents
2016-10-12 21:22:33 INFO  MemoryStore:54 - Block broadcast_5 stored as values in memory (estimated size 4.0 KB, free 366.0 MB)
2016-10-12 21:22:33 INFO  MemoryStore:54 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.4 KB, free 366.0 MB)
2016-10-12 21:22:33 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on 150.212.30.95:37346 (size: 2.4 KB, free: 366.3 MB)
2016-10-12 21:22:33 INFO  SparkContext:54 - Created broadcast 5 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:22:33 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[10] at map at a1.scala:35)
2016-10-12 21:22:33 INFO  TaskSchedulerImpl:54 - Adding task set 4.0 with 1 tasks
2016-10-12 21:22:33 INFO  TaskSetManager:54 - Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5592 bytes)
2016-10-12 21:22:33 INFO  Executor:54 - Running task 0.0 in stage 4.0 (TID 4)
2016-10-12 21:22:33 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 21:22:33 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 21:22:33 INFO  ContextCleaner:54 - Cleaned shuffle 1
2016-10-12 21:22:33 INFO  BlockManagerInfo:54 - Removed broadcast_3_piece0 on 150.212.30.95:37346 in memory (size: 2.5 KB, free: 366.3 MB)
2016-10-12 21:22:33 INFO  BlockManagerInfo:54 - Removed broadcast_4_piece0 on 150.212.30.95:37346 in memory (size: 2.2 KB, free: 366.3 MB)
2016-10-12 21:22:36 INFO  Executor:54 - Finished task 0.0 in stage 4.0 (TID 4). 1490 bytes result sent to driver
2016-10-12 21:22:36 INFO  TaskSetManager:54 - Finished task 0.0 in stage 4.0 (TID 4) in 3375 ms on localhost (1/1)
2016-10-12 21:22:36 INFO  DAGScheduler:54 - ShuffleMapStage 4 (map at a1.scala:35) finished in 3.376 s
2016-10-12 21:22:36 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 21:22:36 INFO  DAGScheduler:54 - running: Set()
2016-10-12 21:22:36 INFO  DAGScheduler:54 - waiting: Set(ResultStage 5)
2016-10-12 21:22:36 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 21:22:36 INFO  TaskSchedulerImpl:54 - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2016-10-12 21:22:36 INFO  DAGScheduler:54 - Submitting ResultStage 5 (MapPartitionsRDD[13] at map at a1.scala:35), which has no missing parents
2016-10-12 21:22:36 INFO  MemoryStore:54 - Block broadcast_6 stored as values in memory (estimated size 3.8 KB, free 366.0 MB)
2016-10-12 21:22:36 INFO  MemoryStore:54 - Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.2 KB, free 366.0 MB)
2016-10-12 21:22:36 INFO  BlockManagerInfo:54 - Added broadcast_6_piece0 in memory on 150.212.30.95:37346 (size: 2.2 KB, free: 366.3 MB)
2016-10-12 21:22:36 INFO  SparkContext:54 - Created broadcast 6 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:22:36 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[13] at map at a1.scala:35)
2016-10-12 21:22:36 INFO  TaskSchedulerImpl:54 - Adding task set 5.0 with 1 tasks
2016-10-12 21:22:36 INFO  TaskSetManager:54 - Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, ANY, 5262 bytes)
2016-10-12 21:22:36 INFO  Executor:54 - Running task 0.0 in stage 5.0 (TID 5)
2016-10-12 21:22:36 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 21:22:36 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2016-10-12 21:22:36 INFO  Executor:54 - Finished task 0.0 in stage 5.0 (TID 5). 9861 bytes result sent to driver
2016-10-12 21:22:36 INFO  TaskSetManager:54 - Finished task 0.0 in stage 5.0 (TID 5) in 58 ms on localhost (1/1)
2016-10-12 21:22:36 INFO  DAGScheduler:54 - ResultStage 5 (collect at a1.scala:35) finished in 0.058 s
2016-10-12 21:22:36 INFO  DAGScheduler:54 - Job 2 finished: collect at a1.scala:35, took 3.496844 s
2016-10-12 21:22:36 INFO  TaskSchedulerImpl:54 - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2016-10-12 21:22:36 INFO  SparkContext:54 - Starting job: collect at a1.scala:47
2016-10-12 21:22:36 INFO  DAGScheduler:54 - Registering RDD 16 (map at a1.scala:42)
2016-10-12 21:22:36 INFO  DAGScheduler:54 - Got job 3 (collect at a1.scala:47) with 1 output partitions
2016-10-12 21:22:36 INFO  DAGScheduler:54 - Final stage: ResultStage 7 (collect at a1.scala:47)
2016-10-12 21:22:36 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 6)
2016-10-12 21:22:36 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 6)
2016-10-12 21:22:36 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 6 (MapPartitionsRDD[16] at map at a1.scala:42), which has no missing parents
2016-10-12 21:22:36 INFO  MemoryStore:54 - Block broadcast_7 stored as values in memory (estimated size 45.6 KB, free 366.0 MB)
2016-10-12 21:22:36 INFO  MemoryStore:54 - Block broadcast_7_piece0 stored as bytes in memory (estimated size 21.5 KB, free 365.9 MB)
2016-10-12 21:22:36 INFO  BlockManagerInfo:54 - Added broadcast_7_piece0 in memory on 150.212.30.95:37346 (size: 21.5 KB, free: 366.3 MB)
2016-10-12 21:22:36 INFO  SparkContext:54 - Created broadcast 7 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:22:36 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[16] at map at a1.scala:42)
2016-10-12 21:22:36 INFO  TaskSchedulerImpl:54 - Adding task set 6.0 with 1 tasks
2016-10-12 21:22:36 INFO  TaskSetManager:54 - Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, PROCESS_LOCAL, 5592 bytes)
2016-10-12 21:22:36 INFO  Executor:54 - Running task 0.0 in stage 6.0 (TID 6)
2016-10-12 21:22:36 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 21:22:36 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 21:22:37 INFO  ContextCleaner:54 - Cleaned shuffle 2
2016-10-12 21:22:37 INFO  BlockManagerInfo:54 - Removed broadcast_5_piece0 on 150.212.30.95:37346 in memory (size: 2.4 KB, free: 366.3 MB)
2016-10-12 21:22:37 INFO  BlockManagerInfo:54 - Removed broadcast_6_piece0 on 150.212.30.95:37346 in memory (size: 2.2 KB, free: 366.3 MB)
2016-10-12 21:22:41 INFO  Executor:54 - Finished task 0.0 in stage 6.0 (TID 6). 1490 bytes result sent to driver
2016-10-12 21:22:41 INFO  TaskSetManager:54 - Finished task 0.0 in stage 6.0 (TID 6) in 4986 ms on localhost (1/1)
2016-10-12 21:22:41 INFO  DAGScheduler:54 - ShuffleMapStage 6 (map at a1.scala:42) finished in 4.987 s
2016-10-12 21:22:41 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 21:22:41 INFO  DAGScheduler:54 - running: Set()
2016-10-12 21:22:41 INFO  DAGScheduler:54 - waiting: Set(ResultStage 7)
2016-10-12 21:22:41 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 21:22:41 INFO  DAGScheduler:54 - Submitting ResultStage 7 (ShuffledRDD[17] at reduceByKey at a1.scala:42), which has no missing parents
2016-10-12 21:22:41 INFO  TaskSchedulerImpl:54 - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2016-10-12 21:22:41 INFO  MemoryStore:54 - Block broadcast_8 stored as values in memory (estimated size 3.1 KB, free 365.9 MB)
2016-10-12 21:22:41 INFO  MemoryStore:54 - Block broadcast_8_piece0 stored as bytes in memory (estimated size 1901.0 B, free 365.9 MB)
2016-10-12 21:22:41 INFO  BlockManagerInfo:54 - Added broadcast_8_piece0 in memory on 150.212.30.95:37346 (size: 1901.0 B, free: 366.3 MB)
2016-10-12 21:22:41 INFO  SparkContext:54 - Created broadcast 8 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:22:41 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 7 (ShuffledRDD[17] at reduceByKey at a1.scala:42)
2016-10-12 21:22:41 INFO  TaskSchedulerImpl:54 - Adding task set 7.0 with 1 tasks
2016-10-12 21:22:41 INFO  TaskSetManager:54 - Starting task 0.0 in stage 7.0 (TID 7, localhost, partition 0, ANY, 5262 bytes)
2016-10-12 21:22:41 INFO  Executor:54 - Running task 0.0 in stage 7.0 (TID 7)
2016-10-12 21:22:41 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 21:22:41 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 3 ms
2016-10-12 21:22:41 INFO  MemoryStore:54 - Block taskresult_7 stored as bytes in memory (estimated size 4.5 MB, free 361.4 MB)
2016-10-12 21:22:41 INFO  BlockManagerInfo:54 - Added taskresult_7 in memory on 150.212.30.95:37346 (size: 4.5 MB, free: 361.8 MB)
2016-10-12 21:22:41 INFO  Executor:54 - Finished task 0.0 in stage 7.0 (TID 7). 4714208 bytes result sent via BlockManager)
2016-10-12 21:22:41 INFO  TransportClientFactory:250 - Successfully created connection to /150.212.30.95:37346 after 6 ms (0 ms spent in bootstraps)
2016-10-12 21:22:41 INFO  BlockManagerInfo:54 - Removed taskresult_7 on 150.212.30.95:37346 in memory (size: 4.5 MB, free: 366.3 MB)
2016-10-12 21:22:41 INFO  DAGScheduler:54 - ResultStage 7 (collect at a1.scala:47) finished in 0.261 s
2016-10-12 21:22:41 INFO  TaskSetManager:54 - Finished task 0.0 in stage 7.0 (TID 7) in 224 ms on localhost (1/1)
2016-10-12 21:22:41 INFO  DAGScheduler:54 - Job 3 finished: collect at a1.scala:47, took 5.314212 s
2016-10-12 21:22:41 INFO  TaskSchedulerImpl:54 - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2016-10-12 21:22:41 INFO  SparkContext:54 - Starting job: takeSample at a1.scala:69
2016-10-12 21:22:41 INFO  MapOutputTrackerMaster:54 - Size of output statuses for shuffle 3 is 148 bytes
2016-10-12 21:22:41 INFO  DAGScheduler:54 - Got job 4 (takeSample at a1.scala:69) with 1 output partitions
2016-10-12 21:22:41 INFO  DAGScheduler:54 - Final stage: ResultStage 9 (takeSample at a1.scala:69)
2016-10-12 21:22:41 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 8)
2016-10-12 21:22:41 INFO  DAGScheduler:54 - Missing parents: List()
2016-10-12 21:22:41 INFO  DAGScheduler:54 - Submitting ResultStage 9 (ShuffledRDD[17] at reduceByKey at a1.scala:42), which has no missing parents
2016-10-12 21:22:41 INFO  MemoryStore:54 - Block broadcast_9 stored as values in memory (estimated size 2.9 KB, free 365.9 MB)
2016-10-12 21:22:42 INFO  MemoryStore:54 - Block broadcast_9_piece0 stored as bytes in memory (estimated size 1853.0 B, free 365.9 MB)
2016-10-12 21:22:42 INFO  BlockManagerInfo:54 - Removed broadcast_7_piece0 on 150.212.30.95:37346 in memory (size: 21.5 KB, free: 366.3 MB)
2016-10-12 21:22:42 INFO  BlockManagerInfo:54 - Added broadcast_9_piece0 in memory on 150.212.30.95:37346 (size: 1853.0 B, free: 366.3 MB)
2016-10-12 21:22:42 INFO  BlockManagerInfo:54 - Removed broadcast_8_piece0 on 150.212.30.95:37346 in memory (size: 1901.0 B, free: 366.3 MB)
2016-10-12 21:22:42 INFO  SparkContext:54 - Created broadcast 9 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:22:42 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 9 (ShuffledRDD[17] at reduceByKey at a1.scala:42)
2016-10-12 21:22:42 INFO  TaskSchedulerImpl:54 - Adding task set 9.0 with 1 tasks
2016-10-12 21:22:42 INFO  TaskSetManager:54 - Starting task 0.0 in stage 9.0 (TID 8, localhost, partition 0, ANY, 5265 bytes)
2016-10-12 21:22:42 INFO  Executor:54 - Running task 0.0 in stage 9.0 (TID 8)
2016-10-12 21:22:42 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 21:22:42 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 2 ms
2016-10-12 21:22:42 INFO  Executor:54 - Finished task 0.0 in stage 9.0 (TID 8). 1512 bytes result sent to driver
2016-10-12 21:22:42 INFO  TaskSetManager:54 - Finished task 0.0 in stage 9.0 (TID 8) in 60 ms on localhost (1/1)
2016-10-12 21:22:42 INFO  TaskSchedulerImpl:54 - Removed TaskSet 9.0, whose tasks have all completed, from pool 
2016-10-12 21:22:42 INFO  DAGScheduler:54 - ResultStage 9 (takeSample at a1.scala:69) finished in 0.062 s
2016-10-12 21:22:42 INFO  DAGScheduler:54 - Job 4 finished: takeSample at a1.scala:69, took 0.213576 s
2016-10-12 21:22:42 INFO  SparkContext:54 - Starting job: takeSample at a1.scala:69
2016-10-12 21:22:42 INFO  DAGScheduler:54 - Got job 5 (takeSample at a1.scala:69) with 1 output partitions
2016-10-12 21:22:42 INFO  DAGScheduler:54 - Final stage: ResultStage 11 (takeSample at a1.scala:69)
2016-10-12 21:22:42 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 10)
2016-10-12 21:22:42 INFO  DAGScheduler:54 - Missing parents: List()
2016-10-12 21:22:42 INFO  DAGScheduler:54 - Submitting ResultStage 11 (PartitionwiseSampledRDD[18] at takeSample at a1.scala:69), which has no missing parents
2016-10-12 21:22:42 INFO  MemoryStore:54 - Block broadcast_10 stored as values in memory (estimated size 3.8 KB, free 366.0 MB)
2016-10-12 21:22:42 INFO  MemoryStore:54 - Block broadcast_10_piece0 stored as bytes in memory (estimated size 2.3 KB, free 366.0 MB)
2016-10-12 21:22:42 INFO  BlockManagerInfo:54 - Added broadcast_10_piece0 in memory on 150.212.30.95:37346 (size: 2.3 KB, free: 366.3 MB)
2016-10-12 21:22:42 INFO  SparkContext:54 - Created broadcast 10 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:22:42 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 11 (PartitionwiseSampledRDD[18] at takeSample at a1.scala:69)
2016-10-12 21:22:42 INFO  TaskSchedulerImpl:54 - Adding task set 11.0 with 1 tasks
2016-10-12 21:22:42 INFO  TaskSetManager:54 - Starting task 0.0 in stage 11.0 (TID 9, localhost, partition 0, ANY, 5374 bytes)
2016-10-12 21:22:42 INFO  Executor:54 - Running task 0.0 in stage 11.0 (TID 9)
2016-10-12 21:22:42 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 21:22:42 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2016-10-12 21:22:42 INFO  Executor:54 - Finished task 0.0 in stage 11.0 (TID 9). 130349 bytes result sent to driver
2016-10-12 21:22:42 INFO  TaskSetManager:54 - Finished task 0.0 in stage 11.0 (TID 9) in 67 ms on localhost (1/1)
2016-10-12 21:22:42 INFO  TaskSchedulerImpl:54 - Removed TaskSet 11.0, whose tasks have all completed, from pool 
2016-10-12 21:22:42 INFO  DAGScheduler:54 - ResultStage 11 (takeSample at a1.scala:69) finished in 0.068 s
2016-10-12 21:22:42 INFO  DAGScheduler:54 - Job 5 finished: takeSample at a1.scala:69, took 0.097645 s
2016-10-12 21:22:42 INFO  SparkContext:54 - Starting job: collect at a1.scala:71
2016-10-12 21:22:42 INFO  DAGScheduler:54 - Got job 6 (collect at a1.scala:71) with 1 output partitions
2016-10-12 21:22:42 INFO  DAGScheduler:54 - Final stage: ResultStage 13 (collect at a1.scala:71)
2016-10-12 21:22:42 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 12)
2016-10-12 21:22:42 INFO  DAGScheduler:54 - Missing parents: List()
2016-10-12 21:22:42 INFO  DAGScheduler:54 - Submitting ResultStage 13 (MapPartitionsRDD[19] at map at a1.scala:71), which has no missing parents
2016-10-12 21:22:42 INFO  MemoryStore:54 - Block broadcast_11 stored as values in memory (estimated size 3.5 KB, free 366.0 MB)
2016-10-12 21:22:42 INFO  MemoryStore:54 - Block broadcast_11_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.0 MB)
2016-10-12 21:22:42 INFO  BlockManagerInfo:54 - Added broadcast_11_piece0 in memory on 150.212.30.95:37346 (size: 2.1 KB, free: 366.3 MB)
2016-10-12 21:22:42 INFO  SparkContext:54 - Created broadcast 11 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:22:42 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[19] at map at a1.scala:71)
2016-10-12 21:22:42 INFO  TaskSchedulerImpl:54 - Adding task set 13.0 with 1 tasks
2016-10-12 21:22:42 INFO  TaskSetManager:54 - Starting task 0.0 in stage 13.0 (TID 10, localhost, partition 0, ANY, 5262 bytes)
2016-10-12 21:22:42 INFO  Executor:54 - Running task 0.0 in stage 13.0 (TID 10)
2016-10-12 21:22:42 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 21:22:42 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2016-10-12 21:22:42 INFO  MemoryStore:54 - Block taskresult_10 stored as bytes in memory (estimated size 4.5 MB, free 361.5 MB)
2016-10-12 21:22:42 INFO  BlockManagerInfo:54 - Added taskresult_10 in memory on 150.212.30.95:37346 (size: 4.5 MB, free: 361.8 MB)
2016-10-12 21:22:42 INFO  Executor:54 - Finished task 0.0 in stage 13.0 (TID 10). 4684342 bytes result sent via BlockManager)
2016-10-12 21:22:42 INFO  BlockManagerInfo:54 - Removed taskresult_10 on 150.212.30.95:37346 in memory (size: 4.5 MB, free: 366.3 MB)
2016-10-12 21:22:42 INFO  TaskSetManager:54 - Finished task 0.0 in stage 13.0 (TID 10) in 83 ms on localhost (1/1)
2016-10-12 21:22:42 INFO  DAGScheduler:54 - ResultStage 13 (collect at a1.scala:71) finished in 0.093 s
2016-10-12 21:22:42 INFO  DAGScheduler:54 - Job 6 finished: collect at a1.scala:71, took 0.115801 s
2016-10-12 21:22:42 INFO  TaskSchedulerImpl:54 - Removed TaskSet 13.0, whose tasks have all completed, from pool 
2016-10-12 21:22:42 INFO  BlockManagerInfo:54 - Removed broadcast_11_piece0 on 150.212.30.95:37346 in memory (size: 2.1 KB, free: 366.3 MB)
2016-10-12 21:22:42 INFO  BlockManagerInfo:54 - Removed broadcast_10_piece0 on 150.212.30.95:37346 in memory (size: 2.3 KB, free: 366.3 MB)
2016-10-12 21:22:43 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2016-10-12 21:22:43 INFO  ServerConnector:306 - Stopped ServerConnector@6c67e137{HTTP/1.1}{0.0.0.0:4041}
2016-10-12 21:22:43 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,UNAVAILABLE}
2016-10-12 21:22:43 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@62e70ea3{/api,null,UNAVAILABLE}
2016-10-12 21:22:43 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@28276e50{/,null,UNAVAILABLE}
2016-10-12 21:22:43 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a7471ce{/static,null,UNAVAILABLE}
2016-10-12 21:22:43 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,UNAVAILABLE}
2016-10-12 21:22:43 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,UNAVAILABLE}
2016-10-12 21:22:43 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,UNAVAILABLE}
2016-10-12 21:22:43 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@297ea53a{/executors,null,UNAVAILABLE}
2016-10-12 21:22:43 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,UNAVAILABLE}
2016-10-12 21:22:43 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4052274f{/environment,null,UNAVAILABLE}
2016-10-12 21:22:43 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,UNAVAILABLE}
2016-10-12 21:22:43 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,UNAVAILABLE}
2016-10-12 21:22:43 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,UNAVAILABLE}
2016-10-12 21:22:43 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1643d68f{/storage,null,UNAVAILABLE}
2016-10-12 21:22:43 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,UNAVAILABLE}
2016-10-12 21:22:43 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,UNAVAILABLE}
2016-10-12 21:22:43 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,UNAVAILABLE}
2016-10-12 21:22:43 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,UNAVAILABLE}
2016-10-12 21:22:43 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,UNAVAILABLE}
2016-10-12 21:22:43 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,UNAVAILABLE}
2016-10-12 21:22:43 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,UNAVAILABLE}
2016-10-12 21:22:43 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,UNAVAILABLE}
2016-10-12 21:22:43 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,UNAVAILABLE}
2016-10-12 21:22:43 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,UNAVAILABLE}
2016-10-12 21:22:43 INFO  SparkUI:54 - Stopped Spark web UI at http://150.212.30.95:4041
2016-10-12 21:22:43 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2016-10-12 21:22:43 INFO  MemoryStore:54 - MemoryStore cleared
2016-10-12 21:22:43 INFO  BlockManager:54 - BlockManager stopped
2016-10-12 21:22:43 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2016-10-12 21:22:43 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2016-10-12 21:22:43 INFO  SparkContext:54 - Successfully stopped SparkContext
2016-10-12 21:22:43 INFO  ShutdownHookManager:54 - Shutdown hook called
2016-10-12 21:22:43 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-8f91a2d5-915d-4ad4-8454-78198ef8acf9
2016-10-12 21:28:00 INFO  SparkContext:54 - Running Spark version 2.0.0
2016-10-12 21:28:00 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-12 21:28:01 WARN  Utils:66 - Your hostname, aadu-XPS-13-9350 resolves to a loopback address: 127.0.1.1; using 150.212.30.95 instead (on interface wlp58s0)
2016-10-12 21:28:01 WARN  Utils:66 - Set SPARK_LOCAL_IP if you need to bind to another address
2016-10-12 21:28:01 INFO  SecurityManager:54 - Changing view acls to: aadu
2016-10-12 21:28:01 INFO  SecurityManager:54 - Changing modify acls to: aadu
2016-10-12 21:28:01 INFO  SecurityManager:54 - Changing view acls groups to: 
2016-10-12 21:28:01 INFO  SecurityManager:54 - Changing modify acls groups to: 
2016-10-12 21:28:01 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(aadu); groups with view permissions: Set(); users  with modify permissions: Set(aadu); groups with modify permissions: Set()
2016-10-12 21:28:01 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 33353.
2016-10-12 21:28:01 INFO  SparkEnv:54 - Registering MapOutputTracker
2016-10-12 21:28:01 INFO  SparkEnv:54 - Registering BlockManagerMaster
2016-10-12 21:28:01 INFO  DiskBlockManager:54 - Created local directory at /tmp/blockmgr-0d800d09-011d-4d53-8e0e-386c7efe42cb
2016-10-12 21:28:01 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2016-10-12 21:28:01 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2016-10-12 21:28:01 INFO  log:186 - Logging initialized @1452ms
2016-10-12 21:28:01 INFO  Server:327 - jetty-9.2.z-SNAPSHOT
2016-10-12 21:28:01 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,AVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,AVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,AVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,AVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,AVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,AVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,AVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,AVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,AVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,AVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1643d68f{/storage,null,AVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,AVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,AVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,AVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4052274f{/environment,null,AVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,AVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@297ea53a{/executors,null,AVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,AVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,AVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,AVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a7471ce{/static,null,AVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@28276e50{/,null,AVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@62e70ea3{/api,null,AVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,AVAILABLE}
2016-10-12 21:28:01 WARN  AbstractLifeCycle:212 - FAILED ServerConnector@4fe89c24{HTTP/1.1}{0.0.0.0:4040}: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2071)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2062)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:139)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:451)
	at Assign1$.main(a1.scala:20)
	at Assign1.main(a1.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2016-10-12 21:28:01 WARN  AbstractLifeCycle:212 - FAILED org.spark_project.jetty.server.Server@6175619b: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2071)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2062)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:139)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:451)
	at Assign1$.main(a1.scala:20)
	at Assign1.main(a1.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2016-10-12 21:28:01 INFO  ServerConnector:306 - Stopped ServerConnector@4fe89c24{HTTP/1.1}{0.0.0.0:4040}
2016-10-12 21:28:01 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,UNAVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@62e70ea3{/api,null,UNAVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@28276e50{/,null,UNAVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a7471ce{/static,null,UNAVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,UNAVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,UNAVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,UNAVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@297ea53a{/executors,null,UNAVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,UNAVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4052274f{/environment,null,UNAVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,UNAVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,UNAVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,UNAVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1643d68f{/storage,null,UNAVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,UNAVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,UNAVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,UNAVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,UNAVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,UNAVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,UNAVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,UNAVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,UNAVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,UNAVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,UNAVAILABLE}
2016-10-12 21:28:01 WARN  Utils:66 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2016-10-12 21:28:01 INFO  Server:327 - jetty-9.2.z-SNAPSHOT
2016-10-12 21:28:01 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,AVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,AVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,AVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,AVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,AVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,AVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,AVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,AVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,AVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,AVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1643d68f{/storage,null,AVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,AVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,AVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,AVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4052274f{/environment,null,AVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,AVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@297ea53a{/executors,null,AVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,AVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,AVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,AVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a7471ce{/static,null,AVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@28276e50{/,null,AVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@62e70ea3{/api,null,AVAILABLE}
2016-10-12 21:28:01 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,AVAILABLE}
2016-10-12 21:28:01 INFO  ServerConnector:266 - Started ServerConnector@6c67e137{HTTP/1.1}{0.0.0.0:4041}
2016-10-12 21:28:01 INFO  Server:379 - Started @1605ms
2016-10-12 21:28:01 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4041.
2016-10-12 21:28:01 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://150.212.30.95:4041
2016-10-12 21:28:01 INFO  SparkContext:54 - Added JAR file:/home/aadu/Repos/adam/adam-assembly/target/adam_2.11-0.19.1-SNAPSHOT.jar at spark://150.212.30.95:33353/jars/adam_2.11-0.19.1-SNAPSHOT.jar with timestamp 1476322081738
2016-10-12 21:28:01 INFO  SparkContext:54 - Added JAR file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/a1.jar at spark://150.212.30.95:33353/jars/a1.jar with timestamp 1476322081740
2016-10-12 21:28:01 INFO  Executor:54 - Starting executor ID driver on host localhost
2016-10-12 21:28:01 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34959.
2016-10-12 21:28:01 INFO  NettyBlockTransferService:54 - Server created on 150.212.30.95:34959
2016-10-12 21:28:01 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 150.212.30.95, 34959)
2016-10-12 21:28:01 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 150.212.30.95:34959 with 366.3 MB RAM, BlockManagerId(driver, 150.212.30.95, 34959)
2016-10-12 21:28:01 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 150.212.30.95, 34959)
2016-10-12 21:28:01 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2472c7d8{/metrics/json,null,AVAILABLE}
2016-10-12 21:28:02 INFO  ADAMContext:1336 - Loading small.adam as Parquet containing Genotypes. Sequence dictionary for translation is ignored.
2016-10-12 21:28:02 INFO  ADAMContext:257 - Reading the ADAM file at small.adam to create RDD
2016-10-12 21:28:02 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 268.7 KB, free 366.0 MB)
2016-10-12 21:28:03 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 22.8 KB, free 366.0 MB)
2016-10-12 21:28:03 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 150.212.30.95:34959 (size: 22.8 KB, free: 366.3 MB)
2016-10-12 21:28:03 INFO  SparkContext:54 - Created broadcast 0 from newAPIHadoopFile at ADAMContext.scala:271
2016-10-12 21:28:03 INFO  FileInputFormat:283 - Total input paths to process : 1
2016-10-12 21:28:03 INFO  SparkContext:54 - Starting job: count at a1.scala:33
2016-10-12 21:28:03 INFO  DAGScheduler:54 - Registering RDD 3 (distinct at a1.scala:33)
2016-10-12 21:28:03 INFO  DAGScheduler:54 - Got job 0 (count at a1.scala:33) with 1 output partitions
2016-10-12 21:28:03 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (count at a1.scala:33)
2016-10-12 21:28:03 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 0)
2016-10-12 21:28:03 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 0)
2016-10-12 21:28:03 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at distinct at a1.scala:33), which has no missing parents
2016-10-12 21:28:03 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 4.2 KB, free 366.0 MB)
2016-10-12 21:28:03 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.5 KB, free 366.0 MB)
2016-10-12 21:28:03 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 150.212.30.95:34959 (size: 2.5 KB, free: 366.3 MB)
2016-10-12 21:28:03 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:28:03 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at distinct at a1.scala:33)
2016-10-12 21:28:03 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2016-10-12 21:28:03 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5507 bytes)
2016-10-12 21:28:03 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2016-10-12 21:28:03 INFO  Executor:54 - Fetching spark://150.212.30.95:33353/jars/adam_2.11-0.19.1-SNAPSHOT.jar with timestamp 1476322081738
2016-10-12 21:28:03 INFO  TransportClientFactory:250 - Successfully created connection to /150.212.30.95:33353 after 32 ms (0 ms spent in bootstraps)
2016-10-12 21:28:03 INFO  Utils:54 - Fetching spark://150.212.30.95:33353/jars/adam_2.11-0.19.1-SNAPSHOT.jar to /tmp/spark-443eb133-fd5e-47e8-b1e0-526eb0e4b49b/userFiles-633544d5-b450-4182-8591-23f1818c7dce/fetchFileTemp8112909275209099374.tmp
2016-10-12 21:28:03 INFO  Executor:54 - Adding file:/tmp/spark-443eb133-fd5e-47e8-b1e0-526eb0e4b49b/userFiles-633544d5-b450-4182-8591-23f1818c7dce/adam_2.11-0.19.1-SNAPSHOT.jar to class loader
2016-10-12 21:28:03 INFO  Executor:54 - Fetching spark://150.212.30.95:33353/jars/a1.jar with timestamp 1476322081740
2016-10-12 21:28:03 INFO  Utils:54 - Fetching spark://150.212.30.95:33353/jars/a1.jar to /tmp/spark-443eb133-fd5e-47e8-b1e0-526eb0e4b49b/userFiles-633544d5-b450-4182-8591-23f1818c7dce/fetchFileTemp3520067962966727707.tmp
2016-10-12 21:28:03 INFO  Executor:54 - Adding file:/tmp/spark-443eb133-fd5e-47e8-b1e0-526eb0e4b49b/userFiles-633544d5-b450-4182-8591-23f1818c7dce/a1.jar to class loader
2016-10-12 21:28:03 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 21:28:03 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 21:28:07 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1490 bytes result sent to driver
2016-10-12 21:28:07 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 4242 ms on localhost (1/1)
2016-10-12 21:28:07 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2016-10-12 21:28:07 INFO  DAGScheduler:54 - ShuffleMapStage 0 (distinct at a1.scala:33) finished in 4.259 s
2016-10-12 21:28:07 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 21:28:07 INFO  DAGScheduler:54 - running: Set()
2016-10-12 21:28:07 INFO  DAGScheduler:54 - waiting: Set(ResultStage 1)
2016-10-12 21:28:07 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 21:28:07 INFO  DAGScheduler:54 - Submitting ResultStage 1 (MapPartitionsRDD[5] at distinct at a1.scala:33), which has no missing parents
2016-10-12 21:28:07 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 3.7 KB, free 366.0 MB)
2016-10-12 21:28:07 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.2 KB, free 366.0 MB)
2016-10-12 21:28:07 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on 150.212.30.95:34959 (size: 2.2 KB, free: 366.3 MB)
2016-10-12 21:28:07 INFO  SparkContext:54 - Created broadcast 2 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:28:07 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at distinct at a1.scala:33)
2016-10-12 21:28:07 INFO  TaskSchedulerImpl:54 - Adding task set 1.0 with 1 tasks
2016-10-12 21:28:07 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, ANY, 5177 bytes)
2016-10-12 21:28:07 INFO  Executor:54 - Running task 0.0 in stage 1.0 (TID 1)
2016-10-12 21:28:07 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 21:28:07 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 3 ms
2016-10-12 21:28:07 INFO  Executor:54 - Finished task 0.0 in stage 1.0 (TID 1). 1512 bytes result sent to driver
2016-10-12 21:28:07 INFO  DAGScheduler:54 - ResultStage 1 (count at a1.scala:33) finished in 0.102 s
2016-10-12 21:28:07 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 1) in 101 ms on localhost (1/1)
2016-10-12 21:28:07 INFO  TaskSchedulerImpl:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2016-10-12 21:28:07 INFO  DAGScheduler:54 - Job 0 finished: count at a1.scala:33, took 4.544178 s
2016-10-12 21:28:07 INFO  SparkContext:54 - Starting job: count at a1.scala:34
2016-10-12 21:28:07 INFO  DAGScheduler:54 - Registering RDD 7 (distinct at a1.scala:34)
2016-10-12 21:28:07 INFO  DAGScheduler:54 - Got job 1 (count at a1.scala:34) with 1 output partitions
2016-10-12 21:28:07 INFO  DAGScheduler:54 - Final stage: ResultStage 3 (count at a1.scala:34)
2016-10-12 21:28:07 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 2)
2016-10-12 21:28:07 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 2)
2016-10-12 21:28:07 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 2 (MapPartitionsRDD[7] at distinct at a1.scala:34), which has no missing parents
2016-10-12 21:28:07 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 4.2 KB, free 366.0 MB)
2016-10-12 21:28:07 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.5 KB, free 366.0 MB)
2016-10-12 21:28:07 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on 150.212.30.95:34959 (size: 2.5 KB, free: 366.3 MB)
2016-10-12 21:28:07 INFO  SparkContext:54 - Created broadcast 3 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:28:07 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[7] at distinct at a1.scala:34)
2016-10-12 21:28:07 INFO  TaskSchedulerImpl:54 - Adding task set 2.0 with 1 tasks
2016-10-12 21:28:07 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5507 bytes)
2016-10-12 21:28:07 INFO  Executor:54 - Running task 0.0 in stage 2.0 (TID 2)
2016-10-12 21:28:07 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 21:28:07 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 21:28:08 INFO  ContextCleaner:54 - Cleaned shuffle 0
2016-10-12 21:28:08 INFO  BlockManagerInfo:54 - Removed broadcast_1_piece0 on 150.212.30.95:34959 in memory (size: 2.5 KB, free: 366.3 MB)
2016-10-12 21:28:08 INFO  BlockManagerInfo:54 - Removed broadcast_2_piece0 on 150.212.30.95:34959 in memory (size: 2.2 KB, free: 366.3 MB)
2016-10-12 21:28:11 INFO  Executor:54 - Finished task 0.0 in stage 2.0 (TID 2). 1490 bytes result sent to driver
2016-10-12 21:28:11 INFO  TaskSetManager:54 - Finished task 0.0 in stage 2.0 (TID 2) in 3357 ms on localhost (1/1)
2016-10-12 21:28:11 INFO  DAGScheduler:54 - ShuffleMapStage 2 (distinct at a1.scala:34) finished in 3.349 s
2016-10-12 21:28:11 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 21:28:11 INFO  DAGScheduler:54 - running: Set()
2016-10-12 21:28:11 INFO  DAGScheduler:54 - waiting: Set(ResultStage 3)
2016-10-12 21:28:11 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 21:28:11 INFO  DAGScheduler:54 - Submitting ResultStage 3 (MapPartitionsRDD[9] at distinct at a1.scala:34), which has no missing parents
2016-10-12 21:28:11 INFO  TaskSchedulerImpl:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2016-10-12 21:28:11 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 3.8 KB, free 366.0 MB)
2016-10-12 21:28:11 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.2 KB, free 366.0 MB)
2016-10-12 21:28:11 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on 150.212.30.95:34959 (size: 2.2 KB, free: 366.3 MB)
2016-10-12 21:28:11 INFO  SparkContext:54 - Created broadcast 4 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:28:11 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[9] at distinct at a1.scala:34)
2016-10-12 21:28:11 INFO  TaskSchedulerImpl:54 - Adding task set 3.0 with 1 tasks
2016-10-12 21:28:11 INFO  TaskSetManager:54 - Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, ANY, 5177 bytes)
2016-10-12 21:28:11 INFO  Executor:54 - Running task 0.0 in stage 3.0 (TID 3)
2016-10-12 21:28:11 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 21:28:11 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 2 ms
2016-10-12 21:28:11 INFO  Executor:54 - Finished task 0.0 in stage 3.0 (TID 3). 1599 bytes result sent to driver
2016-10-12 21:28:11 INFO  DAGScheduler:54 - ResultStage 3 (count at a1.scala:34) finished in 0.064 s
2016-10-12 21:28:11 INFO  TaskSetManager:54 - Finished task 0.0 in stage 3.0 (TID 3) in 63 ms on localhost (1/1)
2016-10-12 21:28:11 INFO  TaskSchedulerImpl:54 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2016-10-12 21:28:11 INFO  DAGScheduler:54 - Job 1 finished: count at a1.scala:34, took 3.486044 s
2016-10-12 21:28:11 INFO  SparkContext:54 - Starting job: collect at a1.scala:35
2016-10-12 21:28:11 INFO  DAGScheduler:54 - Registering RDD 10 (map at a1.scala:35)
2016-10-12 21:28:11 INFO  DAGScheduler:54 - Got job 2 (collect at a1.scala:35) with 1 output partitions
2016-10-12 21:28:11 INFO  DAGScheduler:54 - Final stage: ResultStage 5 (collect at a1.scala:35)
2016-10-12 21:28:11 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 4)
2016-10-12 21:28:11 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 4)
2016-10-12 21:28:11 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 4 (MapPartitionsRDD[10] at map at a1.scala:35), which has no missing parents
2016-10-12 21:28:11 INFO  MemoryStore:54 - Block broadcast_5 stored as values in memory (estimated size 4.0 KB, free 366.0 MB)
2016-10-12 21:28:11 INFO  MemoryStore:54 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.4 KB, free 366.0 MB)
2016-10-12 21:28:11 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on 150.212.30.95:34959 (size: 2.4 KB, free: 366.3 MB)
2016-10-12 21:28:11 INFO  SparkContext:54 - Created broadcast 5 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:28:11 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[10] at map at a1.scala:35)
2016-10-12 21:28:11 INFO  TaskSchedulerImpl:54 - Adding task set 4.0 with 1 tasks
2016-10-12 21:28:11 INFO  TaskSetManager:54 - Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5592 bytes)
2016-10-12 21:28:11 INFO  Executor:54 - Running task 0.0 in stage 4.0 (TID 4)
2016-10-12 21:28:11 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 21:28:11 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 21:28:11 INFO  ContextCleaner:54 - Cleaned shuffle 1
2016-10-12 21:28:11 INFO  BlockManagerInfo:54 - Removed broadcast_3_piece0 on 150.212.30.95:34959 in memory (size: 2.5 KB, free: 366.3 MB)
2016-10-12 21:28:11 INFO  BlockManagerInfo:54 - Removed broadcast_4_piece0 on 150.212.30.95:34959 in memory (size: 2.2 KB, free: 366.3 MB)
2016-10-12 21:28:14 INFO  Executor:54 - Finished task 0.0 in stage 4.0 (TID 4). 1490 bytes result sent to driver
2016-10-12 21:28:14 INFO  TaskSetManager:54 - Finished task 0.0 in stage 4.0 (TID 4) in 3193 ms on localhost (1/1)
2016-10-12 21:28:14 INFO  DAGScheduler:54 - ShuffleMapStage 4 (map at a1.scala:35) finished in 3.187 s
2016-10-12 21:28:14 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 21:28:14 INFO  DAGScheduler:54 - running: Set()
2016-10-12 21:28:14 INFO  DAGScheduler:54 - waiting: Set(ResultStage 5)
2016-10-12 21:28:14 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 21:28:14 INFO  DAGScheduler:54 - Submitting ResultStage 5 (MapPartitionsRDD[13] at map at a1.scala:35), which has no missing parents
2016-10-12 21:28:14 INFO  MemoryStore:54 - Block broadcast_6 stored as values in memory (estimated size 3.8 KB, free 366.0 MB)
2016-10-12 21:28:14 INFO  TaskSchedulerImpl:54 - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2016-10-12 21:28:14 INFO  MemoryStore:54 - Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.2 KB, free 366.0 MB)
2016-10-12 21:28:14 INFO  BlockManagerInfo:54 - Added broadcast_6_piece0 in memory on 150.212.30.95:34959 (size: 2.2 KB, free: 366.3 MB)
2016-10-12 21:28:14 INFO  SparkContext:54 - Created broadcast 6 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:28:14 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[13] at map at a1.scala:35)
2016-10-12 21:28:14 INFO  TaskSchedulerImpl:54 - Adding task set 5.0 with 1 tasks
2016-10-12 21:28:14 INFO  TaskSetManager:54 - Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, ANY, 5262 bytes)
2016-10-12 21:28:14 INFO  Executor:54 - Running task 0.0 in stage 5.0 (TID 5)
2016-10-12 21:28:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 21:28:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2016-10-12 21:28:14 INFO  Executor:54 - Finished task 0.0 in stage 5.0 (TID 5). 9861 bytes result sent to driver
2016-10-12 21:28:14 INFO  DAGScheduler:54 - ResultStage 5 (collect at a1.scala:35) finished in 0.048 s
2016-10-12 21:28:14 INFO  DAGScheduler:54 - Job 2 finished: collect at a1.scala:35, took 3.284844 s
2016-10-12 21:28:14 INFO  TaskSetManager:54 - Finished task 0.0 in stage 5.0 (TID 5) in 49 ms on localhost (1/1)
2016-10-12 21:28:14 INFO  TaskSchedulerImpl:54 - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2016-10-12 21:28:14 INFO  SparkContext:54 - Starting job: collect at a1.scala:47
2016-10-12 21:28:14 INFO  DAGScheduler:54 - Registering RDD 16 (map at a1.scala:42)
2016-10-12 21:28:14 INFO  DAGScheduler:54 - Got job 3 (collect at a1.scala:47) with 1 output partitions
2016-10-12 21:28:14 INFO  DAGScheduler:54 - Final stage: ResultStage 7 (collect at a1.scala:47)
2016-10-12 21:28:14 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 6)
2016-10-12 21:28:14 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 6)
2016-10-12 21:28:14 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 6 (MapPartitionsRDD[16] at map at a1.scala:42), which has no missing parents
2016-10-12 21:28:14 INFO  MemoryStore:54 - Block broadcast_7 stored as values in memory (estimated size 45.6 KB, free 366.0 MB)
2016-10-12 21:28:14 INFO  MemoryStore:54 - Block broadcast_7_piece0 stored as bytes in memory (estimated size 21.5 KB, free 365.9 MB)
2016-10-12 21:28:14 INFO  BlockManagerInfo:54 - Added broadcast_7_piece0 in memory on 150.212.30.95:34959 (size: 21.5 KB, free: 366.3 MB)
2016-10-12 21:28:14 INFO  SparkContext:54 - Created broadcast 7 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:28:14 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[16] at map at a1.scala:42)
2016-10-12 21:28:14 INFO  TaskSchedulerImpl:54 - Adding task set 6.0 with 1 tasks
2016-10-12 21:28:14 INFO  TaskSetManager:54 - Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, PROCESS_LOCAL, 5592 bytes)
2016-10-12 21:28:14 INFO  Executor:54 - Running task 0.0 in stage 6.0 (TID 6)
2016-10-12 21:28:14 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 21:28:14 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 21:28:15 INFO  ContextCleaner:54 - Cleaned shuffle 2
2016-10-12 21:28:15 INFO  BlockManagerInfo:54 - Removed broadcast_5_piece0 on 150.212.30.95:34959 in memory (size: 2.4 KB, free: 366.3 MB)
2016-10-12 21:28:15 INFO  BlockManagerInfo:54 - Removed broadcast_6_piece0 on 150.212.30.95:34959 in memory (size: 2.2 KB, free: 366.3 MB)
2016-10-12 21:28:19 INFO  Executor:54 - Finished task 0.0 in stage 6.0 (TID 6). 1490 bytes result sent to driver
2016-10-12 21:28:19 INFO  TaskSetManager:54 - Finished task 0.0 in stage 6.0 (TID 6) in 4237 ms on localhost (1/1)
2016-10-12 21:28:19 INFO  DAGScheduler:54 - ShuffleMapStage 6 (map at a1.scala:42) finished in 4.240 s
2016-10-12 21:28:19 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 21:28:19 INFO  DAGScheduler:54 - running: Set()
2016-10-12 21:28:19 INFO  DAGScheduler:54 - waiting: Set(ResultStage 7)
2016-10-12 21:28:19 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 21:28:19 INFO  DAGScheduler:54 - Submitting ResultStage 7 (ShuffledRDD[17] at reduceByKey at a1.scala:42), which has no missing parents
2016-10-12 21:28:19 INFO  TaskSchedulerImpl:54 - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2016-10-12 21:28:19 INFO  MemoryStore:54 - Block broadcast_8 stored as values in memory (estimated size 3.1 KB, free 365.9 MB)
2016-10-12 21:28:19 INFO  MemoryStore:54 - Block broadcast_8_piece0 stored as bytes in memory (estimated size 1901.0 B, free 365.9 MB)
2016-10-12 21:28:19 INFO  BlockManagerInfo:54 - Added broadcast_8_piece0 in memory on 150.212.30.95:34959 (size: 1901.0 B, free: 366.3 MB)
2016-10-12 21:28:19 INFO  SparkContext:54 - Created broadcast 8 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:28:19 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 7 (ShuffledRDD[17] at reduceByKey at a1.scala:42)
2016-10-12 21:28:19 INFO  TaskSchedulerImpl:54 - Adding task set 7.0 with 1 tasks
2016-10-12 21:28:19 INFO  TaskSetManager:54 - Starting task 0.0 in stage 7.0 (TID 7, localhost, partition 0, ANY, 5262 bytes)
2016-10-12 21:28:19 INFO  Executor:54 - Running task 0.0 in stage 7.0 (TID 7)
2016-10-12 21:28:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 21:28:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2016-10-12 21:28:19 INFO  MemoryStore:54 - Block taskresult_7 stored as bytes in memory (estimated size 4.5 MB, free 361.4 MB)
2016-10-12 21:28:19 INFO  BlockManagerInfo:54 - Added taskresult_7 in memory on 150.212.30.95:34959 (size: 4.5 MB, free: 361.8 MB)
2016-10-12 21:28:19 INFO  Executor:54 - Finished task 0.0 in stage 7.0 (TID 7). 4714208 bytes result sent via BlockManager)
2016-10-12 21:28:19 INFO  TransportClientFactory:250 - Successfully created connection to /150.212.30.95:34959 after 1 ms (0 ms spent in bootstraps)
2016-10-12 21:28:19 INFO  BlockManagerInfo:54 - Removed taskresult_7 on 150.212.30.95:34959 in memory (size: 4.5 MB, free: 366.3 MB)
2016-10-12 21:28:19 INFO  TaskSetManager:54 - Finished task 0.0 in stage 7.0 (TID 7) in 203 ms on localhost (1/1)
2016-10-12 21:28:19 INFO  DAGScheduler:54 - ResultStage 7 (collect at a1.scala:47) finished in 0.222 s
2016-10-12 21:28:19 INFO  TaskSchedulerImpl:54 - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2016-10-12 21:28:19 INFO  DAGScheduler:54 - Job 3 finished: collect at a1.scala:47, took 4.497826 s
2016-10-12 21:28:19 INFO  SparkContext:54 - Starting job: takeSample at a1.scala:69
2016-10-12 21:28:19 INFO  MapOutputTrackerMaster:54 - Size of output statuses for shuffle 3 is 147 bytes
2016-10-12 21:28:19 INFO  DAGScheduler:54 - Got job 4 (takeSample at a1.scala:69) with 1 output partitions
2016-10-12 21:28:19 INFO  DAGScheduler:54 - Final stage: ResultStage 9 (takeSample at a1.scala:69)
2016-10-12 21:28:19 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 8)
2016-10-12 21:28:19 INFO  DAGScheduler:54 - Missing parents: List()
2016-10-12 21:28:19 INFO  DAGScheduler:54 - Submitting ResultStage 9 (ShuffledRDD[17] at reduceByKey at a1.scala:42), which has no missing parents
2016-10-12 21:28:19 INFO  MemoryStore:54 - Block broadcast_9 stored as values in memory (estimated size 2.9 KB, free 365.9 MB)
2016-10-12 21:28:19 INFO  MemoryStore:54 - Block broadcast_9_piece0 stored as bytes in memory (estimated size 1853.0 B, free 365.9 MB)
2016-10-12 21:28:19 INFO  BlockManagerInfo:54 - Added broadcast_9_piece0 in memory on 150.212.30.95:34959 (size: 1853.0 B, free: 366.3 MB)
2016-10-12 21:28:19 INFO  SparkContext:54 - Created broadcast 9 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:28:19 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 9 (ShuffledRDD[17] at reduceByKey at a1.scala:42)
2016-10-12 21:28:19 INFO  TaskSchedulerImpl:54 - Adding task set 9.0 with 1 tasks
2016-10-12 21:28:19 INFO  TaskSetManager:54 - Starting task 0.0 in stage 9.0 (TID 8, localhost, partition 0, ANY, 5265 bytes)
2016-10-12 21:28:19 INFO  Executor:54 - Running task 0.0 in stage 9.0 (TID 8)
2016-10-12 21:28:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 21:28:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2016-10-12 21:28:19 INFO  Executor:54 - Finished task 0.0 in stage 9.0 (TID 8). 1512 bytes result sent to driver
2016-10-12 21:28:19 INFO  TaskSetManager:54 - Finished task 0.0 in stage 9.0 (TID 8) in 45 ms on localhost (1/1)
2016-10-12 21:28:19 INFO  TaskSchedulerImpl:54 - Removed TaskSet 9.0, whose tasks have all completed, from pool 
2016-10-12 21:28:19 INFO  DAGScheduler:54 - ResultStage 9 (takeSample at a1.scala:69) finished in 0.046 s
2016-10-12 21:28:19 INFO  DAGScheduler:54 - Job 4 finished: takeSample at a1.scala:69, took 0.065084 s
2016-10-12 21:28:19 INFO  SparkContext:54 - Starting job: takeSample at a1.scala:69
2016-10-12 21:28:19 INFO  DAGScheduler:54 - Got job 5 (takeSample at a1.scala:69) with 1 output partitions
2016-10-12 21:28:19 INFO  DAGScheduler:54 - Final stage: ResultStage 11 (takeSample at a1.scala:69)
2016-10-12 21:28:19 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 10)
2016-10-12 21:28:19 INFO  DAGScheduler:54 - Missing parents: List()
2016-10-12 21:28:19 INFO  DAGScheduler:54 - Submitting ResultStage 11 (PartitionwiseSampledRDD[18] at takeSample at a1.scala:69), which has no missing parents
2016-10-12 21:28:19 INFO  MemoryStore:54 - Block broadcast_10 stored as values in memory (estimated size 3.8 KB, free 365.9 MB)
2016-10-12 21:28:19 INFO  MemoryStore:54 - Block broadcast_10_piece0 stored as bytes in memory (estimated size 2.3 KB, free 365.9 MB)
2016-10-12 21:28:19 INFO  BlockManagerInfo:54 - Added broadcast_10_piece0 in memory on 150.212.30.95:34959 (size: 2.3 KB, free: 366.3 MB)
2016-10-12 21:28:19 INFO  SparkContext:54 - Created broadcast 10 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:28:19 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 11 (PartitionwiseSampledRDD[18] at takeSample at a1.scala:69)
2016-10-12 21:28:19 INFO  TaskSchedulerImpl:54 - Adding task set 11.0 with 1 tasks
2016-10-12 21:28:19 INFO  TaskSetManager:54 - Starting task 0.0 in stage 11.0 (TID 9, localhost, partition 0, ANY, 5374 bytes)
2016-10-12 21:28:19 INFO  Executor:54 - Running task 0.0 in stage 11.0 (TID 9)
2016-10-12 21:28:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 21:28:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2016-10-12 21:28:19 INFO  BlockManagerInfo:54 - Removed broadcast_7_piece0 on 150.212.30.95:34959 in memory (size: 21.5 KB, free: 366.3 MB)
2016-10-12 21:28:19 INFO  BlockManagerInfo:54 - Removed broadcast_8_piece0 on 150.212.30.95:34959 in memory (size: 1901.0 B, free: 366.3 MB)
2016-10-12 21:28:19 INFO  BlockManagerInfo:54 - Removed broadcast_9_piece0 on 150.212.30.95:34959 in memory (size: 1853.0 B, free: 366.3 MB)
2016-10-12 21:28:19 INFO  Executor:54 - Finished task 0.0 in stage 11.0 (TID 9). 137082 bytes result sent to driver
2016-10-12 21:28:19 INFO  TaskSetManager:54 - Finished task 0.0 in stage 11.0 (TID 9) in 169 ms on localhost (1/1)
2016-10-12 21:28:19 INFO  DAGScheduler:54 - ResultStage 11 (takeSample at a1.scala:69) finished in 0.170 s
2016-10-12 21:28:19 INFO  DAGScheduler:54 - Job 5 finished: takeSample at a1.scala:69, took 0.188796 s
2016-10-12 21:28:19 INFO  TaskSchedulerImpl:54 - Removed TaskSet 11.0, whose tasks have all completed, from pool 
2016-10-12 21:28:19 INFO  SparkContext:54 - Starting job: collect at a1.scala:71
2016-10-12 21:28:19 INFO  DAGScheduler:54 - Got job 6 (collect at a1.scala:71) with 1 output partitions
2016-10-12 21:28:19 INFO  DAGScheduler:54 - Final stage: ResultStage 13 (collect at a1.scala:71)
2016-10-12 21:28:19 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 12)
2016-10-12 21:28:19 INFO  DAGScheduler:54 - Missing parents: List()
2016-10-12 21:28:19 INFO  DAGScheduler:54 - Submitting ResultStage 13 (MapPartitionsRDD[19] at map at a1.scala:71), which has no missing parents
2016-10-12 21:28:19 INFO  MemoryStore:54 - Block broadcast_11 stored as values in memory (estimated size 3.5 KB, free 366.0 MB)
2016-10-12 21:28:19 INFO  MemoryStore:54 - Block broadcast_11_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.0 MB)
2016-10-12 21:28:19 INFO  BlockManagerInfo:54 - Added broadcast_11_piece0 in memory on 150.212.30.95:34959 (size: 2.1 KB, free: 366.3 MB)
2016-10-12 21:28:19 INFO  SparkContext:54 - Created broadcast 11 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:28:19 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[19] at map at a1.scala:71)
2016-10-12 21:28:19 INFO  TaskSchedulerImpl:54 - Adding task set 13.0 with 1 tasks
2016-10-12 21:28:19 INFO  TaskSetManager:54 - Starting task 0.0 in stage 13.0 (TID 10, localhost, partition 0, ANY, 5262 bytes)
2016-10-12 21:28:19 INFO  Executor:54 - Running task 0.0 in stage 13.0 (TID 10)
2016-10-12 21:28:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 21:28:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2016-10-12 21:28:19 INFO  MemoryStore:54 - Block taskresult_10 stored as bytes in memory (estimated size 4.5 MB, free 361.5 MB)
2016-10-12 21:28:19 INFO  BlockManagerInfo:54 - Added taskresult_10 in memory on 150.212.30.95:34959 (size: 4.5 MB, free: 361.8 MB)
2016-10-12 21:28:19 INFO  Executor:54 - Finished task 0.0 in stage 13.0 (TID 10). 4684342 bytes result sent via BlockManager)
2016-10-12 21:28:19 INFO  BlockManagerInfo:54 - Removed taskresult_10 on 150.212.30.95:34959 in memory (size: 4.5 MB, free: 366.3 MB)
2016-10-12 21:28:19 INFO  DAGScheduler:54 - ResultStage 13 (collect at a1.scala:71) finished in 0.105 s
2016-10-12 21:28:19 INFO  DAGScheduler:54 - Job 6 finished: collect at a1.scala:71, took 0.121639 s
2016-10-12 21:28:19 INFO  TaskSetManager:54 - Finished task 0.0 in stage 13.0 (TID 10) in 87 ms on localhost (1/1)
2016-10-12 21:28:19 INFO  TaskSchedulerImpl:54 - Removed TaskSet 13.0, whose tasks have all completed, from pool 
2016-10-12 21:28:19 INFO  BlockManagerInfo:54 - Removed broadcast_11_piece0 on 150.212.30.95:34959 in memory (size: 2.1 KB, free: 366.3 MB)
2016-10-12 21:28:20 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2016-10-12 21:28:20 INFO  ServerConnector:306 - Stopped ServerConnector@6c67e137{HTTP/1.1}{0.0.0.0:4041}
2016-10-12 21:28:20 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,UNAVAILABLE}
2016-10-12 21:28:20 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@62e70ea3{/api,null,UNAVAILABLE}
2016-10-12 21:28:20 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@28276e50{/,null,UNAVAILABLE}
2016-10-12 21:28:20 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a7471ce{/static,null,UNAVAILABLE}
2016-10-12 21:28:20 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,UNAVAILABLE}
2016-10-12 21:28:20 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,UNAVAILABLE}
2016-10-12 21:28:20 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,UNAVAILABLE}
2016-10-12 21:28:20 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@297ea53a{/executors,null,UNAVAILABLE}
2016-10-12 21:28:20 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,UNAVAILABLE}
2016-10-12 21:28:20 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4052274f{/environment,null,UNAVAILABLE}
2016-10-12 21:28:20 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,UNAVAILABLE}
2016-10-12 21:28:20 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,UNAVAILABLE}
2016-10-12 21:28:20 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,UNAVAILABLE}
2016-10-12 21:28:20 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1643d68f{/storage,null,UNAVAILABLE}
2016-10-12 21:28:20 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,UNAVAILABLE}
2016-10-12 21:28:20 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,UNAVAILABLE}
2016-10-12 21:28:20 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,UNAVAILABLE}
2016-10-12 21:28:20 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,UNAVAILABLE}
2016-10-12 21:28:20 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,UNAVAILABLE}
2016-10-12 21:28:20 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,UNAVAILABLE}
2016-10-12 21:28:20 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,UNAVAILABLE}
2016-10-12 21:28:20 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,UNAVAILABLE}
2016-10-12 21:28:20 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,UNAVAILABLE}
2016-10-12 21:28:20 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,UNAVAILABLE}
2016-10-12 21:28:20 INFO  SparkUI:54 - Stopped Spark web UI at http://150.212.30.95:4041
2016-10-12 21:28:20 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2016-10-12 21:28:20 INFO  MemoryStore:54 - MemoryStore cleared
2016-10-12 21:28:20 INFO  BlockManager:54 - BlockManager stopped
2016-10-12 21:28:20 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2016-10-12 21:28:20 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2016-10-12 21:28:20 INFO  SparkContext:54 - Successfully stopped SparkContext
2016-10-12 21:28:20 INFO  ShutdownHookManager:54 - Shutdown hook called
2016-10-12 21:28:20 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-443eb133-fd5e-47e8-b1e0-526eb0e4b49b
2016-10-12 21:30:21 INFO  SparkContext:54 - Running Spark version 2.0.0
2016-10-12 21:30:22 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-12 21:30:22 WARN  Utils:66 - Your hostname, aadu-XPS-13-9350 resolves to a loopback address: 127.0.1.1; using 150.212.30.95 instead (on interface wlp58s0)
2016-10-12 21:30:22 WARN  Utils:66 - Set SPARK_LOCAL_IP if you need to bind to another address
2016-10-12 21:30:22 INFO  SecurityManager:54 - Changing view acls to: aadu
2016-10-12 21:30:22 INFO  SecurityManager:54 - Changing modify acls to: aadu
2016-10-12 21:30:22 INFO  SecurityManager:54 - Changing view acls groups to: 
2016-10-12 21:30:22 INFO  SecurityManager:54 - Changing modify acls groups to: 
2016-10-12 21:30:22 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(aadu); groups with view permissions: Set(); users  with modify permissions: Set(aadu); groups with modify permissions: Set()
2016-10-12 21:30:22 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 45320.
2016-10-12 21:30:22 INFO  SparkEnv:54 - Registering MapOutputTracker
2016-10-12 21:30:22 INFO  SparkEnv:54 - Registering BlockManagerMaster
2016-10-12 21:30:22 INFO  DiskBlockManager:54 - Created local directory at /tmp/blockmgr-6dd4210f-16c4-46b9-b95a-2ee1a5db5907
2016-10-12 21:30:22 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2016-10-12 21:30:22 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2016-10-12 21:30:22 INFO  log:186 - Logging initialized @1423ms
2016-10-12 21:30:22 INFO  Server:327 - jetty-9.2.z-SNAPSHOT
2016-10-12 21:30:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,AVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,AVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,AVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,AVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,AVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,AVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,AVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,AVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,AVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,AVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1643d68f{/storage,null,AVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,AVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,AVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,AVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4052274f{/environment,null,AVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,AVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@297ea53a{/executors,null,AVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,AVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,AVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,AVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a7471ce{/static,null,AVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@28276e50{/,null,AVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@62e70ea3{/api,null,AVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,AVAILABLE}
2016-10-12 21:30:22 WARN  AbstractLifeCycle:212 - FAILED ServerConnector@4fe89c24{HTTP/1.1}{0.0.0.0:4040}: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2071)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2062)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:139)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:451)
	at Assign1$.main(a1.scala:20)
	at Assign1.main(a1.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2016-10-12 21:30:22 WARN  AbstractLifeCycle:212 - FAILED org.spark_project.jetty.server.Server@6175619b: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2071)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2062)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:139)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:451)
	at Assign1$.main(a1.scala:20)
	at Assign1.main(a1.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2016-10-12 21:30:22 INFO  ServerConnector:306 - Stopped ServerConnector@4fe89c24{HTTP/1.1}{0.0.0.0:4040}
2016-10-12 21:30:22 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,UNAVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@62e70ea3{/api,null,UNAVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@28276e50{/,null,UNAVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a7471ce{/static,null,UNAVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,UNAVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,UNAVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,UNAVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@297ea53a{/executors,null,UNAVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,UNAVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4052274f{/environment,null,UNAVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,UNAVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,UNAVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,UNAVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1643d68f{/storage,null,UNAVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,UNAVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,UNAVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,UNAVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,UNAVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,UNAVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,UNAVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,UNAVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,UNAVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,UNAVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,UNAVAILABLE}
2016-10-12 21:30:22 WARN  Utils:66 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2016-10-12 21:30:22 INFO  Server:327 - jetty-9.2.z-SNAPSHOT
2016-10-12 21:30:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,AVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,AVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,AVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,AVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,AVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,AVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,AVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,AVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,AVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,AVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1643d68f{/storage,null,AVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,AVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,AVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,AVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4052274f{/environment,null,AVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,AVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@297ea53a{/executors,null,AVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,AVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,AVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,AVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a7471ce{/static,null,AVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@28276e50{/,null,AVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@62e70ea3{/api,null,AVAILABLE}
2016-10-12 21:30:22 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,AVAILABLE}
2016-10-12 21:30:22 INFO  ServerConnector:266 - Started ServerConnector@6c67e137{HTTP/1.1}{0.0.0.0:4041}
2016-10-12 21:30:22 INFO  Server:379 - Started @1581ms
2016-10-12 21:30:22 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4041.
2016-10-12 21:30:22 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://150.212.30.95:4041
2016-10-12 21:30:22 INFO  SparkContext:54 - Added JAR file:/home/aadu/Repos/adam/adam-assembly/target/adam_2.11-0.19.1-SNAPSHOT.jar at spark://150.212.30.95:45320/jars/adam_2.11-0.19.1-SNAPSHOT.jar with timestamp 1476322222997
2016-10-12 21:30:22 INFO  SparkContext:54 - Added JAR file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/a1.jar at spark://150.212.30.95:45320/jars/a1.jar with timestamp 1476322222998
2016-10-12 21:30:23 INFO  Executor:54 - Starting executor ID driver on host localhost
2016-10-12 21:30:23 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40555.
2016-10-12 21:30:23 INFO  NettyBlockTransferService:54 - Server created on 150.212.30.95:40555
2016-10-12 21:30:23 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 150.212.30.95, 40555)
2016-10-12 21:30:23 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 150.212.30.95:40555 with 366.3 MB RAM, BlockManagerId(driver, 150.212.30.95, 40555)
2016-10-12 21:30:23 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 150.212.30.95, 40555)
2016-10-12 21:30:23 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2472c7d8{/metrics/json,null,AVAILABLE}
2016-10-12 21:30:23 INFO  ADAMContext:1336 - Loading small.adam as Parquet containing Genotypes. Sequence dictionary for translation is ignored.
2016-10-12 21:30:23 INFO  ADAMContext:257 - Reading the ADAM file at small.adam to create RDD
2016-10-12 21:30:23 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 268.7 KB, free 366.0 MB)
2016-10-12 21:30:24 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 22.8 KB, free 366.0 MB)
2016-10-12 21:30:24 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 150.212.30.95:40555 (size: 22.8 KB, free: 366.3 MB)
2016-10-12 21:30:24 INFO  SparkContext:54 - Created broadcast 0 from newAPIHadoopFile at ADAMContext.scala:271
2016-10-12 21:30:24 INFO  FileInputFormat:283 - Total input paths to process : 1
2016-10-12 21:30:24 INFO  SparkContext:54 - Starting job: count at a1.scala:33
2016-10-12 21:30:24 INFO  DAGScheduler:54 - Registering RDD 3 (distinct at a1.scala:33)
2016-10-12 21:30:24 INFO  DAGScheduler:54 - Got job 0 (count at a1.scala:33) with 1 output partitions
2016-10-12 21:30:24 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (count at a1.scala:33)
2016-10-12 21:30:24 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 0)
2016-10-12 21:30:24 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 0)
2016-10-12 21:30:24 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at distinct at a1.scala:33), which has no missing parents
2016-10-12 21:30:24 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 4.2 KB, free 366.0 MB)
2016-10-12 21:30:24 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.5 KB, free 366.0 MB)
2016-10-12 21:30:24 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 150.212.30.95:40555 (size: 2.5 KB, free: 366.3 MB)
2016-10-12 21:30:24 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:30:24 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at distinct at a1.scala:33)
2016-10-12 21:30:24 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2016-10-12 21:30:24 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5507 bytes)
2016-10-12 21:30:24 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2016-10-12 21:30:24 INFO  Executor:54 - Fetching spark://150.212.30.95:45320/jars/adam_2.11-0.19.1-SNAPSHOT.jar with timestamp 1476322222997
2016-10-12 21:30:24 INFO  TransportClientFactory:250 - Successfully created connection to /150.212.30.95:45320 after 23 ms (0 ms spent in bootstraps)
2016-10-12 21:30:24 INFO  Utils:54 - Fetching spark://150.212.30.95:45320/jars/adam_2.11-0.19.1-SNAPSHOT.jar to /tmp/spark-d094434c-bcda-46c1-8b8a-70a313476653/userFiles-566c9f54-8bb9-4223-be89-479a76279d66/fetchFileTemp6911112544926251110.tmp
2016-10-12 21:30:25 INFO  Executor:54 - Adding file:/tmp/spark-d094434c-bcda-46c1-8b8a-70a313476653/userFiles-566c9f54-8bb9-4223-be89-479a76279d66/adam_2.11-0.19.1-SNAPSHOT.jar to class loader
2016-10-12 21:30:25 INFO  Executor:54 - Fetching spark://150.212.30.95:45320/jars/a1.jar with timestamp 1476322222998
2016-10-12 21:30:25 INFO  Utils:54 - Fetching spark://150.212.30.95:45320/jars/a1.jar to /tmp/spark-d094434c-bcda-46c1-8b8a-70a313476653/userFiles-566c9f54-8bb9-4223-be89-479a76279d66/fetchFileTemp2090082492083865789.tmp
2016-10-12 21:30:25 INFO  Executor:54 - Adding file:/tmp/spark-d094434c-bcda-46c1-8b8a-70a313476653/userFiles-566c9f54-8bb9-4223-be89-479a76279d66/a1.jar to class loader
2016-10-12 21:30:25 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 21:30:25 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 21:30:28 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1490 bytes result sent to driver
2016-10-12 21:30:28 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 4035 ms on localhost (1/1)
2016-10-12 21:30:28 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2016-10-12 21:30:28 INFO  DAGScheduler:54 - ShuffleMapStage 0 (distinct at a1.scala:33) finished in 4.052 s
2016-10-12 21:30:28 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 21:30:28 INFO  DAGScheduler:54 - running: Set()
2016-10-12 21:30:28 INFO  DAGScheduler:54 - waiting: Set(ResultStage 1)
2016-10-12 21:30:28 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 21:30:28 INFO  DAGScheduler:54 - Submitting ResultStage 1 (MapPartitionsRDD[5] at distinct at a1.scala:33), which has no missing parents
2016-10-12 21:30:28 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 3.7 KB, free 366.0 MB)
2016-10-12 21:30:28 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.2 KB, free 366.0 MB)
2016-10-12 21:30:28 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on 150.212.30.95:40555 (size: 2.2 KB, free: 366.3 MB)
2016-10-12 21:30:28 INFO  SparkContext:54 - Created broadcast 2 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:30:28 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at distinct at a1.scala:33)
2016-10-12 21:30:28 INFO  TaskSchedulerImpl:54 - Adding task set 1.0 with 1 tasks
2016-10-12 21:30:28 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, ANY, 5177 bytes)
2016-10-12 21:30:28 INFO  Executor:54 - Running task 0.0 in stage 1.0 (TID 1)
2016-10-12 21:30:28 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 21:30:28 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 4 ms
2016-10-12 21:30:28 INFO  Executor:54 - Finished task 0.0 in stage 1.0 (TID 1). 1512 bytes result sent to driver
2016-10-12 21:30:28 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 1) in 104 ms on localhost (1/1)
2016-10-12 21:30:28 INFO  DAGScheduler:54 - ResultStage 1 (count at a1.scala:33) finished in 0.104 s
2016-10-12 21:30:28 INFO  TaskSchedulerImpl:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2016-10-12 21:30:28 INFO  DAGScheduler:54 - Job 0 finished: count at a1.scala:33, took 4.347179 s
2016-10-12 21:30:28 INFO  BlockManagerInfo:54 - Removed broadcast_1_piece0 on 150.212.30.95:40555 in memory (size: 2.5 KB, free: 366.3 MB)
2016-10-12 21:30:28 INFO  SparkContext:54 - Starting job: count at a1.scala:34
2016-10-12 21:30:28 INFO  DAGScheduler:54 - Registering RDD 7 (distinct at a1.scala:34)
2016-10-12 21:30:28 INFO  DAGScheduler:54 - Got job 1 (count at a1.scala:34) with 1 output partitions
2016-10-12 21:30:28 INFO  DAGScheduler:54 - Final stage: ResultStage 3 (count at a1.scala:34)
2016-10-12 21:30:28 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 2)
2016-10-12 21:30:28 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 2)
2016-10-12 21:30:28 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 2 (MapPartitionsRDD[7] at distinct at a1.scala:34), which has no missing parents
2016-10-12 21:30:28 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 4.2 KB, free 366.0 MB)
2016-10-12 21:30:28 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.5 KB, free 366.0 MB)
2016-10-12 21:30:28 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on 150.212.30.95:40555 (size: 2.5 KB, free: 366.3 MB)
2016-10-12 21:30:28 INFO  SparkContext:54 - Created broadcast 3 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:30:29 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[7] at distinct at a1.scala:34)
2016-10-12 21:30:29 INFO  TaskSchedulerImpl:54 - Adding task set 2.0 with 1 tasks
2016-10-12 21:30:29 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5507 bytes)
2016-10-12 21:30:29 INFO  Executor:54 - Running task 0.0 in stage 2.0 (TID 2)
2016-10-12 21:30:29 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 21:30:29 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 21:30:29 INFO  ContextCleaner:54 - Cleaned shuffle 0
2016-10-12 21:30:29 INFO  BlockManagerInfo:54 - Removed broadcast_2_piece0 on 150.212.30.95:40555 in memory (size: 2.2 KB, free: 366.3 MB)
2016-10-12 21:30:32 INFO  Executor:54 - Finished task 0.0 in stage 2.0 (TID 2). 1490 bytes result sent to driver
2016-10-12 21:30:32 INFO  TaskSetManager:54 - Finished task 0.0 in stage 2.0 (TID 2) in 3169 ms on localhost (1/1)
2016-10-12 21:30:32 INFO  TaskSchedulerImpl:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2016-10-12 21:30:32 INFO  DAGScheduler:54 - ShuffleMapStage 2 (distinct at a1.scala:34) finished in 3.166 s
2016-10-12 21:30:32 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 21:30:32 INFO  DAGScheduler:54 - running: Set()
2016-10-12 21:30:32 INFO  DAGScheduler:54 - waiting: Set(ResultStage 3)
2016-10-12 21:30:32 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 21:30:32 INFO  DAGScheduler:54 - Submitting ResultStage 3 (MapPartitionsRDD[9] at distinct at a1.scala:34), which has no missing parents
2016-10-12 21:30:32 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 3.8 KB, free 366.0 MB)
2016-10-12 21:30:32 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.2 KB, free 366.0 MB)
2016-10-12 21:30:32 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on 150.212.30.95:40555 (size: 2.2 KB, free: 366.3 MB)
2016-10-12 21:30:32 INFO  SparkContext:54 - Created broadcast 4 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:30:32 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[9] at distinct at a1.scala:34)
2016-10-12 21:30:32 INFO  TaskSchedulerImpl:54 - Adding task set 3.0 with 1 tasks
2016-10-12 21:30:32 INFO  TaskSetManager:54 - Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, ANY, 5177 bytes)
2016-10-12 21:30:32 INFO  Executor:54 - Running task 0.0 in stage 3.0 (TID 3)
2016-10-12 21:30:32 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 21:30:32 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2016-10-12 21:30:32 INFO  Executor:54 - Finished task 0.0 in stage 3.0 (TID 3). 1512 bytes result sent to driver
2016-10-12 21:30:32 INFO  DAGScheduler:54 - ResultStage 3 (count at a1.scala:34) finished in 0.067 s
2016-10-12 21:30:32 INFO  TaskSetManager:54 - Finished task 0.0 in stage 3.0 (TID 3) in 66 ms on localhost (1/1)
2016-10-12 21:30:32 INFO  TaskSchedulerImpl:54 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2016-10-12 21:30:32 INFO  DAGScheduler:54 - Job 1 finished: count at a1.scala:34, took 3.299409 s
2016-10-12 21:30:32 INFO  SparkContext:54 - Starting job: collect at a1.scala:35
2016-10-12 21:30:32 INFO  DAGScheduler:54 - Registering RDD 10 (map at a1.scala:35)
2016-10-12 21:30:32 INFO  DAGScheduler:54 - Got job 2 (collect at a1.scala:35) with 1 output partitions
2016-10-12 21:30:32 INFO  DAGScheduler:54 - Final stage: ResultStage 5 (collect at a1.scala:35)
2016-10-12 21:30:32 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 4)
2016-10-12 21:30:32 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 4)
2016-10-12 21:30:32 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 4 (MapPartitionsRDD[10] at map at a1.scala:35), which has no missing parents
2016-10-12 21:30:32 INFO  MemoryStore:54 - Block broadcast_5 stored as values in memory (estimated size 4.0 KB, free 366.0 MB)
2016-10-12 21:30:32 INFO  MemoryStore:54 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.4 KB, free 366.0 MB)
2016-10-12 21:30:32 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on 150.212.30.95:40555 (size: 2.4 KB, free: 366.3 MB)
2016-10-12 21:30:32 INFO  SparkContext:54 - Created broadcast 5 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:30:32 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[10] at map at a1.scala:35)
2016-10-12 21:30:32 INFO  TaskSchedulerImpl:54 - Adding task set 4.0 with 1 tasks
2016-10-12 21:30:32 INFO  TaskSetManager:54 - Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5592 bytes)
2016-10-12 21:30:32 INFO  Executor:54 - Running task 0.0 in stage 4.0 (TID 4)
2016-10-12 21:30:32 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 21:30:32 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 21:30:32 INFO  BlockManagerInfo:54 - Removed broadcast_4_piece0 on 150.212.30.95:40555 in memory (size: 2.2 KB, free: 366.3 MB)
2016-10-12 21:30:32 INFO  ContextCleaner:54 - Cleaned shuffle 1
2016-10-12 21:30:32 INFO  BlockManagerInfo:54 - Removed broadcast_3_piece0 on 150.212.30.95:40555 in memory (size: 2.5 KB, free: 366.3 MB)
2016-10-12 21:30:35 INFO  Executor:54 - Finished task 0.0 in stage 4.0 (TID 4). 1490 bytes result sent to driver
2016-10-12 21:30:35 INFO  TaskSetManager:54 - Finished task 0.0 in stage 4.0 (TID 4) in 3084 ms on localhost (1/1)
2016-10-12 21:30:35 INFO  DAGScheduler:54 - ShuffleMapStage 4 (map at a1.scala:35) finished in 3.083 s
2016-10-12 21:30:35 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 21:30:35 INFO  TaskSchedulerImpl:54 - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2016-10-12 21:30:35 INFO  DAGScheduler:54 - running: Set()
2016-10-12 21:30:35 INFO  DAGScheduler:54 - waiting: Set(ResultStage 5)
2016-10-12 21:30:35 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 21:30:35 INFO  DAGScheduler:54 - Submitting ResultStage 5 (MapPartitionsRDD[13] at map at a1.scala:35), which has no missing parents
2016-10-12 21:30:35 INFO  MemoryStore:54 - Block broadcast_6 stored as values in memory (estimated size 3.8 KB, free 366.0 MB)
2016-10-12 21:30:35 INFO  MemoryStore:54 - Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.2 KB, free 366.0 MB)
2016-10-12 21:30:35 INFO  BlockManagerInfo:54 - Added broadcast_6_piece0 in memory on 150.212.30.95:40555 (size: 2.2 KB, free: 366.3 MB)
2016-10-12 21:30:35 INFO  SparkContext:54 - Created broadcast 6 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:30:35 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[13] at map at a1.scala:35)
2016-10-12 21:30:35 INFO  TaskSchedulerImpl:54 - Adding task set 5.0 with 1 tasks
2016-10-12 21:30:35 INFO  TaskSetManager:54 - Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, ANY, 5262 bytes)
2016-10-12 21:30:35 INFO  Executor:54 - Running task 0.0 in stage 5.0 (TID 5)
2016-10-12 21:30:35 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 21:30:35 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2016-10-12 21:30:35 INFO  Executor:54 - Finished task 0.0 in stage 5.0 (TID 5). 9861 bytes result sent to driver
2016-10-12 21:30:35 INFO  DAGScheduler:54 - ResultStage 5 (collect at a1.scala:35) finished in 0.052 s
2016-10-12 21:30:35 INFO  TaskSetManager:54 - Finished task 0.0 in stage 5.0 (TID 5) in 56 ms on localhost (1/1)
2016-10-12 21:30:35 INFO  DAGScheduler:54 - Job 2 finished: collect at a1.scala:35, took 3.195786 s
2016-10-12 21:30:35 INFO  TaskSchedulerImpl:54 - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2016-10-12 21:30:35 INFO  SparkContext:54 - Starting job: collect at a1.scala:47
2016-10-12 21:30:35 INFO  DAGScheduler:54 - Registering RDD 16 (map at a1.scala:42)
2016-10-12 21:30:35 INFO  DAGScheduler:54 - Got job 3 (collect at a1.scala:47) with 1 output partitions
2016-10-12 21:30:35 INFO  DAGScheduler:54 - Final stage: ResultStage 7 (collect at a1.scala:47)
2016-10-12 21:30:35 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 6)
2016-10-12 21:30:35 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 6)
2016-10-12 21:30:35 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 6 (MapPartitionsRDD[16] at map at a1.scala:42), which has no missing parents
2016-10-12 21:30:35 INFO  MemoryStore:54 - Block broadcast_7 stored as values in memory (estimated size 45.6 KB, free 366.0 MB)
2016-10-12 21:30:35 INFO  MemoryStore:54 - Block broadcast_7_piece0 stored as bytes in memory (estimated size 21.5 KB, free 365.9 MB)
2016-10-12 21:30:35 INFO  BlockManagerInfo:54 - Added broadcast_7_piece0 in memory on 150.212.30.95:40555 (size: 21.5 KB, free: 366.3 MB)
2016-10-12 21:30:35 INFO  SparkContext:54 - Created broadcast 7 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:30:35 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[16] at map at a1.scala:42)
2016-10-12 21:30:35 INFO  TaskSchedulerImpl:54 - Adding task set 6.0 with 1 tasks
2016-10-12 21:30:35 INFO  TaskSetManager:54 - Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, PROCESS_LOCAL, 5592 bytes)
2016-10-12 21:30:35 INFO  Executor:54 - Running task 0.0 in stage 6.0 (TID 6)
2016-10-12 21:30:35 INFO  ContextCleaner:54 - Cleaned shuffle 2
2016-10-12 21:30:35 INFO  BlockManagerInfo:54 - Removed broadcast_5_piece0 on 150.212.30.95:40555 in memory (size: 2.4 KB, free: 366.3 MB)
2016-10-12 21:30:35 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 21:30:35 INFO  BlockManagerInfo:54 - Removed broadcast_6_piece0 on 150.212.30.95:40555 in memory (size: 2.2 KB, free: 366.3 MB)
2016-10-12 21:30:35 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 21:30:39 INFO  Executor:54 - Finished task 0.0 in stage 6.0 (TID 6). 1490 bytes result sent to driver
2016-10-12 21:30:39 INFO  TaskSetManager:54 - Finished task 0.0 in stage 6.0 (TID 6) in 4349 ms on localhost (1/1)
2016-10-12 21:30:39 INFO  DAGScheduler:54 - ShuffleMapStage 6 (map at a1.scala:42) finished in 4.350 s
2016-10-12 21:30:39 INFO  TaskSchedulerImpl:54 - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2016-10-12 21:30:39 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 21:30:39 INFO  DAGScheduler:54 - running: Set()
2016-10-12 21:30:39 INFO  DAGScheduler:54 - waiting: Set(ResultStage 7)
2016-10-12 21:30:39 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 21:30:39 INFO  DAGScheduler:54 - Submitting ResultStage 7 (ShuffledRDD[17] at reduceByKey at a1.scala:42), which has no missing parents
2016-10-12 21:30:39 INFO  MemoryStore:54 - Block broadcast_8 stored as values in memory (estimated size 3.1 KB, free 365.9 MB)
2016-10-12 21:30:39 INFO  MemoryStore:54 - Block broadcast_8_piece0 stored as bytes in memory (estimated size 1901.0 B, free 365.9 MB)
2016-10-12 21:30:39 INFO  BlockManagerInfo:54 - Added broadcast_8_piece0 in memory on 150.212.30.95:40555 (size: 1901.0 B, free: 366.3 MB)
2016-10-12 21:30:39 INFO  SparkContext:54 - Created broadcast 8 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:30:39 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 7 (ShuffledRDD[17] at reduceByKey at a1.scala:42)
2016-10-12 21:30:39 INFO  TaskSchedulerImpl:54 - Adding task set 7.0 with 1 tasks
2016-10-12 21:30:39 INFO  TaskSetManager:54 - Starting task 0.0 in stage 7.0 (TID 7, localhost, partition 0, ANY, 5262 bytes)
2016-10-12 21:30:39 INFO  Executor:54 - Running task 0.0 in stage 7.0 (TID 7)
2016-10-12 21:30:39 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 21:30:39 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2016-10-12 21:30:40 INFO  MemoryStore:54 - Block taskresult_7 stored as bytes in memory (estimated size 4.5 MB, free 361.4 MB)
2016-10-12 21:30:40 INFO  BlockManagerInfo:54 - Added taskresult_7 in memory on 150.212.30.95:40555 (size: 4.5 MB, free: 361.8 MB)
2016-10-12 21:30:40 INFO  Executor:54 - Finished task 0.0 in stage 7.0 (TID 7). 4714208 bytes result sent via BlockManager)
2016-10-12 21:30:40 INFO  TransportClientFactory:250 - Successfully created connection to /150.212.30.95:40555 after 6 ms (0 ms spent in bootstraps)
2016-10-12 21:30:40 INFO  BlockManagerInfo:54 - Removed taskresult_7 on 150.212.30.95:40555 in memory (size: 4.5 MB, free: 366.3 MB)
2016-10-12 21:30:40 INFO  TaskSetManager:54 - Finished task 0.0 in stage 7.0 (TID 7) in 200 ms on localhost (1/1)
2016-10-12 21:30:40 INFO  DAGScheduler:54 - ResultStage 7 (collect at a1.scala:47) finished in 0.221 s
2016-10-12 21:30:40 INFO  DAGScheduler:54 - Job 3 finished: collect at a1.scala:47, took 4.627566 s
2016-10-12 21:30:40 INFO  TaskSchedulerImpl:54 - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2016-10-12 21:30:40 INFO  SparkContext:54 - Starting job: takeSample at a1.scala:69
2016-10-12 21:30:40 INFO  MapOutputTrackerMaster:54 - Size of output statuses for shuffle 3 is 148 bytes
2016-10-12 21:30:40 INFO  DAGScheduler:54 - Got job 4 (takeSample at a1.scala:69) with 1 output partitions
2016-10-12 21:30:40 INFO  DAGScheduler:54 - Final stage: ResultStage 9 (takeSample at a1.scala:69)
2016-10-12 21:30:40 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 8)
2016-10-12 21:30:40 INFO  DAGScheduler:54 - Missing parents: List()
2016-10-12 21:30:40 INFO  DAGScheduler:54 - Submitting ResultStage 9 (ShuffledRDD[17] at reduceByKey at a1.scala:42), which has no missing parents
2016-10-12 21:30:40 INFO  MemoryStore:54 - Block broadcast_9 stored as values in memory (estimated size 2.9 KB, free 365.9 MB)
2016-10-12 21:30:40 INFO  MemoryStore:54 - Block broadcast_9_piece0 stored as bytes in memory (estimated size 1853.0 B, free 365.9 MB)
2016-10-12 21:30:40 INFO  BlockManagerInfo:54 - Added broadcast_9_piece0 in memory on 150.212.30.95:40555 (size: 1853.0 B, free: 366.3 MB)
2016-10-12 21:30:40 INFO  SparkContext:54 - Created broadcast 9 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:30:40 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 9 (ShuffledRDD[17] at reduceByKey at a1.scala:42)
2016-10-12 21:30:40 INFO  TaskSchedulerImpl:54 - Adding task set 9.0 with 1 tasks
2016-10-12 21:30:40 INFO  TaskSetManager:54 - Starting task 0.0 in stage 9.0 (TID 8, localhost, partition 0, ANY, 5265 bytes)
2016-10-12 21:30:40 INFO  Executor:54 - Running task 0.0 in stage 9.0 (TID 8)
2016-10-12 21:30:40 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 21:30:40 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2016-10-12 21:30:40 INFO  Executor:54 - Finished task 0.0 in stage 9.0 (TID 8). 1512 bytes result sent to driver
2016-10-12 21:30:40 INFO  TaskSetManager:54 - Finished task 0.0 in stage 9.0 (TID 8) in 45 ms on localhost (1/1)
2016-10-12 21:30:40 INFO  DAGScheduler:54 - ResultStage 9 (takeSample at a1.scala:69) finished in 0.036 s
2016-10-12 21:30:40 INFO  DAGScheduler:54 - Job 4 finished: takeSample at a1.scala:69, took 0.071306 s
2016-10-12 21:30:40 INFO  TaskSchedulerImpl:54 - Removed TaskSet 9.0, whose tasks have all completed, from pool 
2016-10-12 21:30:40 INFO  SparkContext:54 - Starting job: takeSample at a1.scala:69
2016-10-12 21:30:40 INFO  DAGScheduler:54 - Got job 5 (takeSample at a1.scala:69) with 1 output partitions
2016-10-12 21:30:40 INFO  DAGScheduler:54 - Final stage: ResultStage 11 (takeSample at a1.scala:69)
2016-10-12 21:30:40 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 10)
2016-10-12 21:30:40 INFO  DAGScheduler:54 - Missing parents: List()
2016-10-12 21:30:40 INFO  DAGScheduler:54 - Submitting ResultStage 11 (PartitionwiseSampledRDD[18] at takeSample at a1.scala:69), which has no missing parents
2016-10-12 21:30:40 INFO  MemoryStore:54 - Block broadcast_10 stored as values in memory (estimated size 3.8 KB, free 365.9 MB)
2016-10-12 21:30:40 INFO  MemoryStore:54 - Block broadcast_10_piece0 stored as bytes in memory (estimated size 2.3 KB, free 365.9 MB)
2016-10-12 21:30:40 INFO  BlockManagerInfo:54 - Added broadcast_10_piece0 in memory on 150.212.30.95:40555 (size: 2.3 KB, free: 366.3 MB)
2016-10-12 21:30:40 INFO  SparkContext:54 - Created broadcast 10 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:30:40 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 11 (PartitionwiseSampledRDD[18] at takeSample at a1.scala:69)
2016-10-12 21:30:40 INFO  TaskSchedulerImpl:54 - Adding task set 11.0 with 1 tasks
2016-10-12 21:30:40 INFO  TaskSetManager:54 - Starting task 0.0 in stage 11.0 (TID 9, localhost, partition 0, ANY, 5374 bytes)
2016-10-12 21:30:40 INFO  Executor:54 - Running task 0.0 in stage 11.0 (TID 9)
2016-10-12 21:30:40 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 21:30:40 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2016-10-12 21:30:40 INFO  Executor:54 - Finished task 0.0 in stage 11.0 (TID 9). 125822 bytes result sent to driver
2016-10-12 21:30:40 INFO  TaskSetManager:54 - Finished task 0.0 in stage 11.0 (TID 9) in 54 ms on localhost (1/1)
2016-10-12 21:30:40 INFO  DAGScheduler:54 - ResultStage 11 (takeSample at a1.scala:69) finished in 0.052 s
2016-10-12 21:30:40 INFO  DAGScheduler:54 - Job 5 finished: takeSample at a1.scala:69, took 0.073679 s
2016-10-12 21:30:40 INFO  TaskSchedulerImpl:54 - Removed TaskSet 11.0, whose tasks have all completed, from pool 
2016-10-12 21:30:40 INFO  SparkContext:54 - Starting job: collect at a1.scala:71
2016-10-12 21:30:40 INFO  DAGScheduler:54 - Got job 6 (collect at a1.scala:71) with 1 output partitions
2016-10-12 21:30:40 INFO  DAGScheduler:54 - Final stage: ResultStage 13 (collect at a1.scala:71)
2016-10-12 21:30:40 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 12)
2016-10-12 21:30:40 INFO  DAGScheduler:54 - Missing parents: List()
2016-10-12 21:30:40 INFO  DAGScheduler:54 - Submitting ResultStage 13 (MapPartitionsRDD[19] at map at a1.scala:71), which has no missing parents
2016-10-12 21:30:40 INFO  MemoryStore:54 - Block broadcast_11 stored as values in memory (estimated size 3.5 KB, free 365.9 MB)
2016-10-12 21:30:40 INFO  MemoryStore:54 - Block broadcast_11_piece0 stored as bytes in memory (estimated size 2.1 KB, free 365.9 MB)
2016-10-12 21:30:40 INFO  BlockManagerInfo:54 - Added broadcast_11_piece0 in memory on 150.212.30.95:40555 (size: 2.1 KB, free: 366.2 MB)
2016-10-12 21:30:40 INFO  SparkContext:54 - Created broadcast 11 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:30:40 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[19] at map at a1.scala:71)
2016-10-12 21:30:40 INFO  TaskSchedulerImpl:54 - Adding task set 13.0 with 1 tasks
2016-10-12 21:30:40 INFO  TaskSetManager:54 - Starting task 0.0 in stage 13.0 (TID 10, localhost, partition 0, ANY, 5262 bytes)
2016-10-12 21:30:40 INFO  Executor:54 - Running task 0.0 in stage 13.0 (TID 10)
2016-10-12 21:30:40 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 21:30:40 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2016-10-12 21:30:40 INFO  MemoryStore:54 - Block taskresult_10 stored as bytes in memory (estimated size 4.5 MB, free 361.5 MB)
2016-10-12 21:30:40 INFO  BlockManagerInfo:54 - Added taskresult_10 in memory on 150.212.30.95:40555 (size: 4.5 MB, free: 361.8 MB)
2016-10-12 21:30:40 INFO  Executor:54 - Finished task 0.0 in stage 13.0 (TID 10). 4684342 bytes result sent via BlockManager)
2016-10-12 21:30:40 INFO  BlockManagerInfo:54 - Removed taskresult_10 on 150.212.30.95:40555 in memory (size: 4.5 MB, free: 366.2 MB)
2016-10-12 21:30:40 INFO  TaskSetManager:54 - Finished task 0.0 in stage 13.0 (TID 10) in 84 ms on localhost (1/1)
2016-10-12 21:30:40 INFO  DAGScheduler:54 - ResultStage 13 (collect at a1.scala:71) finished in 0.103 s
2016-10-12 21:30:40 INFO  DAGScheduler:54 - Job 6 finished: collect at a1.scala:71, took 0.119403 s
2016-10-12 21:30:40 INFO  TaskSchedulerImpl:54 - Removed TaskSet 13.0, whose tasks have all completed, from pool 
2016-10-12 21:30:40 INFO  BlockManagerInfo:54 - Removed broadcast_7_piece0 on 150.212.30.95:40555 in memory (size: 21.5 KB, free: 366.3 MB)
2016-10-12 21:30:40 INFO  BlockManagerInfo:54 - Removed broadcast_8_piece0 on 150.212.30.95:40555 in memory (size: 1901.0 B, free: 366.3 MB)
2016-10-12 21:30:40 INFO  BlockManagerInfo:54 - Removed broadcast_9_piece0 on 150.212.30.95:40555 in memory (size: 1853.0 B, free: 366.3 MB)
2016-10-12 21:30:40 INFO  BlockManagerInfo:54 - Removed broadcast_10_piece0 on 150.212.30.95:40555 in memory (size: 2.3 KB, free: 366.3 MB)
2016-10-12 21:30:40 INFO  BlockManagerInfo:54 - Removed broadcast_11_piece0 on 150.212.30.95:40555 in memory (size: 2.1 KB, free: 366.3 MB)
2016-10-12 21:30:41 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2016-10-12 21:30:41 INFO  ServerConnector:306 - Stopped ServerConnector@6c67e137{HTTP/1.1}{0.0.0.0:4041}
2016-10-12 21:30:41 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,UNAVAILABLE}
2016-10-12 21:30:41 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@62e70ea3{/api,null,UNAVAILABLE}
2016-10-12 21:30:41 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@28276e50{/,null,UNAVAILABLE}
2016-10-12 21:30:41 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a7471ce{/static,null,UNAVAILABLE}
2016-10-12 21:30:41 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,UNAVAILABLE}
2016-10-12 21:30:41 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,UNAVAILABLE}
2016-10-12 21:30:41 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,UNAVAILABLE}
2016-10-12 21:30:41 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@297ea53a{/executors,null,UNAVAILABLE}
2016-10-12 21:30:41 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,UNAVAILABLE}
2016-10-12 21:30:41 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4052274f{/environment,null,UNAVAILABLE}
2016-10-12 21:30:41 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,UNAVAILABLE}
2016-10-12 21:30:41 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,UNAVAILABLE}
2016-10-12 21:30:41 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,UNAVAILABLE}
2016-10-12 21:30:41 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1643d68f{/storage,null,UNAVAILABLE}
2016-10-12 21:30:41 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,UNAVAILABLE}
2016-10-12 21:30:41 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,UNAVAILABLE}
2016-10-12 21:30:41 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,UNAVAILABLE}
2016-10-12 21:30:41 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,UNAVAILABLE}
2016-10-12 21:30:41 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,UNAVAILABLE}
2016-10-12 21:30:41 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,UNAVAILABLE}
2016-10-12 21:30:41 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,UNAVAILABLE}
2016-10-12 21:30:41 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,UNAVAILABLE}
2016-10-12 21:30:41 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,UNAVAILABLE}
2016-10-12 21:30:41 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,UNAVAILABLE}
2016-10-12 21:30:41 INFO  SparkUI:54 - Stopped Spark web UI at http://150.212.30.95:4041
2016-10-12 21:30:41 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2016-10-12 21:30:41 INFO  MemoryStore:54 - MemoryStore cleared
2016-10-12 21:30:41 INFO  BlockManager:54 - BlockManager stopped
2016-10-12 21:30:41 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2016-10-12 21:30:41 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2016-10-12 21:30:41 INFO  SparkContext:54 - Successfully stopped SparkContext
2016-10-12 21:30:41 INFO  ShutdownHookManager:54 - Shutdown hook called
2016-10-12 21:30:41 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-d094434c-bcda-46c1-8b8a-70a313476653
2016-10-12 21:35:02 INFO  SparkContext:54 - Running Spark version 2.0.0
2016-10-12 21:35:02 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-12 21:35:02 WARN  Utils:66 - Your hostname, aadu-XPS-13-9350 resolves to a loopback address: 127.0.1.1; using 150.212.30.95 instead (on interface wlp58s0)
2016-10-12 21:35:02 WARN  Utils:66 - Set SPARK_LOCAL_IP if you need to bind to another address
2016-10-12 21:35:02 INFO  SecurityManager:54 - Changing view acls to: aadu
2016-10-12 21:35:02 INFO  SecurityManager:54 - Changing modify acls to: aadu
2016-10-12 21:35:02 INFO  SecurityManager:54 - Changing view acls groups to: 
2016-10-12 21:35:02 INFO  SecurityManager:54 - Changing modify acls groups to: 
2016-10-12 21:35:02 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(aadu); groups with view permissions: Set(); users  with modify permissions: Set(aadu); groups with modify permissions: Set()
2016-10-12 21:35:02 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 46416.
2016-10-12 21:35:02 INFO  SparkEnv:54 - Registering MapOutputTracker
2016-10-12 21:35:02 INFO  SparkEnv:54 - Registering BlockManagerMaster
2016-10-12 21:35:02 INFO  DiskBlockManager:54 - Created local directory at /tmp/blockmgr-52ae8a68-00e8-4097-8e7e-ed8610d1cd79
2016-10-12 21:35:02 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2016-10-12 21:35:02 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2016-10-12 21:35:02 INFO  log:186 - Logging initialized @1400ms
2016-10-12 21:35:03 INFO  Server:327 - jetty-9.2.z-SNAPSHOT
2016-10-12 21:35:03 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,AVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,AVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,AVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,AVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,AVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,AVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,AVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,AVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,AVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,AVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1643d68f{/storage,null,AVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,AVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,AVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,AVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4052274f{/environment,null,AVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,AVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@297ea53a{/executors,null,AVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,AVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,AVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,AVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a7471ce{/static,null,AVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@28276e50{/,null,AVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@62e70ea3{/api,null,AVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,AVAILABLE}
2016-10-12 21:35:03 WARN  AbstractLifeCycle:212 - FAILED ServerConnector@4fe89c24{HTTP/1.1}{0.0.0.0:4040}: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2071)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2062)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:139)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:451)
	at Assign1$.main(a1.scala:20)
	at Assign1.main(a1.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2016-10-12 21:35:03 WARN  AbstractLifeCycle:212 - FAILED org.spark_project.jetty.server.Server@6175619b: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2071)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2062)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:139)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:451)
	at Assign1$.main(a1.scala:20)
	at Assign1.main(a1.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2016-10-12 21:35:03 INFO  ServerConnector:306 - Stopped ServerConnector@4fe89c24{HTTP/1.1}{0.0.0.0:4040}
2016-10-12 21:35:03 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,UNAVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@62e70ea3{/api,null,UNAVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@28276e50{/,null,UNAVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a7471ce{/static,null,UNAVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,UNAVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,UNAVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,UNAVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@297ea53a{/executors,null,UNAVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,UNAVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4052274f{/environment,null,UNAVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,UNAVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,UNAVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,UNAVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1643d68f{/storage,null,UNAVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,UNAVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,UNAVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,UNAVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,UNAVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,UNAVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,UNAVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,UNAVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,UNAVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,UNAVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,UNAVAILABLE}
2016-10-12 21:35:03 WARN  Utils:66 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2016-10-12 21:35:03 INFO  Server:327 - jetty-9.2.z-SNAPSHOT
2016-10-12 21:35:03 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,AVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,AVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,AVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,AVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,AVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,AVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,AVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,AVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,AVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,AVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1643d68f{/storage,null,AVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,AVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,AVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,AVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4052274f{/environment,null,AVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,AVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@297ea53a{/executors,null,AVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,AVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,AVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,AVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a7471ce{/static,null,AVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@28276e50{/,null,AVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@62e70ea3{/api,null,AVAILABLE}
2016-10-12 21:35:03 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,AVAILABLE}
2016-10-12 21:35:03 INFO  ServerConnector:266 - Started ServerConnector@6c67e137{HTTP/1.1}{0.0.0.0:4041}
2016-10-12 21:35:03 INFO  Server:379 - Started @1564ms
2016-10-12 21:35:03 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4041.
2016-10-12 21:35:03 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://150.212.30.95:4041
2016-10-12 21:35:03 INFO  SparkContext:54 - Added JAR file:/home/aadu/Repos/adam/adam-assembly/target/adam_2.11-0.19.1-SNAPSHOT.jar at spark://150.212.30.95:46416/jars/adam_2.11-0.19.1-SNAPSHOT.jar with timestamp 1476322503174
2016-10-12 21:35:03 INFO  SparkContext:54 - Added JAR file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/a1.jar at spark://150.212.30.95:46416/jars/a1.jar with timestamp 1476322503174
2016-10-12 21:35:03 INFO  Executor:54 - Starting executor ID driver on host localhost
2016-10-12 21:35:03 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34044.
2016-10-12 21:35:03 INFO  NettyBlockTransferService:54 - Server created on 150.212.30.95:34044
2016-10-12 21:35:03 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 150.212.30.95, 34044)
2016-10-12 21:35:03 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 150.212.30.95:34044 with 366.3 MB RAM, BlockManagerId(driver, 150.212.30.95, 34044)
2016-10-12 21:35:03 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 150.212.30.95, 34044)
2016-10-12 21:35:03 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2472c7d8{/metrics/json,null,AVAILABLE}
2016-10-12 21:35:03 INFO  ADAMContext:1336 - Loading small.adam as Parquet containing Genotypes. Sequence dictionary for translation is ignored.
2016-10-12 21:35:03 INFO  ADAMContext:257 - Reading the ADAM file at small.adam to create RDD
2016-10-12 21:35:03 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 268.7 KB, free 366.0 MB)
2016-10-12 21:35:04 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 22.8 KB, free 366.0 MB)
2016-10-12 21:35:04 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 150.212.30.95:34044 (size: 22.8 KB, free: 366.3 MB)
2016-10-12 21:35:04 INFO  SparkContext:54 - Created broadcast 0 from newAPIHadoopFile at ADAMContext.scala:271
2016-10-12 21:35:04 INFO  FileInputFormat:283 - Total input paths to process : 1
2016-10-12 21:35:04 INFO  SparkContext:54 - Starting job: count at a1.scala:33
2016-10-12 21:35:04 INFO  DAGScheduler:54 - Registering RDD 3 (distinct at a1.scala:33)
2016-10-12 21:35:04 INFO  DAGScheduler:54 - Got job 0 (count at a1.scala:33) with 1 output partitions
2016-10-12 21:35:04 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (count at a1.scala:33)
2016-10-12 21:35:04 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 0)
2016-10-12 21:35:04 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 0)
2016-10-12 21:35:04 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at distinct at a1.scala:33), which has no missing parents
2016-10-12 21:35:04 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 4.2 KB, free 366.0 MB)
2016-10-12 21:35:04 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.5 KB, free 366.0 MB)
2016-10-12 21:35:04 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 150.212.30.95:34044 (size: 2.5 KB, free: 366.3 MB)
2016-10-12 21:35:04 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:35:04 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at distinct at a1.scala:33)
2016-10-12 21:35:04 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2016-10-12 21:35:04 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5507 bytes)
2016-10-12 21:35:04 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2016-10-12 21:35:04 INFO  Executor:54 - Fetching spark://150.212.30.95:46416/jars/a1.jar with timestamp 1476322503174
2016-10-12 21:35:04 INFO  TransportClientFactory:250 - Successfully created connection to /150.212.30.95:46416 after 25 ms (0 ms spent in bootstraps)
2016-10-12 21:35:05 INFO  Utils:54 - Fetching spark://150.212.30.95:46416/jars/a1.jar to /tmp/spark-8a2d9764-8b8a-45c2-99b9-5ae2d41d63df/userFiles-03ecc8dd-15d4-4939-ba73-cfdcaf9e6ba2/fetchFileTemp9101712680259707711.tmp
2016-10-12 21:35:05 INFO  Executor:54 - Adding file:/tmp/spark-8a2d9764-8b8a-45c2-99b9-5ae2d41d63df/userFiles-03ecc8dd-15d4-4939-ba73-cfdcaf9e6ba2/a1.jar to class loader
2016-10-12 21:35:05 INFO  Executor:54 - Fetching spark://150.212.30.95:46416/jars/adam_2.11-0.19.1-SNAPSHOT.jar with timestamp 1476322503174
2016-10-12 21:35:05 INFO  Utils:54 - Fetching spark://150.212.30.95:46416/jars/adam_2.11-0.19.1-SNAPSHOT.jar to /tmp/spark-8a2d9764-8b8a-45c2-99b9-5ae2d41d63df/userFiles-03ecc8dd-15d4-4939-ba73-cfdcaf9e6ba2/fetchFileTemp6235510787103098803.tmp
2016-10-12 21:35:05 INFO  Executor:54 - Adding file:/tmp/spark-8a2d9764-8b8a-45c2-99b9-5ae2d41d63df/userFiles-03ecc8dd-15d4-4939-ba73-cfdcaf9e6ba2/adam_2.11-0.19.1-SNAPSHOT.jar to class loader
2016-10-12 21:35:05 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 21:35:05 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 21:35:08 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1577 bytes result sent to driver
2016-10-12 21:35:08 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 4084 ms on localhost (1/1)
2016-10-12 21:35:08 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2016-10-12 21:35:08 INFO  DAGScheduler:54 - ShuffleMapStage 0 (distinct at a1.scala:33) finished in 4.098 s
2016-10-12 21:35:08 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 21:35:08 INFO  DAGScheduler:54 - running: Set()
2016-10-12 21:35:08 INFO  DAGScheduler:54 - waiting: Set(ResultStage 1)
2016-10-12 21:35:08 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 21:35:08 INFO  DAGScheduler:54 - Submitting ResultStage 1 (MapPartitionsRDD[5] at distinct at a1.scala:33), which has no missing parents
2016-10-12 21:35:08 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 3.7 KB, free 366.0 MB)
2016-10-12 21:35:09 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.2 KB, free 366.0 MB)
2016-10-12 21:35:09 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on 150.212.30.95:34044 (size: 2.2 KB, free: 366.3 MB)
2016-10-12 21:35:09 INFO  SparkContext:54 - Created broadcast 2 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:35:09 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at distinct at a1.scala:33)
2016-10-12 21:35:09 INFO  TaskSchedulerImpl:54 - Adding task set 1.0 with 1 tasks
2016-10-12 21:35:09 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, ANY, 5177 bytes)
2016-10-12 21:35:09 INFO  Executor:54 - Running task 0.0 in stage 1.0 (TID 1)
2016-10-12 21:35:09 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 21:35:09 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 4 ms
2016-10-12 21:35:09 INFO  Executor:54 - Finished task 0.0 in stage 1.0 (TID 1). 1512 bytes result sent to driver
2016-10-12 21:35:09 INFO  DAGScheduler:54 - ResultStage 1 (count at a1.scala:33) finished in 0.097 s
2016-10-12 21:35:09 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 1) in 97 ms on localhost (1/1)
2016-10-12 21:35:09 INFO  TaskSchedulerImpl:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2016-10-12 21:35:09 INFO  DAGScheduler:54 - Job 0 finished: count at a1.scala:33, took 4.386476 s
2016-10-12 21:35:09 INFO  SparkContext:54 - Starting job: count at a1.scala:34
2016-10-12 21:35:09 INFO  DAGScheduler:54 - Registering RDD 7 (distinct at a1.scala:34)
2016-10-12 21:35:09 INFO  DAGScheduler:54 - Got job 1 (count at a1.scala:34) with 1 output partitions
2016-10-12 21:35:09 INFO  DAGScheduler:54 - Final stage: ResultStage 3 (count at a1.scala:34)
2016-10-12 21:35:09 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 2)
2016-10-12 21:35:09 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 2)
2016-10-12 21:35:09 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 2 (MapPartitionsRDD[7] at distinct at a1.scala:34), which has no missing parents
2016-10-12 21:35:09 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 4.2 KB, free 366.0 MB)
2016-10-12 21:35:09 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.5 KB, free 366.0 MB)
2016-10-12 21:35:09 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on 150.212.30.95:34044 (size: 2.5 KB, free: 366.3 MB)
2016-10-12 21:35:09 INFO  SparkContext:54 - Created broadcast 3 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:35:09 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[7] at distinct at a1.scala:34)
2016-10-12 21:35:09 INFO  TaskSchedulerImpl:54 - Adding task set 2.0 with 1 tasks
2016-10-12 21:35:09 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5507 bytes)
2016-10-12 21:35:09 INFO  Executor:54 - Running task 0.0 in stage 2.0 (TID 2)
2016-10-12 21:35:09 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 21:35:09 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 21:35:09 INFO  BlockManagerInfo:54 - Removed broadcast_2_piece0 on 150.212.30.95:34044 in memory (size: 2.2 KB, free: 366.3 MB)
2016-10-12 21:35:09 INFO  ContextCleaner:54 - Cleaned shuffle 0
2016-10-12 21:35:09 INFO  BlockManagerInfo:54 - Removed broadcast_1_piece0 on 150.212.30.95:34044 in memory (size: 2.5 KB, free: 366.3 MB)
2016-10-12 21:35:12 INFO  Executor:54 - Finished task 0.0 in stage 2.0 (TID 2). 1490 bytes result sent to driver
2016-10-12 21:35:12 INFO  TaskSetManager:54 - Finished task 0.0 in stage 2.0 (TID 2) in 3267 ms on localhost (1/1)
2016-10-12 21:35:12 INFO  DAGScheduler:54 - ShuffleMapStage 2 (distinct at a1.scala:34) finished in 3.270 s
2016-10-12 21:35:12 INFO  TaskSchedulerImpl:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2016-10-12 21:35:12 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 21:35:12 INFO  DAGScheduler:54 - running: Set()
2016-10-12 21:35:12 INFO  DAGScheduler:54 - waiting: Set(ResultStage 3)
2016-10-12 21:35:12 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 21:35:12 INFO  DAGScheduler:54 - Submitting ResultStage 3 (MapPartitionsRDD[9] at distinct at a1.scala:34), which has no missing parents
2016-10-12 21:35:12 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 3.8 KB, free 366.0 MB)
2016-10-12 21:35:12 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.2 KB, free 366.0 MB)
2016-10-12 21:35:12 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on 150.212.30.95:34044 (size: 2.2 KB, free: 366.3 MB)
2016-10-12 21:35:12 INFO  SparkContext:54 - Created broadcast 4 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:35:12 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[9] at distinct at a1.scala:34)
2016-10-12 21:35:12 INFO  TaskSchedulerImpl:54 - Adding task set 3.0 with 1 tasks
2016-10-12 21:35:12 INFO  TaskSetManager:54 - Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, ANY, 5177 bytes)
2016-10-12 21:35:12 INFO  Executor:54 - Running task 0.0 in stage 3.0 (TID 3)
2016-10-12 21:35:12 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 21:35:12 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 2 ms
2016-10-12 21:35:12 INFO  Executor:54 - Finished task 0.0 in stage 3.0 (TID 3). 1512 bytes result sent to driver
2016-10-12 21:35:12 INFO  DAGScheduler:54 - ResultStage 3 (count at a1.scala:34) finished in 0.058 s
2016-10-12 21:35:12 INFO  DAGScheduler:54 - Job 1 finished: count at a1.scala:34, took 3.390200 s
2016-10-12 21:35:12 INFO  TaskSetManager:54 - Finished task 0.0 in stage 3.0 (TID 3) in 58 ms on localhost (1/1)
2016-10-12 21:35:12 INFO  TaskSchedulerImpl:54 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2016-10-12 21:35:12 INFO  SparkContext:54 - Starting job: collect at a1.scala:35
2016-10-12 21:35:12 INFO  DAGScheduler:54 - Registering RDD 10 (map at a1.scala:35)
2016-10-12 21:35:12 INFO  DAGScheduler:54 - Got job 2 (collect at a1.scala:35) with 1 output partitions
2016-10-12 21:35:12 INFO  DAGScheduler:54 - Final stage: ResultStage 5 (collect at a1.scala:35)
2016-10-12 21:35:12 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 4)
2016-10-12 21:35:12 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 4)
2016-10-12 21:35:12 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 4 (MapPartitionsRDD[10] at map at a1.scala:35), which has no missing parents
2016-10-12 21:35:12 INFO  MemoryStore:54 - Block broadcast_5 stored as values in memory (estimated size 4.0 KB, free 366.0 MB)
2016-10-12 21:35:12 INFO  MemoryStore:54 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.4 KB, free 366.0 MB)
2016-10-12 21:35:12 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on 150.212.30.95:34044 (size: 2.4 KB, free: 366.3 MB)
2016-10-12 21:35:12 INFO  SparkContext:54 - Created broadcast 5 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:35:12 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[10] at map at a1.scala:35)
2016-10-12 21:35:12 INFO  TaskSchedulerImpl:54 - Adding task set 4.0 with 1 tasks
2016-10-12 21:35:12 INFO  TaskSetManager:54 - Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5592 bytes)
2016-10-12 21:35:12 INFO  Executor:54 - Running task 0.0 in stage 4.0 (TID 4)
2016-10-12 21:35:12 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 21:35:12 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 21:35:13 INFO  BlockManagerInfo:54 - Removed broadcast_4_piece0 on 150.212.30.95:34044 in memory (size: 2.2 KB, free: 366.3 MB)
2016-10-12 21:35:13 INFO  ContextCleaner:54 - Cleaned shuffle 1
2016-10-12 21:35:13 INFO  BlockManagerInfo:54 - Removed broadcast_3_piece0 on 150.212.30.95:34044 in memory (size: 2.5 KB, free: 366.3 MB)
2016-10-12 21:35:15 INFO  Executor:54 - Finished task 0.0 in stage 4.0 (TID 4). 1490 bytes result sent to driver
2016-10-12 21:35:15 INFO  DAGScheduler:54 - ShuffleMapStage 4 (map at a1.scala:35) finished in 3.050 s
2016-10-12 21:35:15 INFO  TaskSetManager:54 - Finished task 0.0 in stage 4.0 (TID 4) in 3050 ms on localhost (1/1)
2016-10-12 21:35:15 INFO  TaskSchedulerImpl:54 - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2016-10-12 21:35:15 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 21:35:15 INFO  DAGScheduler:54 - running: Set()
2016-10-12 21:35:15 INFO  DAGScheduler:54 - waiting: Set(ResultStage 5)
2016-10-12 21:35:15 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 21:35:15 INFO  DAGScheduler:54 - Submitting ResultStage 5 (MapPartitionsRDD[13] at map at a1.scala:35), which has no missing parents
2016-10-12 21:35:15 INFO  MemoryStore:54 - Block broadcast_6 stored as values in memory (estimated size 3.8 KB, free 366.0 MB)
2016-10-12 21:35:15 INFO  MemoryStore:54 - Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.2 KB, free 366.0 MB)
2016-10-12 21:35:15 INFO  BlockManagerInfo:54 - Added broadcast_6_piece0 in memory on 150.212.30.95:34044 (size: 2.2 KB, free: 366.3 MB)
2016-10-12 21:35:15 INFO  SparkContext:54 - Created broadcast 6 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:35:15 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[13] at map at a1.scala:35)
2016-10-12 21:35:15 INFO  TaskSchedulerImpl:54 - Adding task set 5.0 with 1 tasks
2016-10-12 21:35:15 INFO  TaskSetManager:54 - Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, ANY, 5262 bytes)
2016-10-12 21:35:15 INFO  Executor:54 - Running task 0.0 in stage 5.0 (TID 5)
2016-10-12 21:35:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 21:35:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 2 ms
2016-10-12 21:35:15 INFO  Executor:54 - Finished task 0.0 in stage 5.0 (TID 5). 9861 bytes result sent to driver
2016-10-12 21:35:15 INFO  TaskSetManager:54 - Finished task 0.0 in stage 5.0 (TID 5) in 53 ms on localhost (1/1)
2016-10-12 21:35:15 INFO  DAGScheduler:54 - ResultStage 5 (collect at a1.scala:35) finished in 0.050 s
2016-10-12 21:35:15 INFO  DAGScheduler:54 - Job 2 finished: collect at a1.scala:35, took 3.148753 s
2016-10-12 21:35:15 INFO  TaskSchedulerImpl:54 - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2016-10-12 21:35:15 INFO  SparkContext:54 - Starting job: collect at a1.scala:47
2016-10-12 21:35:15 INFO  DAGScheduler:54 - Registering RDD 16 (map at a1.scala:42)
2016-10-12 21:35:15 INFO  DAGScheduler:54 - Got job 3 (collect at a1.scala:47) with 1 output partitions
2016-10-12 21:35:15 INFO  DAGScheduler:54 - Final stage: ResultStage 7 (collect at a1.scala:47)
2016-10-12 21:35:15 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 6)
2016-10-12 21:35:15 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 6)
2016-10-12 21:35:15 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 6 (MapPartitionsRDD[16] at map at a1.scala:42), which has no missing parents
2016-10-12 21:35:15 INFO  MemoryStore:54 - Block broadcast_7 stored as values in memory (estimated size 45.6 KB, free 366.0 MB)
2016-10-12 21:35:15 INFO  MemoryStore:54 - Block broadcast_7_piece0 stored as bytes in memory (estimated size 21.5 KB, free 365.9 MB)
2016-10-12 21:35:15 INFO  BlockManagerInfo:54 - Added broadcast_7_piece0 in memory on 150.212.30.95:34044 (size: 21.5 KB, free: 366.3 MB)
2016-10-12 21:35:15 INFO  SparkContext:54 - Created broadcast 7 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:35:15 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[16] at map at a1.scala:42)
2016-10-12 21:35:15 INFO  TaskSchedulerImpl:54 - Adding task set 6.0 with 1 tasks
2016-10-12 21:35:15 INFO  TaskSetManager:54 - Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, PROCESS_LOCAL, 5592 bytes)
2016-10-12 21:35:15 INFO  Executor:54 - Running task 0.0 in stage 6.0 (TID 6)
2016-10-12 21:35:15 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 21:35:15 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 21:35:16 INFO  ContextCleaner:54 - Cleaned shuffle 2
2016-10-12 21:35:16 INFO  BlockManagerInfo:54 - Removed broadcast_5_piece0 on 150.212.30.95:34044 in memory (size: 2.4 KB, free: 366.3 MB)
2016-10-12 21:35:16 INFO  BlockManagerInfo:54 - Removed broadcast_6_piece0 on 150.212.30.95:34044 in memory (size: 2.2 KB, free: 366.3 MB)
2016-10-12 21:35:19 INFO  Executor:54 - Finished task 0.0 in stage 6.0 (TID 6). 1490 bytes result sent to driver
2016-10-12 21:35:19 INFO  TaskSetManager:54 - Finished task 0.0 in stage 6.0 (TID 6) in 4180 ms on localhost (1/1)
2016-10-12 21:35:19 INFO  TaskSchedulerImpl:54 - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2016-10-12 21:35:19 INFO  DAGScheduler:54 - ShuffleMapStage 6 (map at a1.scala:42) finished in 4.181 s
2016-10-12 21:35:19 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 21:35:19 INFO  DAGScheduler:54 - running: Set()
2016-10-12 21:35:19 INFO  DAGScheduler:54 - waiting: Set(ResultStage 7)
2016-10-12 21:35:19 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 21:35:19 INFO  DAGScheduler:54 - Submitting ResultStage 7 (ShuffledRDD[17] at reduceByKey at a1.scala:42), which has no missing parents
2016-10-12 21:35:19 INFO  MemoryStore:54 - Block broadcast_8 stored as values in memory (estimated size 3.1 KB, free 365.9 MB)
2016-10-12 21:35:19 INFO  MemoryStore:54 - Block broadcast_8_piece0 stored as bytes in memory (estimated size 1901.0 B, free 365.9 MB)
2016-10-12 21:35:19 INFO  BlockManagerInfo:54 - Added broadcast_8_piece0 in memory on 150.212.30.95:34044 (size: 1901.0 B, free: 366.3 MB)
2016-10-12 21:35:19 INFO  SparkContext:54 - Created broadcast 8 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:35:19 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 7 (ShuffledRDD[17] at reduceByKey at a1.scala:42)
2016-10-12 21:35:19 INFO  TaskSchedulerImpl:54 - Adding task set 7.0 with 1 tasks
2016-10-12 21:35:20 INFO  TaskSetManager:54 - Starting task 0.0 in stage 7.0 (TID 7, localhost, partition 0, ANY, 5262 bytes)
2016-10-12 21:35:20 INFO  Executor:54 - Running task 0.0 in stage 7.0 (TID 7)
2016-10-12 21:35:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 21:35:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2016-10-12 21:35:20 INFO  MemoryStore:54 - Block taskresult_7 stored as bytes in memory (estimated size 4.5 MB, free 361.4 MB)
2016-10-12 21:35:20 INFO  BlockManagerInfo:54 - Added taskresult_7 in memory on 150.212.30.95:34044 (size: 4.5 MB, free: 361.8 MB)
2016-10-12 21:35:20 INFO  Executor:54 - Finished task 0.0 in stage 7.0 (TID 7). 4714208 bytes result sent via BlockManager)
2016-10-12 21:35:20 INFO  TransportClientFactory:250 - Successfully created connection to /150.212.30.95:34044 after 5 ms (0 ms spent in bootstraps)
2016-10-12 21:35:20 INFO  BlockManagerInfo:54 - Removed taskresult_7 on 150.212.30.95:34044 in memory (size: 4.5 MB, free: 366.3 MB)
2016-10-12 21:35:20 INFO  DAGScheduler:54 - ResultStage 7 (collect at a1.scala:47) finished in 0.229 s
2016-10-12 21:35:20 INFO  DAGScheduler:54 - Job 3 finished: collect at a1.scala:47, took 4.463400 s
2016-10-12 21:35:20 INFO  TaskSetManager:54 - Finished task 0.0 in stage 7.0 (TID 7) in 200 ms on localhost (1/1)
2016-10-12 21:35:20 INFO  TaskSchedulerImpl:54 - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2016-10-12 21:35:20 INFO  SparkContext:54 - Starting job: takeSample at a1.scala:69
2016-10-12 21:35:20 INFO  MapOutputTrackerMaster:54 - Size of output statuses for shuffle 3 is 148 bytes
2016-10-12 21:35:20 INFO  DAGScheduler:54 - Got job 4 (takeSample at a1.scala:69) with 1 output partitions
2016-10-12 21:35:20 INFO  DAGScheduler:54 - Final stage: ResultStage 9 (takeSample at a1.scala:69)
2016-10-12 21:35:20 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 8)
2016-10-12 21:35:20 INFO  DAGScheduler:54 - Missing parents: List()
2016-10-12 21:35:20 INFO  DAGScheduler:54 - Submitting ResultStage 9 (ShuffledRDD[17] at reduceByKey at a1.scala:42), which has no missing parents
2016-10-12 21:35:20 INFO  MemoryStore:54 - Block broadcast_9 stored as values in memory (estimated size 2.9 KB, free 365.9 MB)
2016-10-12 21:35:20 INFO  MemoryStore:54 - Block broadcast_9_piece0 stored as bytes in memory (estimated size 1853.0 B, free 365.9 MB)
2016-10-12 21:35:20 INFO  BlockManagerInfo:54 - Added broadcast_9_piece0 in memory on 150.212.30.95:34044 (size: 1853.0 B, free: 366.3 MB)
2016-10-12 21:35:20 INFO  SparkContext:54 - Created broadcast 9 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:35:20 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 9 (ShuffledRDD[17] at reduceByKey at a1.scala:42)
2016-10-12 21:35:20 INFO  TaskSchedulerImpl:54 - Adding task set 9.0 with 1 tasks
2016-10-12 21:35:20 INFO  TaskSetManager:54 - Starting task 0.0 in stage 9.0 (TID 8, localhost, partition 0, ANY, 5265 bytes)
2016-10-12 21:35:20 INFO  Executor:54 - Running task 0.0 in stage 9.0 (TID 8)
2016-10-12 21:35:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 21:35:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2016-10-12 21:35:20 INFO  Executor:54 - Finished task 0.0 in stage 9.0 (TID 8). 1512 bytes result sent to driver
2016-10-12 21:35:20 INFO  DAGScheduler:54 - ResultStage 9 (takeSample at a1.scala:69) finished in 0.057 s
2016-10-12 21:35:20 INFO  DAGScheduler:54 - Job 4 finished: takeSample at a1.scala:69, took 0.086206 s
2016-10-12 21:35:20 INFO  TaskSetManager:54 - Finished task 0.0 in stage 9.0 (TID 8) in 56 ms on localhost (1/1)
2016-10-12 21:35:20 INFO  TaskSchedulerImpl:54 - Removed TaskSet 9.0, whose tasks have all completed, from pool 
2016-10-12 21:35:20 INFO  SparkContext:54 - Starting job: takeSample at a1.scala:69
2016-10-12 21:35:20 INFO  DAGScheduler:54 - Got job 5 (takeSample at a1.scala:69) with 1 output partitions
2016-10-12 21:35:20 INFO  DAGScheduler:54 - Final stage: ResultStage 11 (takeSample at a1.scala:69)
2016-10-12 21:35:20 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 10)
2016-10-12 21:35:20 INFO  DAGScheduler:54 - Missing parents: List()
2016-10-12 21:35:20 INFO  DAGScheduler:54 - Submitting ResultStage 11 (PartitionwiseSampledRDD[18] at takeSample at a1.scala:69), which has no missing parents
2016-10-12 21:35:20 INFO  MemoryStore:54 - Block broadcast_10 stored as values in memory (estimated size 3.8 KB, free 365.9 MB)
2016-10-12 21:35:20 INFO  MemoryStore:54 - Block broadcast_10_piece0 stored as bytes in memory (estimated size 2.3 KB, free 365.9 MB)
2016-10-12 21:35:20 INFO  BlockManagerInfo:54 - Added broadcast_10_piece0 in memory on 150.212.30.95:34044 (size: 2.3 KB, free: 366.3 MB)
2016-10-12 21:35:20 INFO  SparkContext:54 - Created broadcast 10 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:35:20 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 11 (PartitionwiseSampledRDD[18] at takeSample at a1.scala:69)
2016-10-12 21:35:20 INFO  TaskSchedulerImpl:54 - Adding task set 11.0 with 1 tasks
2016-10-12 21:35:20 INFO  TaskSetManager:54 - Starting task 0.0 in stage 11.0 (TID 9, localhost, partition 0, ANY, 5374 bytes)
2016-10-12 21:35:20 INFO  Executor:54 - Running task 0.0 in stage 11.0 (TID 9)
2016-10-12 21:35:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 21:35:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2016-10-12 21:35:20 INFO  Executor:54 - Finished task 0.0 in stage 11.0 (TID 9). 96965 bytes result sent to driver
2016-10-12 21:35:20 INFO  TaskSetManager:54 - Finished task 0.0 in stage 11.0 (TID 9) in 61 ms on localhost (1/1)
2016-10-12 21:35:20 INFO  DAGScheduler:54 - ResultStage 11 (takeSample at a1.scala:69) finished in 0.062 s
2016-10-12 21:35:20 INFO  DAGScheduler:54 - Job 5 finished: takeSample at a1.scala:69, took 0.087785 s
2016-10-12 21:35:20 INFO  TaskSchedulerImpl:54 - Removed TaskSet 11.0, whose tasks have all completed, from pool 
2016-10-12 21:35:20 INFO  SparkContext:54 - Starting job: collect at a1.scala:71
2016-10-12 21:35:20 INFO  DAGScheduler:54 - Got job 6 (collect at a1.scala:71) with 1 output partitions
2016-10-12 21:35:20 INFO  DAGScheduler:54 - Final stage: ResultStage 13 (collect at a1.scala:71)
2016-10-12 21:35:20 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 12)
2016-10-12 21:35:20 INFO  DAGScheduler:54 - Missing parents: List()
2016-10-12 21:35:20 INFO  DAGScheduler:54 - Submitting ResultStage 13 (MapPartitionsRDD[19] at map at a1.scala:71), which has no missing parents
2016-10-12 21:35:20 INFO  MemoryStore:54 - Block broadcast_11 stored as values in memory (estimated size 3.5 KB, free 365.9 MB)
2016-10-12 21:35:20 INFO  MemoryStore:54 - Block broadcast_11_piece0 stored as bytes in memory (estimated size 2.1 KB, free 365.9 MB)
2016-10-12 21:35:20 INFO  BlockManagerInfo:54 - Added broadcast_11_piece0 in memory on 150.212.30.95:34044 (size: 2.1 KB, free: 366.2 MB)
2016-10-12 21:35:20 INFO  SparkContext:54 - Created broadcast 11 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:35:20 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[19] at map at a1.scala:71)
2016-10-12 21:35:20 INFO  TaskSchedulerImpl:54 - Adding task set 13.0 with 1 tasks
2016-10-12 21:35:20 INFO  TaskSetManager:54 - Starting task 0.0 in stage 13.0 (TID 10, localhost, partition 0, ANY, 5262 bytes)
2016-10-12 21:35:20 INFO  Executor:54 - Running task 0.0 in stage 13.0 (TID 10)
2016-10-12 21:35:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 21:35:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2016-10-12 21:35:20 INFO  MemoryStore:54 - Block taskresult_10 stored as bytes in memory (estimated size 4.5 MB, free 361.5 MB)
2016-10-12 21:35:20 INFO  BlockManagerInfo:54 - Added taskresult_10 in memory on 150.212.30.95:34044 (size: 4.5 MB, free: 361.8 MB)
2016-10-12 21:35:20 INFO  Executor:54 - Finished task 0.0 in stage 13.0 (TID 10). 4684342 bytes result sent via BlockManager)
2016-10-12 21:35:20 INFO  BlockManagerInfo:54 - Removed taskresult_10 on 150.212.30.95:34044 in memory (size: 4.5 MB, free: 366.2 MB)
2016-10-12 21:35:20 INFO  TaskSetManager:54 - Finished task 0.0 in stage 13.0 (TID 10) in 86 ms on localhost (1/1)
2016-10-12 21:35:20 INFO  DAGScheduler:54 - ResultStage 13 (collect at a1.scala:71) finished in 0.100 s
2016-10-12 21:35:20 INFO  DAGScheduler:54 - Job 6 finished: collect at a1.scala:71, took 0.120164 s
2016-10-12 21:35:20 INFO  TaskSchedulerImpl:54 - Removed TaskSet 13.0, whose tasks have all completed, from pool 
2016-10-12 21:35:20 INFO  BlockManagerInfo:54 - Removed broadcast_11_piece0 on 150.212.30.95:34044 in memory (size: 2.1 KB, free: 366.3 MB)
2016-10-12 21:35:20 INFO  BlockManagerInfo:54 - Removed broadcast_7_piece0 on 150.212.30.95:34044 in memory (size: 21.5 KB, free: 366.3 MB)
2016-10-12 21:35:20 INFO  BlockManagerInfo:54 - Removed broadcast_8_piece0 on 150.212.30.95:34044 in memory (size: 1901.0 B, free: 366.3 MB)
2016-10-12 21:35:20 INFO  BlockManagerInfo:54 - Removed broadcast_9_piece0 on 150.212.30.95:34044 in memory (size: 1853.0 B, free: 366.3 MB)
2016-10-12 21:35:20 INFO  BlockManagerInfo:54 - Removed broadcast_10_piece0 on 150.212.30.95:34044 in memory (size: 2.3 KB, free: 366.3 MB)
2016-10-12 21:35:21 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2016-10-12 21:35:21 INFO  ServerConnector:306 - Stopped ServerConnector@6c67e137{HTTP/1.1}{0.0.0.0:4041}
2016-10-12 21:35:21 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,UNAVAILABLE}
2016-10-12 21:35:21 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@62e70ea3{/api,null,UNAVAILABLE}
2016-10-12 21:35:21 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@28276e50{/,null,UNAVAILABLE}
2016-10-12 21:35:21 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a7471ce{/static,null,UNAVAILABLE}
2016-10-12 21:35:21 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,UNAVAILABLE}
2016-10-12 21:35:21 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,UNAVAILABLE}
2016-10-12 21:35:21 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,UNAVAILABLE}
2016-10-12 21:35:21 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@297ea53a{/executors,null,UNAVAILABLE}
2016-10-12 21:35:21 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,UNAVAILABLE}
2016-10-12 21:35:21 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4052274f{/environment,null,UNAVAILABLE}
2016-10-12 21:35:21 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,UNAVAILABLE}
2016-10-12 21:35:21 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,UNAVAILABLE}
2016-10-12 21:35:21 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,UNAVAILABLE}
2016-10-12 21:35:21 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1643d68f{/storage,null,UNAVAILABLE}
2016-10-12 21:35:21 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,UNAVAILABLE}
2016-10-12 21:35:21 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,UNAVAILABLE}
2016-10-12 21:35:21 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,UNAVAILABLE}
2016-10-12 21:35:21 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,UNAVAILABLE}
2016-10-12 21:35:21 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,UNAVAILABLE}
2016-10-12 21:35:21 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,UNAVAILABLE}
2016-10-12 21:35:21 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,UNAVAILABLE}
2016-10-12 21:35:21 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,UNAVAILABLE}
2016-10-12 21:35:21 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,UNAVAILABLE}
2016-10-12 21:35:21 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,UNAVAILABLE}
2016-10-12 21:35:21 INFO  SparkUI:54 - Stopped Spark web UI at http://150.212.30.95:4041
2016-10-12 21:35:21 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2016-10-12 21:35:21 INFO  MemoryStore:54 - MemoryStore cleared
2016-10-12 21:35:21 INFO  BlockManager:54 - BlockManager stopped
2016-10-12 21:35:21 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2016-10-12 21:35:21 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2016-10-12 21:35:21 INFO  SparkContext:54 - Successfully stopped SparkContext
2016-10-12 21:35:21 INFO  ShutdownHookManager:54 - Shutdown hook called
2016-10-12 21:35:21 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-8a2d9764-8b8a-45c2-99b9-5ae2d41d63df
2016-10-12 21:36:06 INFO  SparkContext:54 - Running Spark version 2.0.0
2016-10-12 21:36:06 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-12 21:36:07 WARN  Utils:66 - Your hostname, aadu-XPS-13-9350 resolves to a loopback address: 127.0.1.1; using 150.212.30.95 instead (on interface wlp58s0)
2016-10-12 21:36:07 WARN  Utils:66 - Set SPARK_LOCAL_IP if you need to bind to another address
2016-10-12 21:36:07 INFO  SecurityManager:54 - Changing view acls to: aadu
2016-10-12 21:36:07 INFO  SecurityManager:54 - Changing modify acls to: aadu
2016-10-12 21:36:07 INFO  SecurityManager:54 - Changing view acls groups to: 
2016-10-12 21:36:07 INFO  SecurityManager:54 - Changing modify acls groups to: 
2016-10-12 21:36:07 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(aadu); groups with view permissions: Set(); users  with modify permissions: Set(aadu); groups with modify permissions: Set()
2016-10-12 21:36:07 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 44057.
2016-10-12 21:36:07 INFO  SparkEnv:54 - Registering MapOutputTracker
2016-10-12 21:36:07 INFO  SparkEnv:54 - Registering BlockManagerMaster
2016-10-12 21:36:07 INFO  DiskBlockManager:54 - Created local directory at /tmp/blockmgr-f0be8f7b-8d0b-4b42-a861-3ac43c5d0ec2
2016-10-12 21:36:07 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2016-10-12 21:36:07 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2016-10-12 21:36:07 INFO  log:186 - Logging initialized @1398ms
2016-10-12 21:36:07 INFO  Server:327 - jetty-9.2.z-SNAPSHOT
2016-10-12 21:36:07 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,AVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,AVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,AVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,AVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,AVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,AVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,AVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,AVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,AVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,AVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1643d68f{/storage,null,AVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,AVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,AVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,AVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4052274f{/environment,null,AVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,AVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@297ea53a{/executors,null,AVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,AVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,AVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,AVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a7471ce{/static,null,AVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@28276e50{/,null,AVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@62e70ea3{/api,null,AVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,AVAILABLE}
2016-10-12 21:36:07 WARN  AbstractLifeCycle:212 - FAILED ServerConnector@4fe89c24{HTTP/1.1}{0.0.0.0:4040}: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2071)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2062)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:139)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:451)
	at Assign1$.main(a1.scala:20)
	at Assign1.main(a1.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2016-10-12 21:36:07 WARN  AbstractLifeCycle:212 - FAILED org.spark_project.jetty.server.Server@6175619b: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2071)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2062)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:139)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:451)
	at Assign1$.main(a1.scala:20)
	at Assign1.main(a1.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2016-10-12 21:36:07 INFO  ServerConnector:306 - Stopped ServerConnector@4fe89c24{HTTP/1.1}{0.0.0.0:4040}
2016-10-12 21:36:07 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,UNAVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@62e70ea3{/api,null,UNAVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@28276e50{/,null,UNAVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a7471ce{/static,null,UNAVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,UNAVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,UNAVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,UNAVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@297ea53a{/executors,null,UNAVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,UNAVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4052274f{/environment,null,UNAVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,UNAVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,UNAVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,UNAVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1643d68f{/storage,null,UNAVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,UNAVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,UNAVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,UNAVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,UNAVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,UNAVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,UNAVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,UNAVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,UNAVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,UNAVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,UNAVAILABLE}
2016-10-12 21:36:07 WARN  Utils:66 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2016-10-12 21:36:07 INFO  Server:327 - jetty-9.2.z-SNAPSHOT
2016-10-12 21:36:07 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,AVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,AVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,AVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,AVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,AVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,AVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,AVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,AVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,AVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,AVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1643d68f{/storage,null,AVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,AVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,AVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,AVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4052274f{/environment,null,AVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,AVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@297ea53a{/executors,null,AVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,AVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,AVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,AVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a7471ce{/static,null,AVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@28276e50{/,null,AVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@62e70ea3{/api,null,AVAILABLE}
2016-10-12 21:36:07 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,AVAILABLE}
2016-10-12 21:36:07 INFO  ServerConnector:266 - Started ServerConnector@6c67e137{HTTP/1.1}{0.0.0.0:4041}
2016-10-12 21:36:07 INFO  Server:379 - Started @1550ms
2016-10-12 21:36:07 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4041.
2016-10-12 21:36:07 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://150.212.30.95:4041
2016-10-12 21:36:07 INFO  SparkContext:54 - Added JAR file:/home/aadu/Repos/adam/adam-assembly/target/adam_2.11-0.19.1-SNAPSHOT.jar at spark://150.212.30.95:44057/jars/adam_2.11-0.19.1-SNAPSHOT.jar with timestamp 1476322567717
2016-10-12 21:36:07 INFO  SparkContext:54 - Added JAR file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/a1.jar at spark://150.212.30.95:44057/jars/a1.jar with timestamp 1476322567718
2016-10-12 21:36:07 INFO  Executor:54 - Starting executor ID driver on host localhost
2016-10-12 21:36:07 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43700.
2016-10-12 21:36:07 INFO  NettyBlockTransferService:54 - Server created on 150.212.30.95:43700
2016-10-12 21:36:07 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 150.212.30.95, 43700)
2016-10-12 21:36:07 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 150.212.30.95:43700 with 366.3 MB RAM, BlockManagerId(driver, 150.212.30.95, 43700)
2016-10-12 21:36:07 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 150.212.30.95, 43700)
2016-10-12 21:36:07 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2472c7d8{/metrics/json,null,AVAILABLE}
2016-10-12 21:36:08 INFO  ADAMContext:1336 - Loading small.adam as Parquet containing Genotypes. Sequence dictionary for translation is ignored.
2016-10-12 21:36:08 INFO  ADAMContext:257 - Reading the ADAM file at small.adam to create RDD
2016-10-12 21:36:08 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 268.7 KB, free 366.0 MB)
2016-10-12 21:36:09 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 22.8 KB, free 366.0 MB)
2016-10-12 21:36:09 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 150.212.30.95:43700 (size: 22.8 KB, free: 366.3 MB)
2016-10-12 21:36:09 INFO  SparkContext:54 - Created broadcast 0 from newAPIHadoopFile at ADAMContext.scala:271
2016-10-12 21:36:09 INFO  FileInputFormat:283 - Total input paths to process : 1
2016-10-12 21:36:09 INFO  SparkContext:54 - Starting job: count at a1.scala:33
2016-10-12 21:36:09 INFO  DAGScheduler:54 - Registering RDD 3 (distinct at a1.scala:33)
2016-10-12 21:36:09 INFO  DAGScheduler:54 - Got job 0 (count at a1.scala:33) with 1 output partitions
2016-10-12 21:36:09 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (count at a1.scala:33)
2016-10-12 21:36:09 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 0)
2016-10-12 21:36:09 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 0)
2016-10-12 21:36:09 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at distinct at a1.scala:33), which has no missing parents
2016-10-12 21:36:09 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 4.2 KB, free 366.0 MB)
2016-10-12 21:36:09 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.5 KB, free 366.0 MB)
2016-10-12 21:36:09 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 150.212.30.95:43700 (size: 2.5 KB, free: 366.3 MB)
2016-10-12 21:36:09 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:36:09 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at distinct at a1.scala:33)
2016-10-12 21:36:09 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2016-10-12 21:36:09 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5507 bytes)
2016-10-12 21:36:09 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2016-10-12 21:36:09 INFO  Executor:54 - Fetching spark://150.212.30.95:44057/jars/a1.jar with timestamp 1476322567718
2016-10-12 21:36:09 INFO  TransportClientFactory:250 - Successfully created connection to /150.212.30.95:44057 after 30 ms (0 ms spent in bootstraps)
2016-10-12 21:36:09 INFO  Utils:54 - Fetching spark://150.212.30.95:44057/jars/a1.jar to /tmp/spark-84a062fd-52b7-45cc-8d84-84478c1c224b/userFiles-390f5225-54d2-41c3-ba39-eb2b49df45f2/fetchFileTemp7486934913220119618.tmp
2016-10-12 21:36:09 INFO  Executor:54 - Adding file:/tmp/spark-84a062fd-52b7-45cc-8d84-84478c1c224b/userFiles-390f5225-54d2-41c3-ba39-eb2b49df45f2/a1.jar to class loader
2016-10-12 21:36:09 INFO  Executor:54 - Fetching spark://150.212.30.95:44057/jars/adam_2.11-0.19.1-SNAPSHOT.jar with timestamp 1476322567717
2016-10-12 21:36:09 INFO  Utils:54 - Fetching spark://150.212.30.95:44057/jars/adam_2.11-0.19.1-SNAPSHOT.jar to /tmp/spark-84a062fd-52b7-45cc-8d84-84478c1c224b/userFiles-390f5225-54d2-41c3-ba39-eb2b49df45f2/fetchFileTemp5929523855337186901.tmp
2016-10-12 21:36:09 INFO  Executor:54 - Adding file:/tmp/spark-84a062fd-52b7-45cc-8d84-84478c1c224b/userFiles-390f5225-54d2-41c3-ba39-eb2b49df45f2/adam_2.11-0.19.1-SNAPSHOT.jar to class loader
2016-10-12 21:36:09 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 21:36:09 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 21:36:13 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1490 bytes result sent to driver
2016-10-12 21:36:13 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 4302 ms on localhost (1/1)
2016-10-12 21:36:13 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2016-10-12 21:36:13 INFO  DAGScheduler:54 - ShuffleMapStage 0 (distinct at a1.scala:33) finished in 4.317 s
2016-10-12 21:36:13 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 21:36:13 INFO  DAGScheduler:54 - running: Set()
2016-10-12 21:36:13 INFO  DAGScheduler:54 - waiting: Set(ResultStage 1)
2016-10-12 21:36:13 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 21:36:13 INFO  DAGScheduler:54 - Submitting ResultStage 1 (MapPartitionsRDD[5] at distinct at a1.scala:33), which has no missing parents
2016-10-12 21:36:13 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 3.7 KB, free 366.0 MB)
2016-10-12 21:36:13 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.2 KB, free 366.0 MB)
2016-10-12 21:36:13 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on 150.212.30.95:43700 (size: 2.2 KB, free: 366.3 MB)
2016-10-12 21:36:13 INFO  SparkContext:54 - Created broadcast 2 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:36:13 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at distinct at a1.scala:33)
2016-10-12 21:36:13 INFO  TaskSchedulerImpl:54 - Adding task set 1.0 with 1 tasks
2016-10-12 21:36:13 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, ANY, 5177 bytes)
2016-10-12 21:36:13 INFO  Executor:54 - Running task 0.0 in stage 1.0 (TID 1)
2016-10-12 21:36:13 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 21:36:13 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 4 ms
2016-10-12 21:36:13 INFO  Executor:54 - Finished task 0.0 in stage 1.0 (TID 1). 1512 bytes result sent to driver
2016-10-12 21:36:13 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 1) in 98 ms on localhost (1/1)
2016-10-12 21:36:13 INFO  DAGScheduler:54 - ResultStage 1 (count at a1.scala:33) finished in 0.099 s
2016-10-12 21:36:13 INFO  TaskSchedulerImpl:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2016-10-12 21:36:13 INFO  DAGScheduler:54 - Job 0 finished: count at a1.scala:33, took 4.586496 s
2016-10-12 21:36:13 INFO  SparkContext:54 - Starting job: count at a1.scala:34
2016-10-12 21:36:13 INFO  DAGScheduler:54 - Registering RDD 7 (distinct at a1.scala:34)
2016-10-12 21:36:13 INFO  DAGScheduler:54 - Got job 1 (count at a1.scala:34) with 1 output partitions
2016-10-12 21:36:13 INFO  DAGScheduler:54 - Final stage: ResultStage 3 (count at a1.scala:34)
2016-10-12 21:36:13 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 2)
2016-10-12 21:36:13 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 2)
2016-10-12 21:36:13 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 2 (MapPartitionsRDD[7] at distinct at a1.scala:34), which has no missing parents
2016-10-12 21:36:13 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 4.2 KB, free 366.0 MB)
2016-10-12 21:36:13 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.5 KB, free 366.0 MB)
2016-10-12 21:36:13 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on 150.212.30.95:43700 (size: 2.5 KB, free: 366.3 MB)
2016-10-12 21:36:13 INFO  SparkContext:54 - Created broadcast 3 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:36:13 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[7] at distinct at a1.scala:34)
2016-10-12 21:36:13 INFO  TaskSchedulerImpl:54 - Adding task set 2.0 with 1 tasks
2016-10-12 21:36:13 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5507 bytes)
2016-10-12 21:36:13 INFO  Executor:54 - Running task 0.0 in stage 2.0 (TID 2)
2016-10-12 21:36:13 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 21:36:14 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 21:36:14 INFO  ContextCleaner:54 - Cleaned shuffle 0
2016-10-12 21:36:14 INFO  BlockManagerInfo:54 - Removed broadcast_1_piece0 on 150.212.30.95:43700 in memory (size: 2.5 KB, free: 366.3 MB)
2016-10-12 21:36:14 INFO  BlockManagerInfo:54 - Removed broadcast_2_piece0 on 150.212.30.95:43700 in memory (size: 2.2 KB, free: 366.3 MB)
2016-10-12 21:36:17 INFO  Executor:54 - Finished task 0.0 in stage 2.0 (TID 2). 1490 bytes result sent to driver
2016-10-12 21:36:17 INFO  DAGScheduler:54 - ShuffleMapStage 2 (distinct at a1.scala:34) finished in 3.288 s
2016-10-12 21:36:17 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 21:36:17 INFO  DAGScheduler:54 - running: Set()
2016-10-12 21:36:17 INFO  DAGScheduler:54 - waiting: Set(ResultStage 3)
2016-10-12 21:36:17 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 21:36:17 INFO  DAGScheduler:54 - Submitting ResultStage 3 (MapPartitionsRDD[9] at distinct at a1.scala:34), which has no missing parents
2016-10-12 21:36:17 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 3.8 KB, free 366.0 MB)
2016-10-12 21:36:17 INFO  TaskSetManager:54 - Finished task 0.0 in stage 2.0 (TID 2) in 3288 ms on localhost (1/1)
2016-10-12 21:36:17 INFO  TaskSchedulerImpl:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2016-10-12 21:36:17 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.2 KB, free 366.0 MB)
2016-10-12 21:36:17 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on 150.212.30.95:43700 (size: 2.2 KB, free: 366.3 MB)
2016-10-12 21:36:17 INFO  SparkContext:54 - Created broadcast 4 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:36:17 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[9] at distinct at a1.scala:34)
2016-10-12 21:36:17 INFO  TaskSchedulerImpl:54 - Adding task set 3.0 with 1 tasks
2016-10-12 21:36:17 INFO  TaskSetManager:54 - Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, ANY, 5177 bytes)
2016-10-12 21:36:17 INFO  Executor:54 - Running task 0.0 in stage 3.0 (TID 3)
2016-10-12 21:36:17 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 21:36:17 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2016-10-12 21:36:17 INFO  Executor:54 - Finished task 0.0 in stage 3.0 (TID 3). 1512 bytes result sent to driver
2016-10-12 21:36:17 INFO  TaskSetManager:54 - Finished task 0.0 in stage 3.0 (TID 3) in 49 ms on localhost (1/1)
2016-10-12 21:36:17 INFO  DAGScheduler:54 - ResultStage 3 (count at a1.scala:34) finished in 0.033 s
2016-10-12 21:36:17 INFO  DAGScheduler:54 - Job 1 finished: count at a1.scala:34, took 3.395159 s
2016-10-12 21:36:17 INFO  TaskSchedulerImpl:54 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2016-10-12 21:36:17 INFO  SparkContext:54 - Starting job: collect at a1.scala:35
2016-10-12 21:36:17 INFO  DAGScheduler:54 - Registering RDD 10 (map at a1.scala:35)
2016-10-12 21:36:17 INFO  DAGScheduler:54 - Got job 2 (collect at a1.scala:35) with 1 output partitions
2016-10-12 21:36:17 INFO  DAGScheduler:54 - Final stage: ResultStage 5 (collect at a1.scala:35)
2016-10-12 21:36:17 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 4)
2016-10-12 21:36:17 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 4)
2016-10-12 21:36:17 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 4 (MapPartitionsRDD[10] at map at a1.scala:35), which has no missing parents
2016-10-12 21:36:17 INFO  MemoryStore:54 - Block broadcast_5 stored as values in memory (estimated size 4.0 KB, free 366.0 MB)
2016-10-12 21:36:17 INFO  MemoryStore:54 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.4 KB, free 366.0 MB)
2016-10-12 21:36:17 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on 150.212.30.95:43700 (size: 2.4 KB, free: 366.3 MB)
2016-10-12 21:36:17 INFO  SparkContext:54 - Created broadcast 5 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:36:17 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[10] at map at a1.scala:35)
2016-10-12 21:36:17 INFO  TaskSchedulerImpl:54 - Adding task set 4.0 with 1 tasks
2016-10-12 21:36:17 INFO  TaskSetManager:54 - Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5592 bytes)
2016-10-12 21:36:17 INFO  Executor:54 - Running task 0.0 in stage 4.0 (TID 4)
2016-10-12 21:36:17 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 21:36:17 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 21:36:17 INFO  ContextCleaner:54 - Cleaned shuffle 1
2016-10-12 21:36:17 INFO  BlockManagerInfo:54 - Removed broadcast_3_piece0 on 150.212.30.95:43700 in memory (size: 2.5 KB, free: 366.3 MB)
2016-10-12 21:36:17 INFO  BlockManagerInfo:54 - Removed broadcast_4_piece0 on 150.212.30.95:43700 in memory (size: 2.2 KB, free: 366.3 MB)
2016-10-12 21:36:20 INFO  Executor:54 - Finished task 0.0 in stage 4.0 (TID 4). 1490 bytes result sent to driver
2016-10-12 21:36:20 INFO  TaskSetManager:54 - Finished task 0.0 in stage 4.0 (TID 4) in 3163 ms on localhost (1/1)
2016-10-12 21:36:20 INFO  DAGScheduler:54 - ShuffleMapStage 4 (map at a1.scala:35) finished in 3.164 s
2016-10-12 21:36:20 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 21:36:20 INFO  DAGScheduler:54 - running: Set()
2016-10-12 21:36:20 INFO  TaskSchedulerImpl:54 - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2016-10-12 21:36:20 INFO  DAGScheduler:54 - waiting: Set(ResultStage 5)
2016-10-12 21:36:20 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 21:36:20 INFO  DAGScheduler:54 - Submitting ResultStage 5 (MapPartitionsRDD[13] at map at a1.scala:35), which has no missing parents
2016-10-12 21:36:20 INFO  MemoryStore:54 - Block broadcast_6 stored as values in memory (estimated size 3.8 KB, free 366.0 MB)
2016-10-12 21:36:20 INFO  MemoryStore:54 - Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.2 KB, free 366.0 MB)
2016-10-12 21:36:20 INFO  BlockManagerInfo:54 - Added broadcast_6_piece0 in memory on 150.212.30.95:43700 (size: 2.2 KB, free: 366.3 MB)
2016-10-12 21:36:20 INFO  SparkContext:54 - Created broadcast 6 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:36:20 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[13] at map at a1.scala:35)
2016-10-12 21:36:20 INFO  TaskSchedulerImpl:54 - Adding task set 5.0 with 1 tasks
2016-10-12 21:36:20 INFO  TaskSetManager:54 - Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, ANY, 5262 bytes)
2016-10-12 21:36:20 INFO  Executor:54 - Running task 0.0 in stage 5.0 (TID 5)
2016-10-12 21:36:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 21:36:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 2 ms
2016-10-12 21:36:20 INFO  Executor:54 - Finished task 0.0 in stage 5.0 (TID 5). 9861 bytes result sent to driver
2016-10-12 21:36:20 INFO  DAGScheduler:54 - ResultStage 5 (collect at a1.scala:35) finished in 0.056 s
2016-10-12 21:36:20 INFO  DAGScheduler:54 - Job 2 finished: collect at a1.scala:35, took 3.268387 s
2016-10-12 21:36:20 INFO  TaskSetManager:54 - Finished task 0.0 in stage 5.0 (TID 5) in 55 ms on localhost (1/1)
2016-10-12 21:36:20 INFO  TaskSchedulerImpl:54 - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2016-10-12 21:36:20 INFO  SparkContext:54 - Starting job: collect at a1.scala:47
2016-10-12 21:36:20 INFO  DAGScheduler:54 - Registering RDD 16 (map at a1.scala:42)
2016-10-12 21:36:20 INFO  DAGScheduler:54 - Got job 3 (collect at a1.scala:47) with 1 output partitions
2016-10-12 21:36:20 INFO  DAGScheduler:54 - Final stage: ResultStage 7 (collect at a1.scala:47)
2016-10-12 21:36:20 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 6)
2016-10-12 21:36:20 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 6)
2016-10-12 21:36:20 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 6 (MapPartitionsRDD[16] at map at a1.scala:42), which has no missing parents
2016-10-12 21:36:20 INFO  MemoryStore:54 - Block broadcast_7 stored as values in memory (estimated size 45.6 KB, free 366.0 MB)
2016-10-12 21:36:20 INFO  MemoryStore:54 - Block broadcast_7_piece0 stored as bytes in memory (estimated size 21.5 KB, free 365.9 MB)
2016-10-12 21:36:20 INFO  BlockManagerInfo:54 - Added broadcast_7_piece0 in memory on 150.212.30.95:43700 (size: 21.5 KB, free: 366.3 MB)
2016-10-12 21:36:20 INFO  SparkContext:54 - Created broadcast 7 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:36:20 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[16] at map at a1.scala:42)
2016-10-12 21:36:20 INFO  TaskSchedulerImpl:54 - Adding task set 6.0 with 1 tasks
2016-10-12 21:36:20 INFO  TaskSetManager:54 - Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, PROCESS_LOCAL, 5592 bytes)
2016-10-12 21:36:20 INFO  Executor:54 - Running task 0.0 in stage 6.0 (TID 6)
2016-10-12 21:36:20 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 21:36:20 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 21:36:21 INFO  ContextCleaner:54 - Cleaned shuffle 2
2016-10-12 21:36:21 INFO  BlockManagerInfo:54 - Removed broadcast_5_piece0 on 150.212.30.95:43700 in memory (size: 2.4 KB, free: 366.3 MB)
2016-10-12 21:36:21 INFO  BlockManagerInfo:54 - Removed broadcast_6_piece0 on 150.212.30.95:43700 in memory (size: 2.2 KB, free: 366.3 MB)
2016-10-12 21:36:25 INFO  Executor:54 - Finished task 0.0 in stage 6.0 (TID 6). 1577 bytes result sent to driver
2016-10-12 21:36:25 INFO  TaskSetManager:54 - Finished task 0.0 in stage 6.0 (TID 6) in 4282 ms on localhost (1/1)
2016-10-12 21:36:25 INFO  DAGScheduler:54 - ShuffleMapStage 6 (map at a1.scala:42) finished in 4.283 s
2016-10-12 21:36:25 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 21:36:25 INFO  DAGScheduler:54 - running: Set()
2016-10-12 21:36:25 INFO  DAGScheduler:54 - waiting: Set(ResultStage 7)
2016-10-12 21:36:25 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 21:36:25 INFO  TaskSchedulerImpl:54 - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2016-10-12 21:36:25 INFO  DAGScheduler:54 - Submitting ResultStage 7 (ShuffledRDD[17] at reduceByKey at a1.scala:42), which has no missing parents
2016-10-12 21:36:25 INFO  MemoryStore:54 - Block broadcast_8 stored as values in memory (estimated size 3.1 KB, free 365.9 MB)
2016-10-12 21:36:25 INFO  MemoryStore:54 - Block broadcast_8_piece0 stored as bytes in memory (estimated size 1901.0 B, free 365.9 MB)
2016-10-12 21:36:25 INFO  BlockManagerInfo:54 - Added broadcast_8_piece0 in memory on 150.212.30.95:43700 (size: 1901.0 B, free: 366.3 MB)
2016-10-12 21:36:25 INFO  SparkContext:54 - Created broadcast 8 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:36:25 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 7 (ShuffledRDD[17] at reduceByKey at a1.scala:42)
2016-10-12 21:36:25 INFO  TaskSchedulerImpl:54 - Adding task set 7.0 with 1 tasks
2016-10-12 21:36:25 INFO  TaskSetManager:54 - Starting task 0.0 in stage 7.0 (TID 7, localhost, partition 0, ANY, 5262 bytes)
2016-10-12 21:36:25 INFO  Executor:54 - Running task 0.0 in stage 7.0 (TID 7)
2016-10-12 21:36:25 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 21:36:25 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2016-10-12 21:36:25 INFO  MemoryStore:54 - Block taskresult_7 stored as bytes in memory (estimated size 4.5 MB, free 361.4 MB)
2016-10-12 21:36:25 INFO  BlockManagerInfo:54 - Added taskresult_7 in memory on 150.212.30.95:43700 (size: 4.5 MB, free: 361.8 MB)
2016-10-12 21:36:25 INFO  Executor:54 - Finished task 0.0 in stage 7.0 (TID 7). 4714208 bytes result sent via BlockManager)
2016-10-12 21:36:25 INFO  TransportClientFactory:250 - Successfully created connection to /150.212.30.95:43700 after 1 ms (0 ms spent in bootstraps)
2016-10-12 21:36:25 INFO  BlockManagerInfo:54 - Removed taskresult_7 on 150.212.30.95:43700 in memory (size: 4.5 MB, free: 366.3 MB)
2016-10-12 21:36:25 INFO  DAGScheduler:54 - ResultStage 7 (collect at a1.scala:47) finished in 0.226 s
2016-10-12 21:36:25 INFO  DAGScheduler:54 - Job 3 finished: collect at a1.scala:47, took 4.553380 s
2016-10-12 21:36:25 INFO  SparkContext:54 - Starting job: takeSample at a1.scala:69
2016-10-12 21:36:25 INFO  TaskSetManager:54 - Finished task 0.0 in stage 7.0 (TID 7) in 209 ms on localhost (1/1)
2016-10-12 21:36:25 INFO  MapOutputTrackerMaster:54 - Size of output statuses for shuffle 3 is 148 bytes
2016-10-12 21:36:25 INFO  TaskSchedulerImpl:54 - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2016-10-12 21:36:25 INFO  DAGScheduler:54 - Got job 4 (takeSample at a1.scala:69) with 1 output partitions
2016-10-12 21:36:25 INFO  DAGScheduler:54 - Final stage: ResultStage 9 (takeSample at a1.scala:69)
2016-10-12 21:36:25 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 8)
2016-10-12 21:36:25 INFO  DAGScheduler:54 - Missing parents: List()
2016-10-12 21:36:25 INFO  DAGScheduler:54 - Submitting ResultStage 9 (ShuffledRDD[17] at reduceByKey at a1.scala:42), which has no missing parents
2016-10-12 21:36:25 INFO  MemoryStore:54 - Block broadcast_9 stored as values in memory (estimated size 2.9 KB, free 365.9 MB)
2016-10-12 21:36:25 INFO  MemoryStore:54 - Block broadcast_9_piece0 stored as bytes in memory (estimated size 1853.0 B, free 365.9 MB)
2016-10-12 21:36:25 INFO  BlockManagerInfo:54 - Removed broadcast_7_piece0 on 150.212.30.95:43700 in memory (size: 21.5 KB, free: 366.3 MB)
2016-10-12 21:36:25 INFO  BlockManagerInfo:54 - Added broadcast_9_piece0 in memory on 150.212.30.95:43700 (size: 1853.0 B, free: 366.3 MB)
2016-10-12 21:36:25 INFO  SparkContext:54 - Created broadcast 9 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:36:25 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 9 (ShuffledRDD[17] at reduceByKey at a1.scala:42)
2016-10-12 21:36:25 INFO  TaskSchedulerImpl:54 - Adding task set 9.0 with 1 tasks
2016-10-12 21:36:25 INFO  BlockManagerInfo:54 - Removed broadcast_8_piece0 on 150.212.30.95:43700 in memory (size: 1901.0 B, free: 366.3 MB)
2016-10-12 21:36:25 INFO  TaskSetManager:54 - Starting task 0.0 in stage 9.0 (TID 8, localhost, partition 0, ANY, 5265 bytes)
2016-10-12 21:36:25 INFO  Executor:54 - Running task 0.0 in stage 9.0 (TID 8)
2016-10-12 21:36:25 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 21:36:25 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2016-10-12 21:36:25 INFO  Executor:54 - Finished task 0.0 in stage 9.0 (TID 8). 1512 bytes result sent to driver
2016-10-12 21:36:25 INFO  TaskSetManager:54 - Finished task 0.0 in stage 9.0 (TID 8) in 58 ms on localhost (1/1)
2016-10-12 21:36:25 INFO  DAGScheduler:54 - ResultStage 9 (takeSample at a1.scala:69) finished in 0.059 s
2016-10-12 21:36:25 INFO  DAGScheduler:54 - Job 4 finished: takeSample at a1.scala:69, took 0.180326 s
2016-10-12 21:36:25 INFO  TaskSchedulerImpl:54 - Removed TaskSet 9.0, whose tasks have all completed, from pool 
2016-10-12 21:36:25 INFO  SparkContext:54 - Starting job: takeSample at a1.scala:69
2016-10-12 21:36:25 INFO  DAGScheduler:54 - Got job 5 (takeSample at a1.scala:69) with 1 output partitions
2016-10-12 21:36:25 INFO  DAGScheduler:54 - Final stage: ResultStage 11 (takeSample at a1.scala:69)
2016-10-12 21:36:25 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 10)
2016-10-12 21:36:25 INFO  DAGScheduler:54 - Missing parents: List()
2016-10-12 21:36:25 INFO  DAGScheduler:54 - Submitting ResultStage 11 (PartitionwiseSampledRDD[18] at takeSample at a1.scala:69), which has no missing parents
2016-10-12 21:36:25 INFO  MemoryStore:54 - Block broadcast_10 stored as values in memory (estimated size 3.8 KB, free 366.0 MB)
2016-10-12 21:36:25 INFO  MemoryStore:54 - Block broadcast_10_piece0 stored as bytes in memory (estimated size 2.3 KB, free 366.0 MB)
2016-10-12 21:36:25 INFO  BlockManagerInfo:54 - Added broadcast_10_piece0 in memory on 150.212.30.95:43700 (size: 2.3 KB, free: 366.3 MB)
2016-10-12 21:36:25 INFO  SparkContext:54 - Created broadcast 10 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:36:25 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 11 (PartitionwiseSampledRDD[18] at takeSample at a1.scala:69)
2016-10-12 21:36:25 INFO  TaskSchedulerImpl:54 - Adding task set 11.0 with 1 tasks
2016-10-12 21:36:25 INFO  TaskSetManager:54 - Starting task 0.0 in stage 11.0 (TID 9, localhost, partition 0, ANY, 5374 bytes)
2016-10-12 21:36:25 INFO  Executor:54 - Running task 0.0 in stage 11.0 (TID 9)
2016-10-12 21:36:25 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 21:36:25 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2016-10-12 21:36:25 INFO  Executor:54 - Finished task 0.0 in stage 11.0 (TID 9). 139228 bytes result sent to driver
2016-10-12 21:36:25 INFO  TaskSetManager:54 - Finished task 0.0 in stage 11.0 (TID 9) in 60 ms on localhost (1/1)
2016-10-12 21:36:25 INFO  DAGScheduler:54 - ResultStage 11 (takeSample at a1.scala:69) finished in 0.061 s
2016-10-12 21:36:25 INFO  DAGScheduler:54 - Job 5 finished: takeSample at a1.scala:69, took 0.083964 s
2016-10-12 21:36:25 INFO  TaskSchedulerImpl:54 - Removed TaskSet 11.0, whose tasks have all completed, from pool 
2016-10-12 21:36:25 INFO  SparkContext:54 - Starting job: collect at a1.scala:71
2016-10-12 21:36:25 INFO  DAGScheduler:54 - Got job 6 (collect at a1.scala:71) with 1 output partitions
2016-10-12 21:36:25 INFO  DAGScheduler:54 - Final stage: ResultStage 13 (collect at a1.scala:71)
2016-10-12 21:36:25 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 12)
2016-10-12 21:36:25 INFO  DAGScheduler:54 - Missing parents: List()
2016-10-12 21:36:25 INFO  DAGScheduler:54 - Submitting ResultStage 13 (MapPartitionsRDD[19] at map at a1.scala:71), which has no missing parents
2016-10-12 21:36:25 INFO  MemoryStore:54 - Block broadcast_11 stored as values in memory (estimated size 3.5 KB, free 366.0 MB)
2016-10-12 21:36:25 INFO  MemoryStore:54 - Block broadcast_11_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.0 MB)
2016-10-12 21:36:25 INFO  BlockManagerInfo:54 - Added broadcast_11_piece0 in memory on 150.212.30.95:43700 (size: 2.1 KB, free: 366.3 MB)
2016-10-12 21:36:25 INFO  SparkContext:54 - Created broadcast 11 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:36:25 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[19] at map at a1.scala:71)
2016-10-12 21:36:25 INFO  TaskSchedulerImpl:54 - Adding task set 13.0 with 1 tasks
2016-10-12 21:36:25 INFO  TaskSetManager:54 - Starting task 0.0 in stage 13.0 (TID 10, localhost, partition 0, ANY, 5262 bytes)
2016-10-12 21:36:25 INFO  Executor:54 - Running task 0.0 in stage 13.0 (TID 10)
2016-10-12 21:36:25 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 21:36:25 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2016-10-12 21:36:25 INFO  MemoryStore:54 - Block taskresult_10 stored as bytes in memory (estimated size 4.5 MB, free 361.5 MB)
2016-10-12 21:36:25 INFO  BlockManagerInfo:54 - Added taskresult_10 in memory on 150.212.30.95:43700 (size: 4.5 MB, free: 361.8 MB)
2016-10-12 21:36:25 INFO  Executor:54 - Finished task 0.0 in stage 13.0 (TID 10). 4684342 bytes result sent via BlockManager)
2016-10-12 21:36:25 INFO  BlockManagerInfo:54 - Removed taskresult_10 on 150.212.30.95:43700 in memory (size: 4.5 MB, free: 366.3 MB)
2016-10-12 21:36:25 INFO  TaskSetManager:54 - Finished task 0.0 in stage 13.0 (TID 10) in 99 ms on localhost (1/1)
2016-10-12 21:36:25 INFO  DAGScheduler:54 - ResultStage 13 (collect at a1.scala:71) finished in 0.110 s
2016-10-12 21:36:25 INFO  DAGScheduler:54 - Job 6 finished: collect at a1.scala:71, took 0.136290 s
2016-10-12 21:36:25 INFO  TaskSchedulerImpl:54 - Removed TaskSet 13.0, whose tasks have all completed, from pool 
2016-10-12 21:36:25 INFO  BlockManagerInfo:54 - Removed broadcast_10_piece0 on 150.212.30.95:43700 in memory (size: 2.3 KB, free: 366.3 MB)
2016-10-12 21:36:25 INFO  BlockManagerInfo:54 - Removed broadcast_11_piece0 on 150.212.30.95:43700 in memory (size: 2.1 KB, free: 366.3 MB)
2016-10-12 21:36:26 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2016-10-12 21:36:26 INFO  ServerConnector:306 - Stopped ServerConnector@6c67e137{HTTP/1.1}{0.0.0.0:4041}
2016-10-12 21:36:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,UNAVAILABLE}
2016-10-12 21:36:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@62e70ea3{/api,null,UNAVAILABLE}
2016-10-12 21:36:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@28276e50{/,null,UNAVAILABLE}
2016-10-12 21:36:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a7471ce{/static,null,UNAVAILABLE}
2016-10-12 21:36:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,UNAVAILABLE}
2016-10-12 21:36:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,UNAVAILABLE}
2016-10-12 21:36:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,UNAVAILABLE}
2016-10-12 21:36:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@297ea53a{/executors,null,UNAVAILABLE}
2016-10-12 21:36:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,UNAVAILABLE}
2016-10-12 21:36:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4052274f{/environment,null,UNAVAILABLE}
2016-10-12 21:36:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,UNAVAILABLE}
2016-10-12 21:36:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,UNAVAILABLE}
2016-10-12 21:36:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,UNAVAILABLE}
2016-10-12 21:36:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1643d68f{/storage,null,UNAVAILABLE}
2016-10-12 21:36:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,UNAVAILABLE}
2016-10-12 21:36:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,UNAVAILABLE}
2016-10-12 21:36:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,UNAVAILABLE}
2016-10-12 21:36:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,UNAVAILABLE}
2016-10-12 21:36:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,UNAVAILABLE}
2016-10-12 21:36:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,UNAVAILABLE}
2016-10-12 21:36:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,UNAVAILABLE}
2016-10-12 21:36:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,UNAVAILABLE}
2016-10-12 21:36:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,UNAVAILABLE}
2016-10-12 21:36:26 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,UNAVAILABLE}
2016-10-12 21:36:26 INFO  SparkUI:54 - Stopped Spark web UI at http://150.212.30.95:4041
2016-10-12 21:36:26 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2016-10-12 21:36:26 INFO  MemoryStore:54 - MemoryStore cleared
2016-10-12 21:36:26 INFO  BlockManager:54 - BlockManager stopped
2016-10-12 21:36:26 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2016-10-12 21:36:26 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2016-10-12 21:36:26 INFO  SparkContext:54 - Successfully stopped SparkContext
2016-10-12 21:36:26 INFO  ShutdownHookManager:54 - Shutdown hook called
2016-10-12 21:36:26 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-84a062fd-52b7-45cc-8d84-84478c1c224b
2016-10-12 21:37:29 INFO  SparkContext:54 - Running Spark version 2.0.0
2016-10-12 21:37:29 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-12 21:37:30 WARN  Utils:66 - Your hostname, aadu-XPS-13-9350 resolves to a loopback address: 127.0.1.1; using 150.212.30.95 instead (on interface wlp58s0)
2016-10-12 21:37:30 WARN  Utils:66 - Set SPARK_LOCAL_IP if you need to bind to another address
2016-10-12 21:37:30 INFO  SecurityManager:54 - Changing view acls to: aadu
2016-10-12 21:37:30 INFO  SecurityManager:54 - Changing modify acls to: aadu
2016-10-12 21:37:30 INFO  SecurityManager:54 - Changing view acls groups to: 
2016-10-12 21:37:30 INFO  SecurityManager:54 - Changing modify acls groups to: 
2016-10-12 21:37:30 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(aadu); groups with view permissions: Set(); users  with modify permissions: Set(aadu); groups with modify permissions: Set()
2016-10-12 21:37:30 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 40740.
2016-10-12 21:37:30 INFO  SparkEnv:54 - Registering MapOutputTracker
2016-10-12 21:37:30 INFO  SparkEnv:54 - Registering BlockManagerMaster
2016-10-12 21:37:30 INFO  DiskBlockManager:54 - Created local directory at /tmp/blockmgr-1661e0b2-5326-4e11-97b3-0dd11bac9b85
2016-10-12 21:37:30 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2016-10-12 21:37:30 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2016-10-12 21:37:30 INFO  log:186 - Logging initialized @1407ms
2016-10-12 21:37:30 INFO  Server:327 - jetty-9.2.z-SNAPSHOT
2016-10-12 21:37:30 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,AVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,AVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,AVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,AVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,AVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,AVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,AVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,AVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,AVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,AVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1643d68f{/storage,null,AVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,AVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,AVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,AVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4052274f{/environment,null,AVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,AVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@297ea53a{/executors,null,AVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,AVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,AVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,AVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a7471ce{/static,null,AVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@28276e50{/,null,AVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@62e70ea3{/api,null,AVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,AVAILABLE}
2016-10-12 21:37:30 WARN  AbstractLifeCycle:212 - FAILED ServerConnector@4fe89c24{HTTP/1.1}{0.0.0.0:4040}: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2071)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2062)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:139)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:451)
	at Assign1$.main(a1.scala:20)
	at Assign1.main(a1.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2016-10-12 21:37:30 WARN  AbstractLifeCycle:212 - FAILED org.spark_project.jetty.server.Server@6175619b: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2071)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2062)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:139)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:451)
	at Assign1$.main(a1.scala:20)
	at Assign1.main(a1.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2016-10-12 21:37:30 INFO  ServerConnector:306 - Stopped ServerConnector@4fe89c24{HTTP/1.1}{0.0.0.0:4040}
2016-10-12 21:37:30 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,UNAVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@62e70ea3{/api,null,UNAVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@28276e50{/,null,UNAVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a7471ce{/static,null,UNAVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,UNAVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,UNAVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,UNAVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@297ea53a{/executors,null,UNAVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,UNAVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4052274f{/environment,null,UNAVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,UNAVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,UNAVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,UNAVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1643d68f{/storage,null,UNAVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,UNAVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,UNAVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,UNAVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,UNAVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,UNAVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,UNAVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,UNAVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,UNAVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,UNAVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,UNAVAILABLE}
2016-10-12 21:37:30 WARN  Utils:66 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2016-10-12 21:37:30 INFO  Server:327 - jetty-9.2.z-SNAPSHOT
2016-10-12 21:37:30 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,AVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,AVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,AVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,AVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,AVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,AVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,AVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,AVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,AVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,AVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1643d68f{/storage,null,AVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,AVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,AVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,AVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4052274f{/environment,null,AVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,AVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@297ea53a{/executors,null,AVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,AVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,AVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,AVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a7471ce{/static,null,AVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@28276e50{/,null,AVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@62e70ea3{/api,null,AVAILABLE}
2016-10-12 21:37:30 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,AVAILABLE}
2016-10-12 21:37:30 INFO  ServerConnector:266 - Started ServerConnector@6c67e137{HTTP/1.1}{0.0.0.0:4041}
2016-10-12 21:37:30 INFO  Server:379 - Started @1553ms
2016-10-12 21:37:30 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4041.
2016-10-12 21:37:30 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://150.212.30.95:4041
2016-10-12 21:37:30 INFO  SparkContext:54 - Added JAR file:/home/aadu/Repos/adam/adam-assembly/target/adam_2.11-0.19.1-SNAPSHOT.jar at spark://150.212.30.95:40740/jars/adam_2.11-0.19.1-SNAPSHOT.jar with timestamp 1476322650754
2016-10-12 21:37:30 INFO  SparkContext:54 - Added JAR file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/a1.jar at spark://150.212.30.95:40740/jars/a1.jar with timestamp 1476322650756
2016-10-12 21:37:30 INFO  Executor:54 - Starting executor ID driver on host localhost
2016-10-12 21:37:30 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39245.
2016-10-12 21:37:30 INFO  NettyBlockTransferService:54 - Server created on 150.212.30.95:39245
2016-10-12 21:37:30 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 150.212.30.95, 39245)
2016-10-12 21:37:30 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 150.212.30.95:39245 with 366.3 MB RAM, BlockManagerId(driver, 150.212.30.95, 39245)
2016-10-12 21:37:30 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 150.212.30.95, 39245)
2016-10-12 21:37:30 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2472c7d8{/metrics/json,null,AVAILABLE}
2016-10-12 21:37:31 INFO  ADAMContext:1336 - Loading small.adam as Parquet containing Genotypes. Sequence dictionary for translation is ignored.
2016-10-12 21:37:31 INFO  ADAMContext:257 - Reading the ADAM file at small.adam to create RDD
2016-10-12 21:37:31 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 268.7 KB, free 366.0 MB)
2016-10-12 21:37:32 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 22.8 KB, free 366.0 MB)
2016-10-12 21:37:32 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 150.212.30.95:39245 (size: 22.8 KB, free: 366.3 MB)
2016-10-12 21:37:32 INFO  SparkContext:54 - Created broadcast 0 from newAPIHadoopFile at ADAMContext.scala:271
2016-10-12 21:37:32 INFO  FileInputFormat:283 - Total input paths to process : 1
2016-10-12 21:37:32 INFO  SparkContext:54 - Starting job: count at a1.scala:33
2016-10-12 21:37:32 INFO  DAGScheduler:54 - Registering RDD 3 (distinct at a1.scala:33)
2016-10-12 21:37:32 INFO  DAGScheduler:54 - Got job 0 (count at a1.scala:33) with 1 output partitions
2016-10-12 21:37:32 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (count at a1.scala:33)
2016-10-12 21:37:32 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 0)
2016-10-12 21:37:32 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 0)
2016-10-12 21:37:32 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at distinct at a1.scala:33), which has no missing parents
2016-10-12 21:37:32 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 4.2 KB, free 366.0 MB)
2016-10-12 21:37:32 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.5 KB, free 366.0 MB)
2016-10-12 21:37:32 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 150.212.30.95:39245 (size: 2.5 KB, free: 366.3 MB)
2016-10-12 21:37:32 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:37:32 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at distinct at a1.scala:33)
2016-10-12 21:37:32 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2016-10-12 21:37:32 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5507 bytes)
2016-10-12 21:37:32 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2016-10-12 21:37:32 INFO  Executor:54 - Fetching spark://150.212.30.95:40740/jars/a1.jar with timestamp 1476322650756
2016-10-12 21:37:32 INFO  TransportClientFactory:250 - Successfully created connection to /150.212.30.95:40740 after 23 ms (0 ms spent in bootstraps)
2016-10-12 21:37:32 INFO  Utils:54 - Fetching spark://150.212.30.95:40740/jars/a1.jar to /tmp/spark-5f1ba9f8-976f-42ad-91f4-a2001f96a8cc/userFiles-2d2a324f-4bc5-4d88-815c-f76b8f152429/fetchFileTemp8966033417411143077.tmp
2016-10-12 21:37:32 INFO  Executor:54 - Adding file:/tmp/spark-5f1ba9f8-976f-42ad-91f4-a2001f96a8cc/userFiles-2d2a324f-4bc5-4d88-815c-f76b8f152429/a1.jar to class loader
2016-10-12 21:37:32 INFO  Executor:54 - Fetching spark://150.212.30.95:40740/jars/adam_2.11-0.19.1-SNAPSHOT.jar with timestamp 1476322650754
2016-10-12 21:37:32 INFO  Utils:54 - Fetching spark://150.212.30.95:40740/jars/adam_2.11-0.19.1-SNAPSHOT.jar to /tmp/spark-5f1ba9f8-976f-42ad-91f4-a2001f96a8cc/userFiles-2d2a324f-4bc5-4d88-815c-f76b8f152429/fetchFileTemp2910059765087649420.tmp
2016-10-12 21:37:32 INFO  Executor:54 - Adding file:/tmp/spark-5f1ba9f8-976f-42ad-91f4-a2001f96a8cc/userFiles-2d2a324f-4bc5-4d88-815c-f76b8f152429/adam_2.11-0.19.1-SNAPSHOT.jar to class loader
2016-10-12 21:37:32 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 21:37:32 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 21:37:36 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1490 bytes result sent to driver
2016-10-12 21:37:36 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 4021 ms on localhost (1/1)
2016-10-12 21:37:36 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2016-10-12 21:37:36 INFO  DAGScheduler:54 - ShuffleMapStage 0 (distinct at a1.scala:33) finished in 4.038 s
2016-10-12 21:37:36 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 21:37:36 INFO  DAGScheduler:54 - running: Set()
2016-10-12 21:37:36 INFO  DAGScheduler:54 - waiting: Set(ResultStage 1)
2016-10-12 21:37:36 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 21:37:36 INFO  DAGScheduler:54 - Submitting ResultStage 1 (MapPartitionsRDD[5] at distinct at a1.scala:33), which has no missing parents
2016-10-12 21:37:36 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 3.7 KB, free 366.0 MB)
2016-10-12 21:37:36 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.2 KB, free 366.0 MB)
2016-10-12 21:37:36 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on 150.212.30.95:39245 (size: 2.2 KB, free: 366.3 MB)
2016-10-12 21:37:36 INFO  SparkContext:54 - Created broadcast 2 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:37:36 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at distinct at a1.scala:33)
2016-10-12 21:37:36 INFO  TaskSchedulerImpl:54 - Adding task set 1.0 with 1 tasks
2016-10-12 21:37:36 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, ANY, 5177 bytes)
2016-10-12 21:37:36 INFO  Executor:54 - Running task 0.0 in stage 1.0 (TID 1)
2016-10-12 21:37:36 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 21:37:36 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 3 ms
2016-10-12 21:37:36 INFO  Executor:54 - Finished task 0.0 in stage 1.0 (TID 1). 1512 bytes result sent to driver
2016-10-12 21:37:36 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 1) in 101 ms on localhost (1/1)
2016-10-12 21:37:36 INFO  DAGScheduler:54 - ResultStage 1 (count at a1.scala:33) finished in 0.101 s
2016-10-12 21:37:36 INFO  TaskSchedulerImpl:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2016-10-12 21:37:36 INFO  DAGScheduler:54 - Job 0 finished: count at a1.scala:33, took 4.317921 s
2016-10-12 21:37:36 INFO  SparkContext:54 - Starting job: count at a1.scala:34
2016-10-12 21:37:36 INFO  DAGScheduler:54 - Registering RDD 7 (distinct at a1.scala:34)
2016-10-12 21:37:36 INFO  DAGScheduler:54 - Got job 1 (count at a1.scala:34) with 1 output partitions
2016-10-12 21:37:36 INFO  DAGScheduler:54 - Final stage: ResultStage 3 (count at a1.scala:34)
2016-10-12 21:37:36 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 2)
2016-10-12 21:37:36 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 2)
2016-10-12 21:37:36 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 2 (MapPartitionsRDD[7] at distinct at a1.scala:34), which has no missing parents
2016-10-12 21:37:36 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 4.2 KB, free 366.0 MB)
2016-10-12 21:37:36 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.5 KB, free 366.0 MB)
2016-10-12 21:37:36 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on 150.212.30.95:39245 (size: 2.5 KB, free: 366.3 MB)
2016-10-12 21:37:36 INFO  SparkContext:54 - Created broadcast 3 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:37:36 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[7] at distinct at a1.scala:34)
2016-10-12 21:37:36 INFO  TaskSchedulerImpl:54 - Adding task set 2.0 with 1 tasks
2016-10-12 21:37:36 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5507 bytes)
2016-10-12 21:37:36 INFO  Executor:54 - Running task 0.0 in stage 2.0 (TID 2)
2016-10-12 21:37:36 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 21:37:36 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 21:37:37 INFO  BlockManagerInfo:54 - Removed broadcast_2_piece0 on 150.212.30.95:39245 in memory (size: 2.2 KB, free: 366.3 MB)
2016-10-12 21:37:39 INFO  Executor:54 - Finished task 0.0 in stage 2.0 (TID 2). 1490 bytes result sent to driver
2016-10-12 21:37:39 INFO  DAGScheduler:54 - ShuffleMapStage 2 (distinct at a1.scala:34) finished in 3.254 s
2016-10-12 21:37:39 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 21:37:39 INFO  DAGScheduler:54 - running: Set()
2016-10-12 21:37:39 INFO  DAGScheduler:54 - waiting: Set(ResultStage 3)
2016-10-12 21:37:39 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 21:37:39 INFO  DAGScheduler:54 - Submitting ResultStage 3 (MapPartitionsRDD[9] at distinct at a1.scala:34), which has no missing parents
2016-10-12 21:37:39 INFO  TaskSetManager:54 - Finished task 0.0 in stage 2.0 (TID 2) in 3262 ms on localhost (1/1)
2016-10-12 21:37:39 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 3.8 KB, free 366.0 MB)
2016-10-12 21:37:39 INFO  TaskSchedulerImpl:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2016-10-12 21:37:39 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.2 KB, free 366.0 MB)
2016-10-12 21:37:39 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on 150.212.30.95:39245 (size: 2.2 KB, free: 366.3 MB)
2016-10-12 21:37:39 INFO  SparkContext:54 - Created broadcast 4 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:37:39 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[9] at distinct at a1.scala:34)
2016-10-12 21:37:39 INFO  TaskSchedulerImpl:54 - Adding task set 3.0 with 1 tasks
2016-10-12 21:37:39 INFO  TaskSetManager:54 - Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, ANY, 5177 bytes)
2016-10-12 21:37:39 INFO  Executor:54 - Running task 0.0 in stage 3.0 (TID 3)
2016-10-12 21:37:39 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 21:37:39 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2016-10-12 21:37:40 INFO  Executor:54 - Finished task 0.0 in stage 3.0 (TID 3). 1512 bytes result sent to driver
2016-10-12 21:37:40 INFO  DAGScheduler:54 - ResultStage 3 (count at a1.scala:34) finished in 0.064 s
2016-10-12 21:37:40 INFO  TaskSetManager:54 - Finished task 0.0 in stage 3.0 (TID 3) in 64 ms on localhost (1/1)
2016-10-12 21:37:40 INFO  DAGScheduler:54 - Job 1 finished: count at a1.scala:34, took 3.386643 s
2016-10-12 21:37:40 INFO  TaskSchedulerImpl:54 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2016-10-12 21:37:40 INFO  SparkContext:54 - Starting job: collect at a1.scala:35
2016-10-12 21:37:40 INFO  DAGScheduler:54 - Registering RDD 10 (map at a1.scala:35)
2016-10-12 21:37:40 INFO  DAGScheduler:54 - Got job 2 (collect at a1.scala:35) with 1 output partitions
2016-10-12 21:37:40 INFO  DAGScheduler:54 - Final stage: ResultStage 5 (collect at a1.scala:35)
2016-10-12 21:37:40 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 4)
2016-10-12 21:37:40 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 4)
2016-10-12 21:37:40 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 4 (MapPartitionsRDD[10] at map at a1.scala:35), which has no missing parents
2016-10-12 21:37:40 INFO  MemoryStore:54 - Block broadcast_5 stored as values in memory (estimated size 4.0 KB, free 366.0 MB)
2016-10-12 21:37:40 INFO  MemoryStore:54 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.4 KB, free 366.0 MB)
2016-10-12 21:37:40 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on 150.212.30.95:39245 (size: 2.4 KB, free: 366.3 MB)
2016-10-12 21:37:40 INFO  SparkContext:54 - Created broadcast 5 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:37:40 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[10] at map at a1.scala:35)
2016-10-12 21:37:40 INFO  TaskSchedulerImpl:54 - Adding task set 4.0 with 1 tasks
2016-10-12 21:37:40 INFO  TaskSetManager:54 - Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5592 bytes)
2016-10-12 21:37:40 INFO  Executor:54 - Running task 0.0 in stage 4.0 (TID 4)
2016-10-12 21:37:40 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 21:37:40 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 21:37:40 INFO  ContextCleaner:54 - Cleaned shuffle 1
2016-10-12 21:37:40 INFO  BlockManagerInfo:54 - Removed broadcast_3_piece0 on 150.212.30.95:39245 in memory (size: 2.5 KB, free: 366.3 MB)
2016-10-12 21:37:40 INFO  BlockManagerInfo:54 - Removed broadcast_4_piece0 on 150.212.30.95:39245 in memory (size: 2.2 KB, free: 366.3 MB)
2016-10-12 21:37:43 INFO  Executor:54 - Finished task 0.0 in stage 4.0 (TID 4). 1490 bytes result sent to driver
2016-10-12 21:37:43 INFO  DAGScheduler:54 - ShuffleMapStage 4 (map at a1.scala:35) finished in 3.279 s
2016-10-12 21:37:43 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 21:37:43 INFO  DAGScheduler:54 - running: Set()
2016-10-12 21:37:43 INFO  DAGScheduler:54 - waiting: Set(ResultStage 5)
2016-10-12 21:37:43 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 21:37:43 INFO  DAGScheduler:54 - Submitting ResultStage 5 (MapPartitionsRDD[13] at map at a1.scala:35), which has no missing parents
2016-10-12 21:37:43 INFO  TaskSetManager:54 - Finished task 0.0 in stage 4.0 (TID 4) in 3277 ms on localhost (1/1)
2016-10-12 21:37:43 INFO  TaskSchedulerImpl:54 - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2016-10-12 21:37:43 INFO  MemoryStore:54 - Block broadcast_6 stored as values in memory (estimated size 3.8 KB, free 366.0 MB)
2016-10-12 21:37:43 INFO  MemoryStore:54 - Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.2 KB, free 366.0 MB)
2016-10-12 21:37:43 INFO  BlockManagerInfo:54 - Added broadcast_6_piece0 in memory on 150.212.30.95:39245 (size: 2.2 KB, free: 366.3 MB)
2016-10-12 21:37:43 INFO  SparkContext:54 - Created broadcast 6 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:37:43 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[13] at map at a1.scala:35)
2016-10-12 21:37:43 INFO  TaskSchedulerImpl:54 - Adding task set 5.0 with 1 tasks
2016-10-12 21:37:43 INFO  TaskSetManager:54 - Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, ANY, 5262 bytes)
2016-10-12 21:37:43 INFO  Executor:54 - Running task 0.0 in stage 5.0 (TID 5)
2016-10-12 21:37:43 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 21:37:43 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 2 ms
2016-10-12 21:37:43 INFO  Executor:54 - Finished task 0.0 in stage 5.0 (TID 5). 9861 bytes result sent to driver
2016-10-12 21:37:43 INFO  DAGScheduler:54 - ResultStage 5 (collect at a1.scala:35) finished in 0.043 s
2016-10-12 21:37:43 INFO  DAGScheduler:54 - Job 2 finished: collect at a1.scala:35, took 3.357177 s
2016-10-12 21:37:43 INFO  TaskSetManager:54 - Finished task 0.0 in stage 5.0 (TID 5) in 42 ms on localhost (1/1)
2016-10-12 21:37:43 INFO  TaskSchedulerImpl:54 - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2016-10-12 21:37:43 INFO  SparkContext:54 - Starting job: collect at a1.scala:47
2016-10-12 21:37:43 INFO  DAGScheduler:54 - Registering RDD 16 (map at a1.scala:42)
2016-10-12 21:37:43 INFO  DAGScheduler:54 - Got job 3 (collect at a1.scala:47) with 1 output partitions
2016-10-12 21:37:43 INFO  DAGScheduler:54 - Final stage: ResultStage 7 (collect at a1.scala:47)
2016-10-12 21:37:43 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 6)
2016-10-12 21:37:43 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 6)
2016-10-12 21:37:43 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 6 (MapPartitionsRDD[16] at map at a1.scala:42), which has no missing parents
2016-10-12 21:37:43 INFO  MemoryStore:54 - Block broadcast_7 stored as values in memory (estimated size 45.6 KB, free 366.0 MB)
2016-10-12 21:37:43 INFO  MemoryStore:54 - Block broadcast_7_piece0 stored as bytes in memory (estimated size 21.5 KB, free 365.9 MB)
2016-10-12 21:37:43 INFO  BlockManagerInfo:54 - Added broadcast_7_piece0 in memory on 150.212.30.95:39245 (size: 21.5 KB, free: 366.2 MB)
2016-10-12 21:37:43 INFO  SparkContext:54 - Created broadcast 7 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:37:43 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[16] at map at a1.scala:42)
2016-10-12 21:37:43 INFO  TaskSchedulerImpl:54 - Adding task set 6.0 with 1 tasks
2016-10-12 21:37:43 INFO  TaskSetManager:54 - Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, PROCESS_LOCAL, 5592 bytes)
2016-10-12 21:37:43 INFO  Executor:54 - Running task 0.0 in stage 6.0 (TID 6)
2016-10-12 21:37:43 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 21:37:43 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 21:37:43 INFO  ContextCleaner:54 - Cleaned shuffle 2
2016-10-12 21:37:43 INFO  BlockManagerInfo:54 - Removed broadcast_5_piece0 on 150.212.30.95:39245 in memory (size: 2.4 KB, free: 366.3 MB)
2016-10-12 21:37:43 INFO  BlockManagerInfo:54 - Removed broadcast_6_piece0 on 150.212.30.95:39245 in memory (size: 2.2 KB, free: 366.3 MB)
2016-10-12 21:37:47 INFO  Executor:54 - Finished task 0.0 in stage 6.0 (TID 6). 1490 bytes result sent to driver
2016-10-12 21:37:47 INFO  DAGScheduler:54 - ShuffleMapStage 6 (map at a1.scala:42) finished in 4.251 s
2016-10-12 21:37:47 INFO  TaskSetManager:54 - Finished task 0.0 in stage 6.0 (TID 6) in 4250 ms on localhost (1/1)
2016-10-12 21:37:47 INFO  TaskSchedulerImpl:54 - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2016-10-12 21:37:47 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 21:37:47 INFO  DAGScheduler:54 - running: Set()
2016-10-12 21:37:47 INFO  DAGScheduler:54 - waiting: Set(ResultStage 7)
2016-10-12 21:37:47 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 21:37:47 INFO  DAGScheduler:54 - Submitting ResultStage 7 (ShuffledRDD[17] at reduceByKey at a1.scala:42), which has no missing parents
2016-10-12 21:37:47 INFO  MemoryStore:54 - Block broadcast_8 stored as values in memory (estimated size 3.1 KB, free 365.9 MB)
2016-10-12 21:37:47 INFO  MemoryStore:54 - Block broadcast_8_piece0 stored as bytes in memory (estimated size 1901.0 B, free 365.9 MB)
2016-10-12 21:37:47 INFO  BlockManagerInfo:54 - Added broadcast_8_piece0 in memory on 150.212.30.95:39245 (size: 1901.0 B, free: 366.3 MB)
2016-10-12 21:37:47 INFO  SparkContext:54 - Created broadcast 8 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:37:47 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 7 (ShuffledRDD[17] at reduceByKey at a1.scala:42)
2016-10-12 21:37:47 INFO  TaskSchedulerImpl:54 - Adding task set 7.0 with 1 tasks
2016-10-12 21:37:47 INFO  TaskSetManager:54 - Starting task 0.0 in stage 7.0 (TID 7, localhost, partition 0, ANY, 5262 bytes)
2016-10-12 21:37:47 INFO  Executor:54 - Running task 0.0 in stage 7.0 (TID 7)
2016-10-12 21:37:47 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 21:37:47 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2016-10-12 21:37:47 INFO  MemoryStore:54 - Block taskresult_7 stored as bytes in memory (estimated size 4.5 MB, free 361.4 MB)
2016-10-12 21:37:47 INFO  BlockManagerInfo:54 - Added taskresult_7 in memory on 150.212.30.95:39245 (size: 4.5 MB, free: 361.8 MB)
2016-10-12 21:37:47 INFO  Executor:54 - Finished task 0.0 in stage 7.0 (TID 7). 4714208 bytes result sent via BlockManager)
2016-10-12 21:37:47 INFO  TransportClientFactory:250 - Successfully created connection to /150.212.30.95:39245 after 1 ms (0 ms spent in bootstraps)
2016-10-12 21:37:47 INFO  BlockManagerInfo:54 - Removed taskresult_7 on 150.212.30.95:39245 in memory (size: 4.5 MB, free: 366.3 MB)
2016-10-12 21:37:47 INFO  DAGScheduler:54 - ResultStage 7 (collect at a1.scala:47) finished in 0.192 s
2016-10-12 21:37:47 INFO  DAGScheduler:54 - Job 3 finished: collect at a1.scala:47, took 4.491525 s
2016-10-12 21:37:47 INFO  TaskSetManager:54 - Finished task 0.0 in stage 7.0 (TID 7) in 178 ms on localhost (1/1)
2016-10-12 21:37:47 INFO  TaskSchedulerImpl:54 - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2016-10-12 21:37:47 INFO  SparkContext:54 - Starting job: takeSample at a1.scala:69
2016-10-12 21:37:47 INFO  MapOutputTrackerMaster:54 - Size of output statuses for shuffle 3 is 148 bytes
2016-10-12 21:37:48 INFO  DAGScheduler:54 - Got job 4 (takeSample at a1.scala:69) with 1 output partitions
2016-10-12 21:37:48 INFO  DAGScheduler:54 - Final stage: ResultStage 9 (takeSample at a1.scala:69)
2016-10-12 21:37:48 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 8)
2016-10-12 21:37:48 INFO  DAGScheduler:54 - Missing parents: List()
2016-10-12 21:37:48 INFO  DAGScheduler:54 - Submitting ResultStage 9 (ShuffledRDD[17] at reduceByKey at a1.scala:42), which has no missing parents
2016-10-12 21:37:48 INFO  MemoryStore:54 - Block broadcast_9 stored as values in memory (estimated size 2.9 KB, free 365.9 MB)
2016-10-12 21:37:48 INFO  MemoryStore:54 - Block broadcast_9_piece0 stored as bytes in memory (estimated size 1853.0 B, free 365.9 MB)
2016-10-12 21:37:48 INFO  BlockManagerInfo:54 - Added broadcast_9_piece0 in memory on 150.212.30.95:39245 (size: 1853.0 B, free: 366.3 MB)
2016-10-12 21:37:48 INFO  SparkContext:54 - Created broadcast 9 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:37:48 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 9 (ShuffledRDD[17] at reduceByKey at a1.scala:42)
2016-10-12 21:37:48 INFO  TaskSchedulerImpl:54 - Adding task set 9.0 with 1 tasks
2016-10-12 21:37:48 INFO  TaskSetManager:54 - Starting task 0.0 in stage 9.0 (TID 8, localhost, partition 0, ANY, 5265 bytes)
2016-10-12 21:37:48 INFO  BlockManagerInfo:54 - Removed broadcast_1_piece0 on 150.212.30.95:39245 in memory (size: 2.5 KB, free: 366.3 MB)
2016-10-12 21:37:48 INFO  Executor:54 - Running task 0.0 in stage 9.0 (TID 8)
2016-10-12 21:37:48 INFO  BlockManagerInfo:54 - Removed broadcast_8_piece0 on 150.212.30.95:39245 in memory (size: 1901.0 B, free: 366.3 MB)
2016-10-12 21:37:48 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 21:37:48 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2016-10-12 21:37:48 INFO  BlockManagerInfo:54 - Removed broadcast_7_piece0 on 150.212.30.95:39245 in memory (size: 21.5 KB, free: 366.3 MB)
2016-10-12 21:37:48 INFO  ContextCleaner:54 - Cleaned shuffle 0
2016-10-12 21:37:48 INFO  Executor:54 - Finished task 0.0 in stage 9.0 (TID 8). 1512 bytes result sent to driver
2016-10-12 21:37:48 INFO  TaskSetManager:54 - Finished task 0.0 in stage 9.0 (TID 8) in 156 ms on localhost (1/1)
2016-10-12 21:37:48 INFO  DAGScheduler:54 - ResultStage 9 (takeSample at a1.scala:69) finished in 0.156 s
2016-10-12 21:37:48 INFO  DAGScheduler:54 - Job 4 finished: takeSample at a1.scala:69, took 0.197345 s
2016-10-12 21:37:48 INFO  TaskSchedulerImpl:54 - Removed TaskSet 9.0, whose tasks have all completed, from pool 
2016-10-12 21:37:48 INFO  SparkContext:54 - Starting job: takeSample at a1.scala:69
2016-10-12 21:37:48 INFO  DAGScheduler:54 - Got job 5 (takeSample at a1.scala:69) with 1 output partitions
2016-10-12 21:37:48 INFO  DAGScheduler:54 - Final stage: ResultStage 11 (takeSample at a1.scala:69)
2016-10-12 21:37:48 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 10)
2016-10-12 21:37:48 INFO  DAGScheduler:54 - Missing parents: List()
2016-10-12 21:37:48 INFO  DAGScheduler:54 - Submitting ResultStage 11 (PartitionwiseSampledRDD[18] at takeSample at a1.scala:69), which has no missing parents
2016-10-12 21:37:48 INFO  MemoryStore:54 - Block broadcast_10 stored as values in memory (estimated size 3.8 KB, free 366.0 MB)
2016-10-12 21:37:48 INFO  MemoryStore:54 - Block broadcast_10_piece0 stored as bytes in memory (estimated size 2.3 KB, free 366.0 MB)
2016-10-12 21:37:48 INFO  BlockManagerInfo:54 - Added broadcast_10_piece0 in memory on 150.212.30.95:39245 (size: 2.3 KB, free: 366.3 MB)
2016-10-12 21:37:48 INFO  SparkContext:54 - Created broadcast 10 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:37:48 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 11 (PartitionwiseSampledRDD[18] at takeSample at a1.scala:69)
2016-10-12 21:37:48 INFO  TaskSchedulerImpl:54 - Adding task set 11.0 with 1 tasks
2016-10-12 21:37:48 INFO  TaskSetManager:54 - Starting task 0.0 in stage 11.0 (TID 9, localhost, partition 0, ANY, 5374 bytes)
2016-10-12 21:37:48 INFO  Executor:54 - Running task 0.0 in stage 11.0 (TID 9)
2016-10-12 21:37:48 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 21:37:48 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2016-10-12 21:37:48 INFO  Executor:54 - Finished task 0.0 in stage 11.0 (TID 9). 150241 bytes result sent to driver
2016-10-12 21:37:48 INFO  DAGScheduler:54 - ResultStage 11 (takeSample at a1.scala:69) finished in 0.060 s
2016-10-12 21:37:48 INFO  TaskSetManager:54 - Finished task 0.0 in stage 11.0 (TID 9) in 58 ms on localhost (1/1)
2016-10-12 21:37:48 INFO  DAGScheduler:54 - Job 5 finished: takeSample at a1.scala:69, took 0.077756 s
2016-10-12 21:37:48 INFO  TaskSchedulerImpl:54 - Removed TaskSet 11.0, whose tasks have all completed, from pool 
2016-10-12 21:37:48 INFO  SparkContext:54 - Starting job: collect at a1.scala:71
2016-10-12 21:37:48 INFO  DAGScheduler:54 - Got job 6 (collect at a1.scala:71) with 1 output partitions
2016-10-12 21:37:48 INFO  DAGScheduler:54 - Final stage: ResultStage 13 (collect at a1.scala:71)
2016-10-12 21:37:48 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 12)
2016-10-12 21:37:48 INFO  DAGScheduler:54 - Missing parents: List()
2016-10-12 21:37:48 INFO  DAGScheduler:54 - Submitting ResultStage 13 (MapPartitionsRDD[19] at map at a1.scala:71), which has no missing parents
2016-10-12 21:37:48 INFO  MemoryStore:54 - Block broadcast_11 stored as values in memory (estimated size 3.5 KB, free 366.0 MB)
2016-10-12 21:37:48 INFO  MemoryStore:54 - Block broadcast_11_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.0 MB)
2016-10-12 21:37:48 INFO  BlockManagerInfo:54 - Added broadcast_11_piece0 in memory on 150.212.30.95:39245 (size: 2.1 KB, free: 366.3 MB)
2016-10-12 21:37:48 INFO  SparkContext:54 - Created broadcast 11 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:37:48 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[19] at map at a1.scala:71)
2016-10-12 21:37:48 INFO  TaskSchedulerImpl:54 - Adding task set 13.0 with 1 tasks
2016-10-12 21:37:48 INFO  TaskSetManager:54 - Starting task 0.0 in stage 13.0 (TID 10, localhost, partition 0, ANY, 5262 bytes)
2016-10-12 21:37:48 INFO  Executor:54 - Running task 0.0 in stage 13.0 (TID 10)
2016-10-12 21:37:48 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 21:37:48 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 2 ms
2016-10-12 21:37:48 INFO  MemoryStore:54 - Block taskresult_10 stored as bytes in memory (estimated size 4.5 MB, free 361.5 MB)
2016-10-12 21:37:48 INFO  BlockManagerInfo:54 - Added taskresult_10 in memory on 150.212.30.95:39245 (size: 4.5 MB, free: 361.8 MB)
2016-10-12 21:37:48 INFO  Executor:54 - Finished task 0.0 in stage 13.0 (TID 10). 4684342 bytes result sent via BlockManager)
2016-10-12 21:37:48 INFO  BlockManagerInfo:54 - Removed taskresult_10 on 150.212.30.95:39245 in memory (size: 4.5 MB, free: 366.3 MB)
2016-10-12 21:37:48 INFO  DAGScheduler:54 - ResultStage 13 (collect at a1.scala:71) finished in 0.094 s
2016-10-12 21:37:48 INFO  DAGScheduler:54 - Job 6 finished: collect at a1.scala:71, took 0.117224 s
2016-10-12 21:37:48 INFO  TaskSetManager:54 - Finished task 0.0 in stage 13.0 (TID 10) in 84 ms on localhost (1/1)
2016-10-12 21:37:48 INFO  TaskSchedulerImpl:54 - Removed TaskSet 13.0, whose tasks have all completed, from pool 
2016-10-12 21:37:48 INFO  BlockManagerInfo:54 - Removed broadcast_11_piece0 on 150.212.30.95:39245 in memory (size: 2.1 KB, free: 366.3 MB)
2016-10-12 21:37:48 INFO  BlockManagerInfo:54 - Removed broadcast_10_piece0 on 150.212.30.95:39245 in memory (size: 2.3 KB, free: 366.3 MB)
2016-10-12 21:37:53 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2016-10-12 21:37:53 INFO  ServerConnector:306 - Stopped ServerConnector@6c67e137{HTTP/1.1}{0.0.0.0:4041}
2016-10-12 21:37:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,UNAVAILABLE}
2016-10-12 21:37:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@62e70ea3{/api,null,UNAVAILABLE}
2016-10-12 21:37:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@28276e50{/,null,UNAVAILABLE}
2016-10-12 21:37:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a7471ce{/static,null,UNAVAILABLE}
2016-10-12 21:37:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,UNAVAILABLE}
2016-10-12 21:37:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,UNAVAILABLE}
2016-10-12 21:37:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,UNAVAILABLE}
2016-10-12 21:37:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@297ea53a{/executors,null,UNAVAILABLE}
2016-10-12 21:37:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,UNAVAILABLE}
2016-10-12 21:37:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4052274f{/environment,null,UNAVAILABLE}
2016-10-12 21:37:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,UNAVAILABLE}
2016-10-12 21:37:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,UNAVAILABLE}
2016-10-12 21:37:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,UNAVAILABLE}
2016-10-12 21:37:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1643d68f{/storage,null,UNAVAILABLE}
2016-10-12 21:37:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,UNAVAILABLE}
2016-10-12 21:37:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,UNAVAILABLE}
2016-10-12 21:37:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,UNAVAILABLE}
2016-10-12 21:37:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,UNAVAILABLE}
2016-10-12 21:37:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,UNAVAILABLE}
2016-10-12 21:37:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,UNAVAILABLE}
2016-10-12 21:37:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,UNAVAILABLE}
2016-10-12 21:37:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,UNAVAILABLE}
2016-10-12 21:37:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,UNAVAILABLE}
2016-10-12 21:37:53 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,UNAVAILABLE}
2016-10-12 21:37:53 INFO  SparkUI:54 - Stopped Spark web UI at http://150.212.30.95:4041
2016-10-12 21:37:53 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2016-10-12 21:37:53 INFO  MemoryStore:54 - MemoryStore cleared
2016-10-12 21:37:53 INFO  BlockManager:54 - BlockManager stopped
2016-10-12 21:37:53 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2016-10-12 21:37:53 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2016-10-12 21:37:53 INFO  SparkContext:54 - Successfully stopped SparkContext
2016-10-12 21:37:53 INFO  ShutdownHookManager:54 - Shutdown hook called
2016-10-12 21:37:53 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-5f1ba9f8-976f-42ad-91f4-a2001f96a8cc
2016-10-12 21:39:09 INFO  SparkContext:54 - Running Spark version 2.0.0
2016-10-12 21:39:09 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-10-12 21:39:09 WARN  Utils:66 - Your hostname, aadu-XPS-13-9350 resolves to a loopback address: 127.0.1.1; using 150.212.30.95 instead (on interface wlp58s0)
2016-10-12 21:39:09 WARN  Utils:66 - Set SPARK_LOCAL_IP if you need to bind to another address
2016-10-12 21:39:09 INFO  SecurityManager:54 - Changing view acls to: aadu
2016-10-12 21:39:09 INFO  SecurityManager:54 - Changing modify acls to: aadu
2016-10-12 21:39:09 INFO  SecurityManager:54 - Changing view acls groups to: 
2016-10-12 21:39:09 INFO  SecurityManager:54 - Changing modify acls groups to: 
2016-10-12 21:39:09 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(aadu); groups with view permissions: Set(); users  with modify permissions: Set(aadu); groups with modify permissions: Set()
2016-10-12 21:39:09 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 43327.
2016-10-12 21:39:09 INFO  SparkEnv:54 - Registering MapOutputTracker
2016-10-12 21:39:09 INFO  SparkEnv:54 - Registering BlockManagerMaster
2016-10-12 21:39:09 INFO  DiskBlockManager:54 - Created local directory at /tmp/blockmgr-97a7019e-a241-4c77-899e-f5a1d831e5fd
2016-10-12 21:39:09 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2016-10-12 21:39:09 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2016-10-12 21:39:09 INFO  log:186 - Logging initialized @1434ms
2016-10-12 21:39:10 INFO  Server:327 - jetty-9.2.z-SNAPSHOT
2016-10-12 21:39:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,AVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,AVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,AVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,AVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,AVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,AVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,AVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,AVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,AVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,AVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1643d68f{/storage,null,AVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,AVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,AVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,AVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4052274f{/environment,null,AVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,AVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@297ea53a{/executors,null,AVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,AVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,AVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,AVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a7471ce{/static,null,AVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@28276e50{/,null,AVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@62e70ea3{/api,null,AVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,AVAILABLE}
2016-10-12 21:39:10 WARN  AbstractLifeCycle:212 - FAILED ServerConnector@4fe89c24{HTTP/1.1}{0.0.0.0:4040}: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2071)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2062)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:139)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:451)
	at Assign1$.main(a1.scala:20)
	at Assign1.main(a1.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2016-10-12 21:39:10 WARN  AbstractLifeCycle:212 - FAILED org.spark_project.jetty.server.Server@6175619b: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark_project.jetty.server.ServerConnector.open(ServerConnector.java:321)
	at org.spark_project.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80)
	at org.spark_project.jetty.server.ServerConnector.doStart(ServerConnector.java:236)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.spark_project.jetty.server.Server.doStart(Server.java:366)
	at org.spark_project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:298)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:308)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:2071)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2062)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:308)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:139)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at org.apache.spark.SparkContext$$anonfun$10.apply(SparkContext.scala:451)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:451)
	at Assign1$.main(a1.scala:20)
	at Assign1.main(a1.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:729)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2016-10-12 21:39:10 INFO  ServerConnector:306 - Stopped ServerConnector@4fe89c24{HTTP/1.1}{0.0.0.0:4040}
2016-10-12 21:39:10 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,UNAVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@62e70ea3{/api,null,UNAVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@28276e50{/,null,UNAVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a7471ce{/static,null,UNAVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,UNAVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,UNAVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,UNAVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@297ea53a{/executors,null,UNAVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,UNAVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4052274f{/environment,null,UNAVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,UNAVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,UNAVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,UNAVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1643d68f{/storage,null,UNAVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,UNAVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,UNAVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,UNAVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,UNAVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,UNAVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,UNAVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,UNAVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,UNAVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,UNAVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,UNAVAILABLE}
2016-10-12 21:39:10 WARN  Utils:66 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2016-10-12 21:39:10 INFO  Server:327 - jetty-9.2.z-SNAPSHOT
2016-10-12 21:39:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,AVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,AVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,AVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,AVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,AVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,AVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,AVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,AVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,AVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,AVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1643d68f{/storage,null,AVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,AVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,AVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,AVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4052274f{/environment,null,AVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,AVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@297ea53a{/executors,null,AVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,AVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,AVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,AVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7a7471ce{/static,null,AVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@28276e50{/,null,AVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@62e70ea3{/api,null,AVAILABLE}
2016-10-12 21:39:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,AVAILABLE}
2016-10-12 21:39:10 INFO  ServerConnector:266 - Started ServerConnector@6c67e137{HTTP/1.1}{0.0.0.0:4041}
2016-10-12 21:39:10 INFO  Server:379 - Started @1587ms
2016-10-12 21:39:10 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4041.
2016-10-12 21:39:10 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://150.212.30.95:4041
2016-10-12 21:39:10 INFO  SparkContext:54 - Added JAR file:/home/aadu/Repos/adam/adam-assembly/target/adam_2.11-0.19.1-SNAPSHOT.jar at spark://150.212.30.95:43327/jars/adam_2.11-0.19.1-SNAPSHOT.jar with timestamp 1476322750166
2016-10-12 21:39:10 INFO  SparkContext:54 - Added JAR file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/a1.jar at spark://150.212.30.95:43327/jars/a1.jar with timestamp 1476322750166
2016-10-12 21:39:10 INFO  Executor:54 - Starting executor ID driver on host localhost
2016-10-12 21:39:10 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41887.
2016-10-12 21:39:10 INFO  NettyBlockTransferService:54 - Server created on 150.212.30.95:41887
2016-10-12 21:39:10 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 150.212.30.95, 41887)
2016-10-12 21:39:10 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 150.212.30.95:41887 with 366.3 MB RAM, BlockManagerId(driver, 150.212.30.95, 41887)
2016-10-12 21:39:10 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 150.212.30.95, 41887)
2016-10-12 21:39:10 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@2472c7d8{/metrics/json,null,AVAILABLE}
2016-10-12 21:39:10 INFO  ADAMContext:1336 - Loading small.adam as Parquet containing Genotypes. Sequence dictionary for translation is ignored.
2016-10-12 21:39:10 INFO  ADAMContext:257 - Reading the ADAM file at small.adam to create RDD
2016-10-12 21:39:10 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 268.7 KB, free 366.0 MB)
2016-10-12 21:39:11 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 22.8 KB, free 366.0 MB)
2016-10-12 21:39:11 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 150.212.30.95:41887 (size: 22.8 KB, free: 366.3 MB)
2016-10-12 21:39:11 INFO  SparkContext:54 - Created broadcast 0 from newAPIHadoopFile at ADAMContext.scala:271
2016-10-12 21:39:11 INFO  FileInputFormat:283 - Total input paths to process : 1
2016-10-12 21:39:11 INFO  SparkContext:54 - Starting job: count at a1.scala:33
2016-10-12 21:39:11 INFO  DAGScheduler:54 - Registering RDD 3 (distinct at a1.scala:33)
2016-10-12 21:39:11 INFO  DAGScheduler:54 - Got job 0 (count at a1.scala:33) with 1 output partitions
2016-10-12 21:39:11 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (count at a1.scala:33)
2016-10-12 21:39:11 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 0)
2016-10-12 21:39:11 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 0)
2016-10-12 21:39:11 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at distinct at a1.scala:33), which has no missing parents
2016-10-12 21:39:11 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 4.2 KB, free 366.0 MB)
2016-10-12 21:39:11 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.5 KB, free 366.0 MB)
2016-10-12 21:39:11 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 150.212.30.95:41887 (size: 2.5 KB, free: 366.3 MB)
2016-10-12 21:39:11 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:39:11 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at distinct at a1.scala:33)
2016-10-12 21:39:11 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2016-10-12 21:39:11 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5507 bytes)
2016-10-12 21:39:11 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2016-10-12 21:39:11 INFO  Executor:54 - Fetching spark://150.212.30.95:43327/jars/adam_2.11-0.19.1-SNAPSHOT.jar with timestamp 1476322750166
2016-10-12 21:39:11 INFO  TransportClientFactory:250 - Successfully created connection to /150.212.30.95:43327 after 24 ms (0 ms spent in bootstraps)
2016-10-12 21:39:11 INFO  Utils:54 - Fetching spark://150.212.30.95:43327/jars/adam_2.11-0.19.1-SNAPSHOT.jar to /tmp/spark-d4fe5a69-fc04-487f-8a39-fa0ef313263b/userFiles-d5a48adf-1846-4a47-9cfb-e1729b5668eb/fetchFileTemp30464098160652610.tmp
2016-10-12 21:39:12 INFO  Executor:54 - Adding file:/tmp/spark-d4fe5a69-fc04-487f-8a39-fa0ef313263b/userFiles-d5a48adf-1846-4a47-9cfb-e1729b5668eb/adam_2.11-0.19.1-SNAPSHOT.jar to class loader
2016-10-12 21:39:12 INFO  Executor:54 - Fetching spark://150.212.30.95:43327/jars/a1.jar with timestamp 1476322750166
2016-10-12 21:39:12 INFO  Utils:54 - Fetching spark://150.212.30.95:43327/jars/a1.jar to /tmp/spark-d4fe5a69-fc04-487f-8a39-fa0ef313263b/userFiles-d5a48adf-1846-4a47-9cfb-e1729b5668eb/fetchFileTemp6119577081460878049.tmp
2016-10-12 21:39:12 INFO  Executor:54 - Adding file:/tmp/spark-d4fe5a69-fc04-487f-8a39-fa0ef313263b/userFiles-d5a48adf-1846-4a47-9cfb-e1729b5668eb/a1.jar to class loader
2016-10-12 21:39:12 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 21:39:12 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 21:39:15 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1490 bytes result sent to driver
2016-10-12 21:39:16 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 4176 ms on localhost (1/1)
2016-10-12 21:39:16 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2016-10-12 21:39:16 INFO  DAGScheduler:54 - ShuffleMapStage 0 (distinct at a1.scala:33) finished in 4.189 s
2016-10-12 21:39:16 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 21:39:16 INFO  DAGScheduler:54 - running: Set()
2016-10-12 21:39:16 INFO  DAGScheduler:54 - waiting: Set(ResultStage 1)
2016-10-12 21:39:16 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 21:39:16 INFO  DAGScheduler:54 - Submitting ResultStage 1 (MapPartitionsRDD[5] at distinct at a1.scala:33), which has no missing parents
2016-10-12 21:39:16 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 3.7 KB, free 366.0 MB)
2016-10-12 21:39:16 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.2 KB, free 366.0 MB)
2016-10-12 21:39:16 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on 150.212.30.95:41887 (size: 2.2 KB, free: 366.3 MB)
2016-10-12 21:39:16 INFO  SparkContext:54 - Created broadcast 2 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:39:16 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at distinct at a1.scala:33)
2016-10-12 21:39:16 INFO  TaskSchedulerImpl:54 - Adding task set 1.0 with 1 tasks
2016-10-12 21:39:16 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 1, localhost, partition 0, ANY, 5177 bytes)
2016-10-12 21:39:16 INFO  Executor:54 - Running task 0.0 in stage 1.0 (TID 1)
2016-10-12 21:39:16 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 21:39:16 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 4 ms
2016-10-12 21:39:16 INFO  Executor:54 - Finished task 0.0 in stage 1.0 (TID 1). 1512 bytes result sent to driver
2016-10-12 21:39:16 INFO  DAGScheduler:54 - ResultStage 1 (count at a1.scala:33) finished in 0.121 s
2016-10-12 21:39:16 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 1) in 119 ms on localhost (1/1)
2016-10-12 21:39:16 INFO  TaskSchedulerImpl:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2016-10-12 21:39:16 INFO  DAGScheduler:54 - Job 0 finished: count at a1.scala:33, took 4.486909 s
2016-10-12 21:39:16 INFO  SparkContext:54 - Starting job: count at a1.scala:34
2016-10-12 21:39:16 INFO  DAGScheduler:54 - Registering RDD 7 (distinct at a1.scala:34)
2016-10-12 21:39:16 INFO  DAGScheduler:54 - Got job 1 (count at a1.scala:34) with 1 output partitions
2016-10-12 21:39:16 INFO  DAGScheduler:54 - Final stage: ResultStage 3 (count at a1.scala:34)
2016-10-12 21:39:16 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 2)
2016-10-12 21:39:16 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 2)
2016-10-12 21:39:16 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 2 (MapPartitionsRDD[7] at distinct at a1.scala:34), which has no missing parents
2016-10-12 21:39:16 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 4.2 KB, free 366.0 MB)
2016-10-12 21:39:16 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.5 KB, free 366.0 MB)
2016-10-12 21:39:16 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on 150.212.30.95:41887 (size: 2.5 KB, free: 366.3 MB)
2016-10-12 21:39:16 INFO  SparkContext:54 - Created broadcast 3 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:39:16 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[7] at distinct at a1.scala:34)
2016-10-12 21:39:16 INFO  TaskSchedulerImpl:54 - Adding task set 2.0 with 1 tasks
2016-10-12 21:39:16 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 2, localhost, partition 0, PROCESS_LOCAL, 5507 bytes)
2016-10-12 21:39:16 INFO  Executor:54 - Running task 0.0 in stage 2.0 (TID 2)
2016-10-12 21:39:16 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 21:39:16 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 21:39:16 INFO  BlockManagerInfo:54 - Removed broadcast_2_piece0 on 150.212.30.95:41887 in memory (size: 2.2 KB, free: 366.3 MB)
2016-10-12 21:39:19 INFO  Executor:54 - Finished task 0.0 in stage 2.0 (TID 2). 1490 bytes result sent to driver
2016-10-12 21:39:19 INFO  TaskSetManager:54 - Finished task 0.0 in stage 2.0 (TID 2) in 3412 ms on localhost (1/1)
2016-10-12 21:39:19 INFO  DAGScheduler:54 - ShuffleMapStage 2 (distinct at a1.scala:34) finished in 3.413 s
2016-10-12 21:39:19 INFO  TaskSchedulerImpl:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2016-10-12 21:39:19 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 21:39:19 INFO  DAGScheduler:54 - running: Set()
2016-10-12 21:39:19 INFO  DAGScheduler:54 - waiting: Set(ResultStage 3)
2016-10-12 21:39:19 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 21:39:19 INFO  DAGScheduler:54 - Submitting ResultStage 3 (MapPartitionsRDD[9] at distinct at a1.scala:34), which has no missing parents
2016-10-12 21:39:19 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 3.8 KB, free 366.0 MB)
2016-10-12 21:39:19 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.2 KB, free 366.0 MB)
2016-10-12 21:39:19 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on 150.212.30.95:41887 (size: 2.2 KB, free: 366.3 MB)
2016-10-12 21:39:19 INFO  SparkContext:54 - Created broadcast 4 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:39:19 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[9] at distinct at a1.scala:34)
2016-10-12 21:39:19 INFO  TaskSchedulerImpl:54 - Adding task set 3.0 with 1 tasks
2016-10-12 21:39:19 INFO  TaskSetManager:54 - Starting task 0.0 in stage 3.0 (TID 3, localhost, partition 0, ANY, 5177 bytes)
2016-10-12 21:39:19 INFO  Executor:54 - Running task 0.0 in stage 3.0 (TID 3)
2016-10-12 21:39:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 21:39:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2016-10-12 21:39:19 INFO  Executor:54 - Finished task 0.0 in stage 3.0 (TID 3). 1512 bytes result sent to driver
2016-10-12 21:39:19 INFO  TaskSetManager:54 - Finished task 0.0 in stage 3.0 (TID 3) in 53 ms on localhost (1/1)
2016-10-12 21:39:19 INFO  DAGScheduler:54 - ResultStage 3 (count at a1.scala:34) finished in 0.055 s
2016-10-12 21:39:19 INFO  DAGScheduler:54 - Job 1 finished: count at a1.scala:34, took 3.525964 s
2016-10-12 21:39:19 INFO  TaskSchedulerImpl:54 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2016-10-12 21:39:19 INFO  SparkContext:54 - Starting job: collect at a1.scala:35
2016-10-12 21:39:19 INFO  DAGScheduler:54 - Registering RDD 10 (map at a1.scala:35)
2016-10-12 21:39:19 INFO  DAGScheduler:54 - Got job 2 (collect at a1.scala:35) with 1 output partitions
2016-10-12 21:39:19 INFO  DAGScheduler:54 - Final stage: ResultStage 5 (collect at a1.scala:35)
2016-10-12 21:39:19 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 4)
2016-10-12 21:39:19 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 4)
2016-10-12 21:39:19 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 4 (MapPartitionsRDD[10] at map at a1.scala:35), which has no missing parents
2016-10-12 21:39:19 INFO  MemoryStore:54 - Block broadcast_5 stored as values in memory (estimated size 4.0 KB, free 366.0 MB)
2016-10-12 21:39:19 INFO  MemoryStore:54 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.4 KB, free 366.0 MB)
2016-10-12 21:39:19 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on 150.212.30.95:41887 (size: 2.4 KB, free: 366.3 MB)
2016-10-12 21:39:19 INFO  SparkContext:54 - Created broadcast 5 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:39:19 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[10] at map at a1.scala:35)
2016-10-12 21:39:19 INFO  TaskSchedulerImpl:54 - Adding task set 4.0 with 1 tasks
2016-10-12 21:39:19 INFO  TaskSetManager:54 - Starting task 0.0 in stage 4.0 (TID 4, localhost, partition 0, PROCESS_LOCAL, 5592 bytes)
2016-10-12 21:39:19 INFO  Executor:54 - Running task 0.0 in stage 4.0 (TID 4)
2016-10-12 21:39:19 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 21:39:19 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 21:39:20 INFO  ContextCleaner:54 - Cleaned shuffle 1
2016-10-12 21:39:20 INFO  BlockManagerInfo:54 - Removed broadcast_3_piece0 on 150.212.30.95:41887 in memory (size: 2.5 KB, free: 366.3 MB)
2016-10-12 21:39:20 INFO  BlockManagerInfo:54 - Removed broadcast_4_piece0 on 150.212.30.95:41887 in memory (size: 2.2 KB, free: 366.3 MB)
2016-10-12 21:39:23 INFO  Executor:54 - Finished task 0.0 in stage 4.0 (TID 4). 1490 bytes result sent to driver
2016-10-12 21:39:23 INFO  DAGScheduler:54 - ShuffleMapStage 4 (map at a1.scala:35) finished in 3.518 s
2016-10-12 21:39:23 INFO  TaskSetManager:54 - Finished task 0.0 in stage 4.0 (TID 4) in 3515 ms on localhost (1/1)
2016-10-12 21:39:23 INFO  TaskSchedulerImpl:54 - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2016-10-12 21:39:23 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 21:39:23 INFO  DAGScheduler:54 - running: Set()
2016-10-12 21:39:23 INFO  DAGScheduler:54 - waiting: Set(ResultStage 5)
2016-10-12 21:39:23 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 21:39:23 INFO  DAGScheduler:54 - Submitting ResultStage 5 (MapPartitionsRDD[13] at map at a1.scala:35), which has no missing parents
2016-10-12 21:39:23 INFO  MemoryStore:54 - Block broadcast_6 stored as values in memory (estimated size 3.8 KB, free 366.0 MB)
2016-10-12 21:39:23 INFO  MemoryStore:54 - Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.2 KB, free 366.0 MB)
2016-10-12 21:39:23 INFO  BlockManagerInfo:54 - Added broadcast_6_piece0 in memory on 150.212.30.95:41887 (size: 2.2 KB, free: 366.3 MB)
2016-10-12 21:39:23 INFO  SparkContext:54 - Created broadcast 6 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:39:23 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[13] at map at a1.scala:35)
2016-10-12 21:39:23 INFO  TaskSchedulerImpl:54 - Adding task set 5.0 with 1 tasks
2016-10-12 21:39:23 INFO  TaskSetManager:54 - Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0, ANY, 5262 bytes)
2016-10-12 21:39:23 INFO  Executor:54 - Running task 0.0 in stage 5.0 (TID 5)
2016-10-12 21:39:23 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 21:39:23 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 2 ms
2016-10-12 21:39:23 INFO  Executor:54 - Finished task 0.0 in stage 5.0 (TID 5). 9861 bytes result sent to driver
2016-10-12 21:39:23 INFO  DAGScheduler:54 - ResultStage 5 (collect at a1.scala:35) finished in 0.065 s
2016-10-12 21:39:23 INFO  TaskSetManager:54 - Finished task 0.0 in stage 5.0 (TID 5) in 69 ms on localhost (1/1)
2016-10-12 21:39:23 INFO  DAGScheduler:54 - Job 2 finished: collect at a1.scala:35, took 3.625975 s
2016-10-12 21:39:23 INFO  TaskSchedulerImpl:54 - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2016-10-12 21:39:23 INFO  SparkContext:54 - Starting job: collect at a1.scala:47
2016-10-12 21:39:23 INFO  DAGScheduler:54 - Registering RDD 16 (map at a1.scala:42)
2016-10-12 21:39:23 INFO  DAGScheduler:54 - Got job 3 (collect at a1.scala:47) with 1 output partitions
2016-10-12 21:39:23 INFO  DAGScheduler:54 - Final stage: ResultStage 7 (collect at a1.scala:47)
2016-10-12 21:39:23 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 6)
2016-10-12 21:39:23 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 6)
2016-10-12 21:39:23 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 6 (MapPartitionsRDD[16] at map at a1.scala:42), which has no missing parents
2016-10-12 21:39:23 INFO  MemoryStore:54 - Block broadcast_7 stored as values in memory (estimated size 45.6 KB, free 366.0 MB)
2016-10-12 21:39:23 INFO  MemoryStore:54 - Block broadcast_7_piece0 stored as bytes in memory (estimated size 21.5 KB, free 365.9 MB)
2016-10-12 21:39:23 INFO  BlockManagerInfo:54 - Added broadcast_7_piece0 in memory on 150.212.30.95:41887 (size: 21.5 KB, free: 366.2 MB)
2016-10-12 21:39:23 INFO  SparkContext:54 - Created broadcast 7 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:39:23 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[16] at map at a1.scala:42)
2016-10-12 21:39:23 INFO  TaskSchedulerImpl:54 - Adding task set 6.0 with 1 tasks
2016-10-12 21:39:23 INFO  TaskSetManager:54 - Starting task 0.0 in stage 6.0 (TID 6, localhost, partition 0, PROCESS_LOCAL, 5592 bytes)
2016-10-12 21:39:23 INFO  Executor:54 - Running task 0.0 in stage 6.0 (TID 6)
2016-10-12 21:39:23 INFO  NewHadoopRDD:54 - Input split: ParquetInputSplit{part: file:/home/aadu/Repos/School-Work/2065MachineLearning/assignment1/small.adam/part-r-00000.gz.parquet start: 0 end: 152153 length: 152153 hosts: []}
2016-10-12 21:39:23 INFO  CodecPool:181 - Got brand-new decompressor [.gz]
2016-10-12 21:39:24 INFO  ContextCleaner:54 - Cleaned shuffle 2
2016-10-12 21:39:24 INFO  BlockManagerInfo:54 - Removed broadcast_5_piece0 on 150.212.30.95:41887 in memory (size: 2.4 KB, free: 366.3 MB)
2016-10-12 21:39:24 INFO  BlockManagerInfo:54 - Removed broadcast_6_piece0 on 150.212.30.95:41887 in memory (size: 2.2 KB, free: 366.3 MB)
2016-10-12 21:39:28 INFO  Executor:54 - Finished task 0.0 in stage 6.0 (TID 6). 1490 bytes result sent to driver
2016-10-12 21:39:28 INFO  TaskSetManager:54 - Finished task 0.0 in stage 6.0 (TID 6) in 4804 ms on localhost (1/1)
2016-10-12 21:39:28 INFO  DAGScheduler:54 - ShuffleMapStage 6 (map at a1.scala:42) finished in 4.804 s
2016-10-12 21:39:28 INFO  DAGScheduler:54 - looking for newly runnable stages
2016-10-12 21:39:28 INFO  DAGScheduler:54 - running: Set()
2016-10-12 21:39:28 INFO  DAGScheduler:54 - waiting: Set(ResultStage 7)
2016-10-12 21:39:28 INFO  DAGScheduler:54 - failed: Set()
2016-10-12 21:39:28 INFO  DAGScheduler:54 - Submitting ResultStage 7 (ShuffledRDD[17] at reduceByKey at a1.scala:42), which has no missing parents
2016-10-12 21:39:28 INFO  TaskSchedulerImpl:54 - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2016-10-12 21:39:28 INFO  MemoryStore:54 - Block broadcast_8 stored as values in memory (estimated size 3.1 KB, free 365.9 MB)
2016-10-12 21:39:28 INFO  MemoryStore:54 - Block broadcast_8_piece0 stored as bytes in memory (estimated size 1901.0 B, free 365.9 MB)
2016-10-12 21:39:28 INFO  BlockManagerInfo:54 - Added broadcast_8_piece0 in memory on 150.212.30.95:41887 (size: 1901.0 B, free: 366.3 MB)
2016-10-12 21:39:28 INFO  SparkContext:54 - Created broadcast 8 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:39:28 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 7 (ShuffledRDD[17] at reduceByKey at a1.scala:42)
2016-10-12 21:39:28 INFO  TaskSchedulerImpl:54 - Adding task set 7.0 with 1 tasks
2016-10-12 21:39:28 INFO  TaskSetManager:54 - Starting task 0.0 in stage 7.0 (TID 7, localhost, partition 0, ANY, 5262 bytes)
2016-10-12 21:39:28 INFO  Executor:54 - Running task 0.0 in stage 7.0 (TID 7)
2016-10-12 21:39:28 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 21:39:28 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2016-10-12 21:39:28 INFO  MemoryStore:54 - Block taskresult_7 stored as bytes in memory (estimated size 4.5 MB, free 361.4 MB)
2016-10-12 21:39:28 INFO  BlockManagerInfo:54 - Added taskresult_7 in memory on 150.212.30.95:41887 (size: 4.5 MB, free: 361.8 MB)
2016-10-12 21:39:28 INFO  Executor:54 - Finished task 0.0 in stage 7.0 (TID 7). 4714208 bytes result sent via BlockManager)
2016-10-12 21:39:28 INFO  TransportClientFactory:250 - Successfully created connection to /150.212.30.95:41887 after 1 ms (0 ms spent in bootstraps)
2016-10-12 21:39:28 INFO  BlockManagerInfo:54 - Removed taskresult_7 on 150.212.30.95:41887 in memory (size: 4.5 MB, free: 366.3 MB)
2016-10-12 21:39:28 INFO  DAGScheduler:54 - ResultStage 7 (collect at a1.scala:47) finished in 0.227 s
2016-10-12 21:39:28 INFO  TaskSetManager:54 - Finished task 0.0 in stage 7.0 (TID 7) in 198 ms on localhost (1/1)
2016-10-12 21:39:28 INFO  DAGScheduler:54 - Job 3 finished: collect at a1.scala:47, took 5.086088 s
2016-10-12 21:39:28 INFO  TaskSchedulerImpl:54 - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2016-10-12 21:39:28 INFO  SparkContext:54 - Starting job: takeSample at a1.scala:69
2016-10-12 21:39:28 INFO  MapOutputTrackerMaster:54 - Size of output statuses for shuffle 3 is 148 bytes
2016-10-12 21:39:28 INFO  DAGScheduler:54 - Got job 4 (takeSample at a1.scala:69) with 1 output partitions
2016-10-12 21:39:28 INFO  DAGScheduler:54 - Final stage: ResultStage 9 (takeSample at a1.scala:69)
2016-10-12 21:39:28 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 8)
2016-10-12 21:39:28 INFO  DAGScheduler:54 - Missing parents: List()
2016-10-12 21:39:28 INFO  DAGScheduler:54 - Submitting ResultStage 9 (ShuffledRDD[17] at reduceByKey at a1.scala:42), which has no missing parents
2016-10-12 21:39:28 INFO  MemoryStore:54 - Block broadcast_9 stored as values in memory (estimated size 2.9 KB, free 365.9 MB)
2016-10-12 21:39:28 INFO  MemoryStore:54 - Block broadcast_9_piece0 stored as bytes in memory (estimated size 1853.0 B, free 365.9 MB)
2016-10-12 21:39:28 INFO  BlockManagerInfo:54 - Added broadcast_9_piece0 in memory on 150.212.30.95:41887 (size: 1853.0 B, free: 366.3 MB)
2016-10-12 21:39:28 INFO  SparkContext:54 - Created broadcast 9 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:39:28 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 9 (ShuffledRDD[17] at reduceByKey at a1.scala:42)
2016-10-12 21:39:28 INFO  TaskSchedulerImpl:54 - Adding task set 9.0 with 1 tasks
2016-10-12 21:39:28 INFO  TaskSetManager:54 - Starting task 0.0 in stage 9.0 (TID 8, localhost, partition 0, ANY, 5265 bytes)
2016-10-12 21:39:28 INFO  Executor:54 - Running task 0.0 in stage 9.0 (TID 8)
2016-10-12 21:39:28 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 21:39:28 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 2 ms
2016-10-12 21:39:28 INFO  Executor:54 - Finished task 0.0 in stage 9.0 (TID 8). 1512 bytes result sent to driver
2016-10-12 21:39:28 INFO  TaskSetManager:54 - Finished task 0.0 in stage 9.0 (TID 8) in 70 ms on localhost (1/1)
2016-10-12 21:39:28 INFO  TaskSchedulerImpl:54 - Removed TaskSet 9.0, whose tasks have all completed, from pool 
2016-10-12 21:39:28 INFO  DAGScheduler:54 - ResultStage 9 (takeSample at a1.scala:69) finished in 0.066 s
2016-10-12 21:39:28 INFO  DAGScheduler:54 - Job 4 finished: takeSample at a1.scala:69, took 0.089999 s
2016-10-12 21:39:28 INFO  SparkContext:54 - Starting job: takeSample at a1.scala:69
2016-10-12 21:39:28 INFO  DAGScheduler:54 - Got job 5 (takeSample at a1.scala:69) with 1 output partitions
2016-10-12 21:39:28 INFO  DAGScheduler:54 - Final stage: ResultStage 11 (takeSample at a1.scala:69)
2016-10-12 21:39:28 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 10)
2016-10-12 21:39:28 INFO  DAGScheduler:54 - Missing parents: List()
2016-10-12 21:39:28 INFO  DAGScheduler:54 - Submitting ResultStage 11 (PartitionwiseSampledRDD[18] at takeSample at a1.scala:69), which has no missing parents
2016-10-12 21:39:28 INFO  MemoryStore:54 - Block broadcast_10 stored as values in memory (estimated size 3.8 KB, free 365.9 MB)
2016-10-12 21:39:28 INFO  MemoryStore:54 - Block broadcast_10_piece0 stored as bytes in memory (estimated size 2.3 KB, free 365.9 MB)
2016-10-12 21:39:28 INFO  BlockManagerInfo:54 - Added broadcast_10_piece0 in memory on 150.212.30.95:41887 (size: 2.3 KB, free: 366.2 MB)
2016-10-12 21:39:28 INFO  SparkContext:54 - Created broadcast 10 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:39:28 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 11 (PartitionwiseSampledRDD[18] at takeSample at a1.scala:69)
2016-10-12 21:39:28 INFO  TaskSchedulerImpl:54 - Adding task set 11.0 with 1 tasks
2016-10-12 21:39:28 INFO  TaskSetManager:54 - Starting task 0.0 in stage 11.0 (TID 9, localhost, partition 0, ANY, 5374 bytes)
2016-10-12 21:39:28 INFO  Executor:54 - Running task 0.0 in stage 11.0 (TID 9)
2016-10-12 21:39:28 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 21:39:28 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 2 ms
2016-10-12 21:39:28 INFO  Executor:54 - Finished task 0.0 in stage 11.0 (TID 9). 136922 bytes result sent to driver
2016-10-12 21:39:28 INFO  DAGScheduler:54 - ResultStage 11 (takeSample at a1.scala:69) finished in 0.065 s
2016-10-12 21:39:28 INFO  DAGScheduler:54 - Job 5 finished: takeSample at a1.scala:69, took 0.088944 s
2016-10-12 21:39:28 INFO  TaskSetManager:54 - Finished task 0.0 in stage 11.0 (TID 9) in 65 ms on localhost (1/1)
2016-10-12 21:39:28 INFO  TaskSchedulerImpl:54 - Removed TaskSet 11.0, whose tasks have all completed, from pool 
2016-10-12 21:39:28 INFO  SparkContext:54 - Starting job: collect at a1.scala:71
2016-10-12 21:39:28 INFO  DAGScheduler:54 - Got job 6 (collect at a1.scala:71) with 1 output partitions
2016-10-12 21:39:28 INFO  DAGScheduler:54 - Final stage: ResultStage 13 (collect at a1.scala:71)
2016-10-12 21:39:28 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 12)
2016-10-12 21:39:28 INFO  DAGScheduler:54 - Missing parents: List()
2016-10-12 21:39:28 INFO  DAGScheduler:54 - Submitting ResultStage 13 (MapPartitionsRDD[19] at map at a1.scala:71), which has no missing parents
2016-10-12 21:39:28 INFO  MemoryStore:54 - Block broadcast_11 stored as values in memory (estimated size 3.5 KB, free 365.9 MB)
2016-10-12 21:39:28 INFO  MemoryStore:54 - Block broadcast_11_piece0 stored as bytes in memory (estimated size 2.1 KB, free 365.9 MB)
2016-10-12 21:39:28 INFO  BlockManagerInfo:54 - Added broadcast_11_piece0 in memory on 150.212.30.95:41887 (size: 2.1 KB, free: 366.2 MB)
2016-10-12 21:39:28 INFO  SparkContext:54 - Created broadcast 11 from broadcast at DAGScheduler.scala:1012
2016-10-12 21:39:28 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[19] at map at a1.scala:71)
2016-10-12 21:39:28 INFO  TaskSchedulerImpl:54 - Adding task set 13.0 with 1 tasks
2016-10-12 21:39:28 INFO  TaskSetManager:54 - Starting task 0.0 in stage 13.0 (TID 10, localhost, partition 0, ANY, 5262 bytes)
2016-10-12 21:39:28 INFO  Executor:54 - Running task 0.0 in stage 13.0 (TID 10)
2016-10-12 21:39:28 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks out of 1 blocks
2016-10-12 21:39:28 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 2 ms
2016-10-12 21:39:28 INFO  BlockManagerInfo:54 - Removed broadcast_7_piece0 on 150.212.30.95:41887 in memory (size: 21.5 KB, free: 366.3 MB)
2016-10-12 21:39:28 INFO  BlockManagerInfo:54 - Removed broadcast_8_piece0 on 150.212.30.95:41887 in memory (size: 1901.0 B, free: 366.3 MB)
2016-10-12 21:39:28 INFO  BlockManagerInfo:54 - Removed broadcast_9_piece0 on 150.212.30.95:41887 in memory (size: 1853.0 B, free: 366.3 MB)
2016-10-12 21:39:28 INFO  BlockManagerInfo:54 - Removed broadcast_10_piece0 on 150.212.30.95:41887 in memory (size: 2.3 KB, free: 366.3 MB)
2016-10-12 21:39:28 INFO  BlockManagerInfo:54 - Removed broadcast_1_piece0 on 150.212.30.95:41887 in memory (size: 2.5 KB, free: 366.3 MB)
2016-10-12 21:39:28 INFO  ContextCleaner:54 - Cleaned shuffle 0
2016-10-12 21:39:28 INFO  MemoryStore:54 - Block taskresult_10 stored as bytes in memory (estimated size 4.5 MB, free 361.5 MB)
2016-10-12 21:39:28 INFO  BlockManagerInfo:54 - Added taskresult_10 in memory on 150.212.30.95:41887 (size: 4.5 MB, free: 361.8 MB)
2016-10-12 21:39:28 INFO  Executor:54 - Finished task 0.0 in stage 13.0 (TID 10). 4684415 bytes result sent via BlockManager)
2016-10-12 21:39:28 INFO  BlockManagerInfo:54 - Removed taskresult_10 on 150.212.30.95:41887 in memory (size: 4.5 MB, free: 366.3 MB)
2016-10-12 21:39:28 INFO  DAGScheduler:54 - ResultStage 13 (collect at a1.scala:71) finished in 0.211 s
2016-10-12 21:39:28 INFO  DAGScheduler:54 - Job 6 finished: collect at a1.scala:71, took 0.235257 s
2016-10-12 21:39:28 INFO  TaskSetManager:54 - Finished task 0.0 in stage 13.0 (TID 10) in 195 ms on localhost (1/1)
2016-10-12 21:39:28 INFO  TaskSchedulerImpl:54 - Removed TaskSet 13.0, whose tasks have all completed, from pool 
2016-10-12 21:39:34 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2016-10-12 21:39:34 INFO  ServerConnector:306 - Stopped ServerConnector@6c67e137{HTTP/1.1}{0.0.0.0:4041}
2016-10-12 21:39:34 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3efe7086{/stages/stage/kill,null,UNAVAILABLE}
2016-10-12 21:39:34 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@62e70ea3{/api,null,UNAVAILABLE}
2016-10-12 21:39:34 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@28276e50{/,null,UNAVAILABLE}
2016-10-12 21:39:34 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a7471ce{/static,null,UNAVAILABLE}
2016-10-12 21:39:34 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@267f474e{/executors/threadDump/json,null,UNAVAILABLE}
2016-10-12 21:39:34 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,UNAVAILABLE}
2016-10-12 21:39:34 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@acb0951{/executors/json,null,UNAVAILABLE}
2016-10-12 21:39:34 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@297ea53a{/executors,null,UNAVAILABLE}
2016-10-12 21:39:34 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@132ddbab{/environment/json,null,UNAVAILABLE}
2016-10-12 21:39:34 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4052274f{/environment,null,UNAVAILABLE}
2016-10-12 21:39:34 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@482d776b{/storage/rdd/json,null,UNAVAILABLE}
2016-10-12 21:39:34 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2e029d61{/storage/rdd,null,UNAVAILABLE}
2016-10-12 21:39:34 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@186978a6{/storage/json,null,UNAVAILABLE}
2016-10-12 21:39:34 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1643d68f{/storage,null,UNAVAILABLE}
2016-10-12 21:39:34 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@107ed6fc{/stages/pool/json,null,UNAVAILABLE}
2016-10-12 21:39:34 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@346a361{/stages/pool,null,UNAVAILABLE}
2016-10-12 21:39:34 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@34a75079{/stages/stage/json,null,UNAVAILABLE}
2016-10-12 21:39:34 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@2a3591c5{/stages/stage,null,UNAVAILABLE}
2016-10-12 21:39:34 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@631e06ab{/stages/json,null,UNAVAILABLE}
2016-10-12 21:39:34 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6d0b5baf{/stages,null,UNAVAILABLE}
2016-10-12 21:39:34 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job/json,null,UNAVAILABLE}
2016-10-12 21:39:34 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,UNAVAILABLE}
2016-10-12 21:39:34 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,UNAVAILABLE}
2016-10-12 21:39:34 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7a48e6e2{/jobs,null,UNAVAILABLE}
2016-10-12 21:39:34 INFO  SparkUI:54 - Stopped Spark web UI at http://150.212.30.95:4041
2016-10-12 21:39:34 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2016-10-12 21:39:34 INFO  MemoryStore:54 - MemoryStore cleared
2016-10-12 21:39:34 INFO  BlockManager:54 - BlockManager stopped
2016-10-12 21:39:34 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2016-10-12 21:39:34 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2016-10-12 21:39:34 INFO  SparkContext:54 - Successfully stopped SparkContext
2016-10-12 21:39:34 INFO  ShutdownHookManager:54 - Shutdown hook called
2016-10-12 21:39:34 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-d4fe5a69-fc04-487f-8a39-fa0ef313263b
